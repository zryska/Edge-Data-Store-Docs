{
    "docfx.console.2.43.2/content/articles/intro.html":  {
                                                             "href":  "docfx.console.2.43.2/content/articles/intro.html",
                                                             "title":  "Add your introductions here!",
                                                             "keywords":  "Add your introductions here!"
                                                         },
    "V1/Troubleshooting/Troubleshooting.html":  {
                                                    "href":  "V1/Troubleshooting/Troubleshooting.html",
                                                    "title":  "Edge Data Store troubleshooting",
                                                    "keywords":  "Edge Data Store troubleshooting If you encounter errors while using or developing against Edge Data Store, you have both local and remote means of diagnosing issues. Edge Data Store supports a diagnostics namespace that is used to store streams containing diagnostic information from Edge Data Store itself. As with any other stream data stored in the Edge Storage component, you can egress this to either PI Web API or OSIsoft Cloud Services to monitor the state of a system remotely. In addition, all components in Edge Data Store support OMF Health messages that can be configured using the Health Endpoint configuration so that OMF Health messages are sent to remote PI Web API or OSIsoft Cloud Service endpoints to support remote monitoring of devices. Ingress Ingress logging You can find log messages related to egress in the Storage logs. If you set the the log level temporarily to Trace , most information for troubleshooting will be output. Ingress debugging In order to troubleshoot problems between an OMF application and Edge Storage, enable debugging. If you set an appropriate value for the IngressDebugExpiration property in an storage runtime configuration, debugging will be enabled for all incoming OMF messages, and HTTP request and response content will be stored to disk for review. The property represents the date and time when debugging should no longer be enabled. You can also disable debugging if you set the value to null . Examples of valid strings representing date and time: Utc: ???yyyy-mm-ddThh:mm:ssZ??? Local: ???mm-dd-yyyy hh:mm:ss??? The content of the OMF message, including the headers will be written to the Logs Directory. For an active application this can become quite large. As a result, debug information is stored to disk in a separate format that usual log messages. A single file will be written to the usual Logs directory for every incoming OMF Type, Container, and Data message. Egress Egress logging You can find log messages related to egress in the Storage logs. If you set the the log level temporarily to Trace , most information for troubleshooting will be output. Egress debugging In order to troubleshoot problems between Edge Data Store and the destination, enable debugging. If you set an appropriate value for the DebugExpiration property in an egress configuration, debugging for that destination will be enabled, and HTTP request and response content will be stored to disk for review. The property represents the date and time when debugging should no longer be enabled. You can also disable debugging if you set the value to null . Examples of valid strings representing date and time: Utc: ???yyyy-mm-ddThh:mm:ssZ??? Local: ???mm-dd-yyyy hh:mm:ss??? The content length of each request/response request response and the overall number of requests/responses, requests responses, can be quite large. As a result, debug information is stored to disk in a separate location than the typical log messages. Debug folders/files folders files will be created under the Edge Data Store data folder. The debug folder/file folder file structure is: Windows: %programdata%\\OSIsoft\\EdgeDataStore\\Storage\\egressdump\\{tenantId}\\{namespaceId}\\{egressId}\\{omfType}\\{Ticks}-{Guid}-{Req/Res}.txt %programdata%\\OSIsoft\\EdgeDataStore\\Storage\\egressdump\\{tenantId}\\{namespaceId}\\{egressId}\\{omfType}\\{Ticks}-{Guid}-{Req Res}.txt Linux: /usr/share/OSIsoft/EdgeDataStore/Storage/egressdump/{tenantId}/{namespaceId}/{egressId}/{omfType}/{Ticks}-{Guid}-{Req/Res}.txt  usr share OSIsoft EdgeDataStore Storage egressdump {tenantId} {namespaceId} {egressId} {omfType} {Ticks}-{Guid}-{Req Res}.txt omfType represents Type/Container/Data; Type Container Data; Ticks represents the tick count for the Utc DateTime when it was decided that the message would be written to disk; Guid represents a unique Guid for each request/response request response pair; Req/Res Req Res whether it was the HTTP request or response."
                                                },
    "README.html":  {
                        "href":  "README.html",
                        "title":  "Edge-Data-Store-Docs",
                        "keywords":  "Edge-Data-Store-Docs"
                    },
    "V1/index.html":  {
                          "href":  "V1/index.html",
                          "title":  "OSIsoft Edge Data Store",
                          "keywords":  "OSIsoft Edge Data Store ======= Overview OMF Quick Start Modbus Quick Start Opc Ua Quick Start OCS Egress Quick Start PI Egress Quick Start SDS Read/Write Read Write Quick Start Visualization Quick Start Analytics Quick Start Command Line Quick Start - Linux Command Line Quick Start - Windows Design Installation Security System Configuration EDS adapters OpcUa Linux Opc Ua Data Selection Windows Opc Ua Data Selection Modbus OMF Storage Sequential Data Store Types Streams Stream Views Indexes Writing Data Write Data API Reading Data Reading Data API Filter Expressions Table Format Units of Measure Request/Response Request Response Compression Searching Stream Tags and Metadata Egress Administration Management Tools Logging Configuration Configuration Schemas Edge Data Store Schema System System Schema System Port Schema Modbus Modbus Data Source Schema Modbus Data Selection Schema Modbus Logging Schema OPC UA OPC UA Data Source Schema OPC UA Data Selection Schema OPC UA Logging Schema Storage Storage Schema Storage Logging Schema Storage Periodic Egress Endpoints Schema Storage Runtime Schema Storage OEM Schema Health Diagnostics Platforms Docker Command Line Troubleshooting Release Notes"
                      },
    "V1/Modbus/ModbusOverview.html":  {
                                          "href":  "V1/Modbus/ModbusOverview.html",
                                          "title":  "Modbus EDS adapter",
                                          "keywords":  "Modbus EDS adapter Overview Modbus is a commonly available communication protocol used for connecting and transmitting information between industrial electronic devices. The Modbus TCP EDS adapter Adapter polls Modbus TCP slave devices, and transfers time series data from the data source devices into Edge Data Store. Polling is based on the measurement configuration provided, and models the register measurements in a Modbus data source. The Modbus TCP EDS adapter communicates with any device conforming to the Modbus TCP/IP TCP IP protocol through a gateway or router. The Modbus slave devices and routers do not need to be on the same subnet as Edge Data Store. To install a Modbus EDS adapter, please reference Edge Data Store Configuration on how to add a new component to Edge Data Store. The example below covers configuring a EDS adapter named Modbus1. If another EDS adapter has been installed, please substitute the name of the installed adapter in the below example for Modbus1. Configuration of Modbus data source To use the Modbus TCP EDS adapter Adapter of Edge Data Store, you must configure it for the Modbus data source from which it will be polling data. Procedure for configuring Modbus data source Complete the following to configure the Modbus data source: Using any text editor, create a file that contains a Modbus data source in JSON form. This file can be created or copied to any directory on a device with Edge Data Store installed. See Modbus Data Source Example section below for content structure See Parameters for Modbus Data Source section below for a table of all available parameters Save the file as DataSource.config.json. Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:5590/api/v1/configuration/\u003cEDS http:  localhost:5590 api v1 configuration \u003cEDS adapterId\u003e/DataSource/ adapterId\u003e DataSource  . In a Modbus EDS adapter is added during installation it will have a EDS adapterId of Modbus1, which is used in the example below. Example using cURL (run this command from the same directory where the file is located): curl -v -d \"@DataSource.config.json\" -H \"Content-Type: application/json\" application json\" -X POST \"http://localhost:5590/api/v1/configuration/Modbus1/DataSource\" \"http:  localhost:5590 api v1 configuration Modbus1 DataSource\" Parameters for Modbus data source The following parameters are available for configuring a Modbus data source. Parameter Required Type Description IpAddress Required string The IP Address of the device from which the data is to be collected using the Modbus protocol. Host name is not supported. Port Optional number The TCP port of the target device that listens for and responds to Modbus requests. The value ranges from 0 to 65535. If not configured, the default TCP port is 502 (which is the default port for Modbus protocol). StreamIdPrefix Optional number Parameter applied to all data items collected from the data source. If not configured, the default value will be the ID of the Modbus EDS adapter. The custom StreamIdPrefix has the highest priority. ConnectTimeout Optional number Parameter to specify the time (in milliseconds) to wait when Modbus TCP EDS adapter is trying to connect to the data source. The value ranges from 1000 ms to 30000 ms. The default value is 5000 ms. ReconnectInterval Optional number Parameter to specify the time (in milliseconds) to wait before retrying to connect to the data source when the data source is offline. The value ranges from 100 ms to 30000 ms. The default value is 1000 ms. RequestTimeout Optional number Parameter to specify the time (in milliseconds) that Modbus TCP EDS adapter waits for a pending request before marking it as timeout and dropping the request. The default value is 10000 ms. The value must be a positive integer, there is no value range. DelayBetweenRequests Optional number Parameter to specify the minimum time (in milliseconds) between two successive requests sent to the data source. The value ranges from 0 ms to 1000 ms. The default value is 0 ms. MaxResponseDataLength Optional number Parameter to limit the maximum length (in bytes) of data that can be read within one transaction. This feature is provided to support devices that limit the number of bytes that can be returned. If there is no device limitation, the request length should be the maximum length of 250 bytes. The value ranges from 2 to 250. The default value is 250 ms. Modbus data source example The following is an example of valid Modbus data source configuration: { \"IpAddress\": \"117.23.45.110\", \"Port\" : 502, \"ConnectTimeout\" : 10000, \"StreamIdPrefix\" : \"DataSource1\", } Configuration of Modbus data selection Once a data source is configured for a Modbus instance, which data is to be collected from the Modbus slave device must be configured. Procedure for configuring Modbus data selection Complete the following to configure Modbus data selection: Using any text editor, create a file that contains a Modbus data selection in JSON form. This file can be created or copied to any directory on a device with Edge Data Store installed. See Modbus Data Selection Example section below for content structure See Parameters for Modbus Data Selection section below for a table of all available parameters Save the file as DataSelection.config.json. Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:5590/api/v1/configuration/\u003cEDS http:  localhost:5590 api v1 configuration \u003cEDS adapterId\u003e/DataSelection/ adapterId\u003e DataSelection  . Example using cURL (run this command from the same directory where the file is located): curl -v -d \"@DataSelection.config.json\" -H \"Content-Type: application/json\" application json\" -X POST \"http://localhost:5590/api/v1/configuration/\u003cEDS \"http:  localhost:5590 api v1 configuration \u003cEDS adapterId\u003e/DataSelection\" adapterId\u003e DataSelection\" Parameters for Modbus data selection The following parameters are available for configuring Modbus data selection. Parameter Required Type Description Selected Optional bool This field is used to select or clear a measurement. To select an item, set to true. To remove an item, leave the field empty or set to false. If not configured, the default value is true. Name Optional string The optional friendly name of the data item collected from the data source. If not configured, the default value will be the stream ID. UnitId Required number Modbus slave device unit ID. This must be a value between 0 and 247, inclusively. RegisterType Required number or string Modbus register type. Supported types are Coil, Discrete, Input16, Input32, Holding16 and Holding32. Input16 and Holding16 are used to read registers that have a size of 16 bits. For registers that have a size of 32 bits, use the Input32 and Holding32 register types. To represent the types, you can type in the register type ID or the exact name: 1 or Coil (Read Coil Status) 2 or Discrete (Read Discrete Input Status) 3 or Holding16 (Read 16-bit Holding Registers) 4 or Holding32 (Read 32-bit Holding Registers) 6 or Input16 (Read 16-bit Input Registers) 7 or Input32 (Read 32-bit Input Registers) RegisterOffset Required number The 0 relative offset to the starting register for this measurement. For example, if your Holding registers start at base register 40001, the offset to this register is 0. For 40002, the offset to this register is 1. DataTypeCode Required number An integer representing the data type that Modbus TCP EDS adapter will read starting at the register specified by the offset. Supported data types are: 1 = Boolean 10 = Int16 20 = UInt16 30 = Int32 31 = Int32ByteSwap 100 = Float32 101 = Float32ByteSwap 110 = Float64 111 = Float64ByteSwap 1001 - 1250 = String 2001 - 2250 = StringByteSwap ScanRate Required number How often this measurement should be read from the device in milliseconds. Acceptable values are from 0 to 86400000. If 0 ms is specified, Modbus TCP EDS adapter will scan for data as fast as possible. BitMap Required string The bitmap is used to extract and reorder bits from a word register. The format of the bitmap is uuvvwwxxyyzz, where uu, vv, ww, yy, and zz each refer to a single bit. A leading zero is required if the referenced bit is less than 10. The low-order bit is 01 and high-order bit is either 16 or 32. Up to 16 bits can be referenced for a 16-bit word (data types 10 and 20) and up to 32 bits can be reference for a 32-bit word (data type 30 and 31). The bitmap 0307120802 will map the second bit of the original word to the first bit of the new word, the eighth bit to the second bit, the twelfth bit to the third bit, and so on. The high-order bits of the new word are padded with zeros if they are not specified. ConversionFactor Required number This numerical value can be used to scale the raw response received from the Modbus TCP device. If this is specified, regardless of the specified data type, the value will be promoted to a float32 (single) when stored. [Result = (Value /   Conversion Factor)] ConversionOffset Required number This numerical value can be used to apply an offset to the response received from the Modbus TCP device. If this is specified, regardless of the specified data type, the value will be promoted to a float32 (single) when stored. [Result = (Value - Conversion Offset)] StreamID Required string The custom stream ID that will be used to create the streams. If not specified, the Modbus TCP EDS adapter will generate a default stream ID based on the measurement configuration. A properly configured custom stream ID follows these rules: Is not case-sensitive. Can contain spaces. Cannot start with two underscores (\"__\"). Can contain a maximum of 260 characters. Cannot use the following characters: /   : ? # [ ] @ ! $ \u0026 \u0027 ( ) \\ * + , ; = % \u003c \u003e | Cannot start or end with a period. Cannot contain consecutive periods. Cannot consist of only periods. Each JSON object in the file represents a measurement. You can modify the fields in each object to configure the measurement parameters. To add more measurements, you need to create more JSON objects with properly completed fields. Data selection examples Below is an example of a valid Modbus data source configuration. Modbus data selection example. [ { \"Selected\": true, \"Name\": \"Measurement1\", \"UnitId\": 0, \"RegisterType\": 1, \"RegisterOffset\": 0, \"DataTypeCode\": 1, \"BitMap\": \"\", \"ConversionFactor\": null, \"ConversionOffset\": null, \"StreamId\": \"SampleStreamID1\", \"ScanRate\": 0 }, { \"Selected\": true, \"Name\": \"Measurement2\", \"UnitId\": 247, \"RegisterType\": 2, \"RegisterOffset\": 65535, \"DataTypeCode\": 10, \"BitMap\": \"\", \"ConversionFactor\": 1, \"ConversionOffset\": 0, \"StreamId\": \"\", \"ScanRate\": 86400000 }, { \"Selected\": true, \"Name\": \"Measurement3\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 1, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"StreamId\": \"Sample Stream ID 2\", \"ScanRate\": 1000 }, { \"Selected\": true, \"Name\": \"Measurement4\", \"UnitId\": 1, \"RegisterType\": 4, \"RegisterOffset\": 1, \"DataTypeCode\": 30, \"BitMap\": \"30293231\", \"ConversionFactor\": 1, \"ConversionOffset\": 2, \"StreamId\": \"Sample_Stream_ID_3\", \"ScanRate\": 1000 } ]"
                                      },
    "V1/LinuxWindows/LinuxWindows.html":  {
                                              "href":  "V1/LinuxWindows/LinuxWindows.html",
                                              "title":  "Linux and Windows platform differences",
                                              "keywords":  "Linux and Windows platform differences When developing applications to work with the Edge Data Store, there is no difference in expected behavior between Linux and Windows installations. There are some differences in how Edge Data Store is installed between Linux and Windows, to follow best practices on both platforms. Windows file locations Program binaries are placed in the C:\\Program Files\\OSIsoft\\EdgeDataStore directory by default. for information about changing this location see the installation documentation. Configuration, log, and data files are placed under C:\\ProgramData\\OSIsoft\\EdgeDataStore\\ This is not configurable. This folder structure will not be automatically removed during uninstallation. For information about clearing these files, see the installation documentation. Key material for configuration files\u0027 encrypted secrets is stored using the Windows DPAPI in a secure Windows store. This is not configurable. Linux file locations Program binaries are placed in the /opt/EdgeDataStore  opt EdgeDataStore directory. Configuration, log, and data files are placed under /usr/share/OSIsoft/EdgeDataStore.  usr share OSIsoft EdgeDataStore. This folder structure will not be automatically removed during uninstallation. For information about clearing these files, see the installation documentation. Key material for configuration files\u0027 encrypted secrets are stored using limited access files under /usr/share/OSIsoft/EdgeDataStore.  usr share OSIsoft EdgeDataStore. File locations for Linux are not user configurable. When the Debian installer is used the Edge Data Store is installed using the service identity osisoft.edgedatastore.service. If you have a need to restart the service from the Linux command line you can use the following command: sudo systemctl restart osisoft.edgedatastore.service"
                                          },
    "V1/Installation/InstallationOverview.html":  {
                                                      "href":  "V1/Installation/InstallationOverview.html",
                                                      "title":  "Installation of Edge Data Store",
                                                      "keywords":  "Installation of Edge Data Store Overview Edge Data Store is supported on a variety of platforms and processors. OSIsoft provides ready to use install kits for the following platforms: Windows 10 x64 - EdgeDataStore.msi (Intel/AMD (Intel AMD 64 bit processors) Debian 9 or later x64/AMD64 x64 AMD64 - EdgeDataStore_linux-x64.deb (Intel/AMD (Intel AMD 64 bit processors) Debian 9 or later ARM32 - EdgeDataStore_linux-arm.deb (Raspberry PI 2,3,4, BeagleBone devices, other ARM v7 and ARM v8 32 bit processors) In addition to ready to use install kits, OSIsoft also provides examples of how to create Docker containers , and tar.gz files are provided with binaries for customers who wish to build their own custom installers or containers for Linux. Install Edge Data Store on a device using an install kit To use any of the installers, copy the appropriate file to the file system of the device. The installers allow the port assignment to be configured at install time. The default port is 5590. The user can specify any numeric value in the range of 1024 to 65535; any other characters or values will be considered invalid. You should select a port not already in use by another program on the host; the installer will not check for this case. Note The port assignment can be changed after installation - see the configuration section of the documentation. Windows (Windows 10 x64) You must have administrative privileges to run the installer. Double click the EdgeDataStore.msi file in Windows Explorer to launch the installer UI. You will be prompted for install location and port (with the default 5590 value pre-set). When the install finishes, Edge Data Store will be installed and running on the port specified. There are also checkboxes to allow a Modbus or OPC UA EDS adapter to be installed along with the default Storage component. Note The UI based installer will prompt for a port value, and will not proceed if an invalid port is specified. The installer can be launched from the command line with the following command msiexec /i  i EdgeDataStore.msi PORT=5590 INSTALLFOLDER=\"C:\\otherdir\" The PORT (shown above as the default value; must be in all caps) is optional, and can be changed to a valid value of the user\u0027s preference. If PORT=nnnn is omitted, the default will be used. The UI will launch with the port pre-set to the value specified; validity will be checked as mentioned above, with the install proceeding only when a valid port number is provided. If, however, the \"quiet\" or \"no ui\" flag for msiexec is specified, and the PORT value on the command line is not valid, the install will proceed with the default 5590 value. The INSTALLFOLDER (must be all caps) is also optional; you can specify an alternate location for Edge Data Store\u0027s binary components. The default value is \"C:\\Program Files\\OSISoft\\EdgeDataStore\". OSIsoft recommends you use the default value. Windows uninstallation To remove the EdgeDataStore program files from a computer, use the Windows Control Panel uninstall application process. The configuration, data, and log files will not be removed by the uninstallation process. To remove data, configuration and log files, remove the directory C:\\ProgramData\\OSIsoft\\EdgeDataStore. This will result in deletion of all data stored in the Edge Storage component in addition to configuration and log files. Debian 9 or Later Linux (Ubuntu Raspberry PI, BeagleBone, other Debian based Linux distros) You must have administrative privileges to install the software, e.g. root or sudo privilege. The examples below assume a user with permission to use sudo. Open a terminal window and type: sudo apt install ./EdgeDataStore_linux_\u003ceither . EdgeDataStore_linux_\u003ceither x64 or arm depending upon processor\u003e.deb A validation check will be done for prerequisites. If the Linux OS is up to date, the install will succeed. If the install fails, run the following commands from the terminal window and try the install again: sudo apt update sudo apt upgrade After the check for prerequisites succeeds, a prompt will appear asking if you want to change the default port (5590). If you wish to change the port type to another value in the acceptable range, type the port value you want and press Enter; if 5590 is acceptable, simply press Enter. You wil then be prompted if you want to install a Modbus or OPC UA EDS adapter in addition to the default Storage component. The default is not to install them, so you can press enter to proceed if neither is desired. They can be added after the installation is complete if desired. Note If an invalid value is specified for the port, the install will proceed with the default value of 5590 selected. The install will complete and Edge Data Store will be running on your device. Linux uninstallation To remove Edge Data Store software from a Linux computer, open a terminal window and run the command: sudo apt remove osisoft.EdgeDataStore Running this command will not delete the data, configuration, or log files. To remove data, configuration, and log files, remove the directory /usr/share/OSIsoft/EdgeDataStore/.  usr share OSIsoft EdgeDataStore . This will result in deletion of all data stored in the Edge Storage component, in addition to configuration and log files. This can be done with the following command: sudo rm -r /usr/share/EdgeDataStore/  usr share EdgeDataStore  After Installation (Windows and Linux) You can verify that Edge Data Store is correctly installed by running the following script from the terminal window (depending upon the processor, memory, and storage, it may take the system a few seconds to start up): curl http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration If the installation was successful, you will get back a JSON copy of the default system configuration: { \"Storage\": { \"PeriodicEgressEndpoints\": [], \"Runtime\": { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\", \"checkpointRateInSec\": 30, \"transactionLogLimitMB\": 250, \"enableTransactionLog\": true }, \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 } }, \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 }, \"Components\": [ { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ] } } If you get back an error, wait a few seconds and try it again. On a device with limited processor, memory, and slow storage, it may take some time before the Edge Data Store is fully initialized and running for the first time."
                                                  },
    "V1/Health/Health.html":  {
                                  "href":  "V1/Health/Health.html",
                                  "title":  "Edge Data Store health",
                                  "keywords":  "Edge Data Store health Having insight into the health of the Edge Data Store and the components that make it up can be critical for ensuring that your needs for data collection are being met. To that end, Edge Data Store and its components produce health information to be sent to OSIsoft Health Omf Endpoints. When enabled, Edge Data Store will transfer to configured Omf health endpoints the types and containers that represent available health information. Configuring Edge Data Store health endpoints The Edge Data Store has the ability to report system health to one or more OMF endpoints capable of receiving health messages. To enable this functionality, one or more health endpoints must be configured. Table 1. Configuration parameters for Edge Data Store health endpoints Parameter Required Description Id Optional The ID can be any alphanumeric string, for example Endpoint1. If you do not specify an ID, Edge Data Store generates one automatically. Endpoint Required The URL of the ingress point which accepts OMF health messages. UserName Required for PI Web API endpoints The user name used for authentication to PI Web API OMF endpoint. Password Required for PI Web API endpoints The password used for authentication to PI Web API OMF endpoint. ClientId Required for OSIsoft Cloud Services. The Client Id used for authentication to OSIsoft Cloud Services. ClientSecret Required for OSIsoft Cloud Services. The Client Secret used for authentication to OSIsoft Cloud Services. Buffering Optional Options are memory, disk, or none. The default is none. MaxBufferSizeMB Optional The limit on the maximum megabytes of data to buffer for messages to this endpoint if an integer is \u003e0. This parameter is useful if you want to limit memory or disk usage growth in the event of disconnection to the endpoint. If the buffer is full, old messages will be discarded for new messages. The default is 0. ValidateEndpointCertificate Optional Edge EDS adapter validates the endpoint certificate if set to true (recommended). If set to false, Edge EDS adapter accepts any endpoint certificate. OSIsoft strongly recommends using disabled endpoint certificate validation for testing purposes only. EDS adapter health The following health types and streams are created to reflect the health of EDS adapter adapters. The Connectors static type includes these properties and servers as a root AF element with the id Connectors. Type Property Description string Id Connectors - root AF element string Description Collection of Connector assets EDS adapter health The Connector Health static type includes the following properties, which are logged in a stream with the id {machinename}.{componentid}. The stream is linked to root AF element (Connectors). Type Property Description string Id {machinename}.{componentId} string Description {productname} health string Connector Type {adaptertype} string Version {adapterversion} Device status The DeviceStatus dynamic type includes the following values, which are logged in a stream with the id Connectors.{machinename}.{componentid}.DeviceStatus. The stream is linked to {machinename}.{componentid} static stream. Type Property Description string Time Timestamp of event string DeviceStatus Device status value Next health message expected The NextHealthMessageExpected dynamic type includes the following values, which are logged in a stream with the id Connectors.{machinename}.{componentid}.NextHealthMessageExpected. The stream is linked to {machinename}.{componentid} static stream. Heard beat message is expected once a minute. Type Property Description string Time Timestamp of event string NextHealthMessageExpected Time when next health message is expected. Storage component health The following health types and streams are created to reflect the health of the Storage component. The Storage static type includes the following properties and servers as a root AF element with the id Storage. Type Property Description string Id Storage - root AF element string Description Storage Health Storage health The Storage Health static type includes the following properties, which are logged in a stream with the id {machinename}.Storage. The stream is linked to root AF element (Storage). Type Property Description string Id {machinename}.Storage string Description {productname} health string Connector Type {adaptertype} string Version {storageversion} Storage device status The DeviceStatus dynamic type includes the following values, which are logged in a stream with the id Storage.{machinename}.DeviceStatus. The stream is linked to {machinename}.Storage static stream. Type Property Description string Time Timestamp of event string DeviceStatus Device status value Storage next health message expected The NextHealthMessageExpected dynamic type includes the following values, which are logged in a stream with the id Storage.{machinename}.NextHealthMessageExpected. The stream is linked to {machinename}.Storage static stream. Heard beat message is expected once a minute. Type Property Description string Time Timestamp of event string NextHealthMessageExpected Time when next health message is expected."
                              },
    "V1/Configuration/Schemas/System_schema.html":  {
                                                        "href":  "V1/Configuration/Schemas/System_schema.html",
                                                        "title":  "SystemConfiguration schema",
                                                        "keywords":  "SystemConfiguration schema \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"Components\": [{ \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"Modbus1\", \"componentType\": \"Modbus\" }, { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ], \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 } } Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden Modbus_Logging_schema.json Properties Property Type Required Nullable Defined by Logging SystemLoggingConfiguration Optional Yes EdgeLoggerConfiguration Components [SystemComponentsConfiguration] Optional Yes ComponentsConfiguration HealthEndpoints [SystemHealthEndpointsConfiguration] Optional Yes HealthEndpointsConfiguration Port SystemPortConfiguration Optional Yes PortConfiguration Logging is optional type: SystemLoggingConfiguration Components is optional type: [SystemComponentsConfiguration] HealthEndpoints is optional type: [SystemHealthEndpointsConfiguration] Port is optional type: SystemPortConfiguration"
                                                    },
    "V1/Configuration/Schemas/System_Port_schema.html":  {
                                                             "href":  "V1/Configuration/Schemas/System_Port_schema.html",
                                                             "title":  "Sample system port configuration file",
                                                             "keywords":  "Sample system port configuration file { \"Port\": 5590 } System port schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden System_Port_schema.json PortConfiguration properties Property Type Required Nullable Defined by Port integer Optional No PortConfiguration (this schema) Port Port is optional type: integer defined in this schema Port type integer minimum value: 1024 maximum value: 65535 All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required Port integer Optional Port Port is optional type: integer Port type integer minimum value: 1024 maximum value: 65535"
                                                         },
    "V1/Configuration/Schemas/System_Logging_schema.html":  {
                                                                "href":  "V1/Configuration/Schemas/System_Logging_schema.html",
                                                                "title":  "System logging schema",
                                                                "keywords":  "System logging schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden System_Logging_schema.json EdgeLoggerConfiguration properties Property Type Required Nullable Defined by LogFileCountLimit integer Optional Yes EdgeLoggerConfiguration (this schema) LogFileSizeLimitBytes integer Optional Yes EdgeLoggerConfiguration (this schema) LogLevel reference Optional No EdgeLoggerConfiguration (this schema) LogFileCountLimit LogFileCountLimit is optional type: integer defined in this schema LogFileCountLimit type integer , nullable LogFileSizeLimitBytes LogFileSizeLimitBytes is optional type: integer defined in this schema LogFileSizeLimitBytes type integer , nullable LogLevel LogLevel is optional type: reference defined in this schema LogLevel type ??? #/definitions/EdgeLogLevel # definitions EdgeLogLevel All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required LogFileCountLimit integer Optional LogFileSizeLimitBytes integer Optional LogLevel Optional LogFileCountLimit LogFileCountLimit is optional type: integer LogFileCountLimit type integer , nullable LogFileSizeLimitBytes LogFileSizeLimitBytes is optional type: integer LogFileSizeLimitBytes type integer , nullable LogLevel LogLevel is optional type: reference LogLevel type ??? #/definitions/EdgeLogLevel # definitions EdgeLogLevel"
                                                            },
    "V1/Configuration/Schemas/System_HealthEndpoints_schema.html":  {
                                                                        "href":  "V1/Configuration/Schemas/System_HealthEndpoints_schema.html",
                                                                        "title":  "OMF health endpoint configuration schema",
                                                                        "keywords":  "OMF health endpoint configuration schema [{ \"endpoint\": \"https://\u003cpi \"https:  \u003cpi web api server\u003e/piwebapi/omf/\", server\u003e piwebapi omf \", \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"buffering\": 0, \"maxBufferSizeMB\": 0 }, { \"Endpoint\": \"https://\u003cOCS \"https:  \u003cOCS OMF endpoint\u003e\", \"ClientId\": \"\u003cclientid\u003e\", \"ClientSecret\": \"\u003cclientsecret\u003e\", \"buffering\": 0, \"maxBufferSizeMB\": 0 } ] Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden System_HealthEndpoints_schema.json OmfHealthEndpointConfiguration properties Property Type Required Nullable Defined by Buffering reference Optional No OmfHealthEndpointConfiguration (this schema) ClientId string Optional Yes OmfHealthEndpointConfiguration (this schema) ClientSecret string Optional Yes OmfHealthEndpointConfiguration (this schema) Endpoint string Optional Yes OmfHealthEndpointConfiguration (this schema) Id string Optional Yes OmfHealthEndpointConfiguration (this schema) MaxBufferSizeMB integer Optional No OmfHealthEndpointConfiguration (this schema) Password string Optional Yes OmfHealthEndpointConfiguration (this schema) UserName string Optional Yes OmfHealthEndpointConfiguration (this schema) ValidateEndpointCertificate boolean Optional No OmfHealthEndpointConfiguration (this schema) Buffering Buffering is optional type: reference defined in this schema Buffering type ??? #/definitions/BufferType # definitions BufferType ClientId ClientId is optional type: string defined in this schema ClientId type string , nullable ClientSecret ClientSecret is optional type: string defined in this schema ClientSecret type string , nullable Endpoint Endpoint is optional type: string defined in this schema Endpoint type string , nullable Id Id is optional type: string defined in this schema Id type string , nullable MaxBufferSizeMB MaxBufferSizeMB is optional type: integer defined in this schema MaxBufferSizeMB type integer Password Password is optional type: string defined in this schema Password type string , nullable UserName UserName is optional type: string defined in this schema UserName type string , nullable ValidateEndpointCertificate ValidateEndpointCertificate is optional type: boolean defined in this schema ValidateEndpointCertificate type boolean All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required Buffering Optional ClientId string Optional ClientSecret string Optional Endpoint string Optional Id string Optional MaxBufferSizeMB integer Optional Password string Optional UserName string Optional ValidateEndpointCertificate boolean Optional Buffering Buffering is optional type: reference Buffering type ??? #/definitions/BufferType # definitions BufferType ClientId ClientId is optional type: string ClientId type string , nullable ClientSecret ClientSecret is optional type: string ClientSecret type string , nullable Endpoint Endpoint is optional type: string Endpoint type string , nullable Id Id is optional type: string Id type string , nullable MaxBufferSizeMB MaxBufferSizeMB is optional type: integer MaxBufferSizeMB type integer Password Password is optional type: string Password type string , nullable UserName UserName is optional type: string UserName type string , nullable ValidateEndpointCertificate ValidateEndpointCertificate is optional type: boolean ValidateEndpointCertificate type boolean"
                                                                    },
    "V1/Configuration/Schemas/Storage_OEM_schema.html":  {
                                                             "href":  "V1/Configuration/Schemas/Storage_OEM_schema.html",
                                                             "title":  "Storage OEM configuration schema",
                                                             "keywords":  "Storage OEM configuration schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden Storage_OEM_schema.json OEMConfiguration properties Property Type Required Nullable Defined by CheckpointRateInSec integer Optional No OEMConfiguration (this schema) EnableTransactionLog boolean Optional No OEMConfiguration (this schema) TransactionLogLimitMB integer Optional No OEMConfiguration (this schema) CheckpointRateInSec CheckpointRateInSec is optional type: integer defined in this schema CheckpointRateInSec type integer minimum value: 0 maximum value: 2147483647 EnableTransactionLog EnableTransactionLog is optional type: boolean defined in this schema EnableTransactionLog type boolean TransactionLogLimitMB TransactionLogLimitMB is optional type: integer defined in this schema TransactionLogLimitMB type integer minimum value: 1 maximum value: 9223372036854780000 All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required CheckpointRateInSec integer Optional EnableTransactionLog boolean Optional TransactionLogLimitMB integer Optional CheckpointRateInSec CheckpointRateInSec is optional type: integer CheckpointRateInSec type integer minimum value: 0 maximum value: 2147483647 EnableTransactionLog EnableTransactionLog is optional type: boolean EnableTransactionLog type boolean TransactionLogLimitMB TransactionLogLimitMB is optional type: integer TransactionLogLimitMB type integer minimum value: 1 maximum value: 9223372036854780000"
                                                         },
    "V1/Configuration/Schemas/Storage_Logging_schema.html":  {
                                                                 "href":  "V1/Configuration/Schemas/Storage_Logging_schema.html",
                                                                 "title":  "Storage logging schema",
                                                                 "keywords":  "Storage logging schema Abstract Extensible Status Identifiable Custom properties Additional properties Can be instantiated Yes Experimental No Forbidden Forbidden StorageLoggerConfiguration Properties Property Type Required Nullable Defined by LogFileCountLimit integer Optional Yes EdgeLoggerConfiguration (this schema) LogFileSizeLimitBytes integer Optional Yes EdgeLoggerConfiguration (this schema) LogLevel reference Optional No EdgeLoggerConfiguration (this schema) LogFileCountLimit LogFileCountLimit is optional type: integer defined in this schema LogFileCountLimit type integer , nullable LogFileSizeLimitBytes LogFileSizeLimitBytes is optional type: integer defined in this schema LogFileSizeLimitBytes type integer , nullable LogLevel LogLevel is optional type: reference defined in this schema LogLevel type ??? #/definitions/EdgeLogLevel # definitions EdgeLogLevel All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required LogFileCountLimit integer Optional LogFileSizeLimitBytes integer Optional LogLevel Optional"
                                                             },
    "V1/Configuration/Schemas/Modbus_schema.html":  {
                                                        "href":  "V1/Configuration/Schemas/Modbus_schema.html",
                                                        "title":  "ModbusConfiguration Schema",
                                                        "keywords":  "ModbusConfiguration Schema Abstract Extensible Status Identifiable Custom Properties Additional Properties Defined In Can be instantiated Yes Experimental No Forbidden Forbidden Modbus_Logging_schema.json Properties Property Type Required Nullable Defined by Logging ModbusLoggingConfiguration Optional Yes EdgeLoggerConfiguration DataSource DataSourceConfiguration Optional Yes ComponentsConfiguration DataSelection [ModbusDataSelectionConfiguration] Optional Yes DataSelectionConfiguration Logging is optional type: SystemLoggingConfiguration DataSource is optional type: DataSourceConfiguration DataSelection is optional type: [ModbusDataSelectionConfiguration]"
                                                    },
    "V1/Configuration/Schemas/Modbus_Logging_schema.html":  {
                                                                "href":  "V1/Configuration/Schemas/Modbus_Logging_schema.html",
                                                                "title":  "ModbusLoggerConfiguration Schema",
                                                                "keywords":  "ModbusLoggerConfiguration Schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden Modbus_Logging_schema.json ModbusLoggerConfiguration Properties Property Type Required Nullable Defined by LogFileCountLimit integer Optional Yes EdgeLoggerConfiguration (this schema) LogFileSizeLimitBytes integer Optional Yes EdgeLoggerConfiguration (this schema) LogLevel reference Optional No EdgeLoggerConfiguration (this schema) LogFileCountLimit LogFileCountLimit is optional type: integer defined in this schema LogFileCountLimit type integer , nullable LogFileSizeLimitBytes LogFileSizeLimitBytes is optional type: integer defined in this schema LogFileSizeLimitBytes type integer , nullable LogLevel LogLevel is optional type: reference defined in this schema LogLevel type ??? #/definitions/EdgeLogLevel # definitions EdgeLogLevel All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required LogFileCountLimit integer Optional LogFileSizeLimitBytes integer Optional LogLevel Optional LogFileCountLimit LogFileCountLimit is optional type: integer LogFileCountLimit type integer , nullable LogFileSizeLimitBytes LogFileSizeLimitBytes is optional type: integer LogFileSizeLimitBytes type integer , nullable LogLevel LogLevel is optional type: reference LogLevel type ??? #/definitions/EdgeLogLevel # definitions EdgeLogLevel"
                                                            },
    "V1/Configuration/Schemas/ConfigurationSchemaList.html":  {
                                                                  "href":  "V1/Configuration/Schemas/ConfigurationSchemaList.html",
                                                                  "title":  "Configuration schemas",
                                                                  "keywords":  "Configuration schemas The Edge Data Store is configured via a series of JSON files. The schemas for these files are provided in the installation directory and are documented below. Edge Data Store configuration schemas Use the following schemas to configure Edge Data Store: EdgeLoggerConfiguration PortConfiguration OmfHealthEndpointConfiguration EdgeDataStoreConfig EDS adapter Adapters configuration schemas Use the following schemas to configure EDS adapter Adapters: OPC UA DataSourceConfiguration DataCollectionItem EdgeLoggerConfiguration Modbus DataSourceConfiguration DataSelectionConfiguration EdgeLoggerConfiguration Storage configuration schemas Use the following schemas to configure the Storage component: EdgeLoggerConfiguration StorageRuntimeConfiguration OEMConfiguration Periodic Egress Endpoints"
                                                              },
    "V1/Configuration/EdgeSystemConfiguration.html":  {
                                                          "href":  "V1/Configuration/EdgeSystemConfiguration.html",
                                                          "title":  "Edge Data Store configuration",
                                                          "keywords":  "Edge Data Store configuration Edge Data Store uses JSON configuration files in a protected directory on Windows and Linux to store configuration that is read on startup. While the files are accessible to view, it is recommended that you use REST or the edgecmd command line tool for any changes you make to the files. As part of making Edge Data Store as secure as possible, any passwords or secrets that are configured will be stored in encrypted form (with cryptographic key material stored separately in a secure location.) If the files are edited directly, the system may not work as expected. Note: It is possible to edit any single component or facet of the system using REST, but it is also possible to configure the system as a whole with a single REST call. Configuring the Edge Data Store The Edge Data Store hosts other components. While the initial release of the Edge Data Store includes Modbus, Opc Ua, and Storage components, they are only active if the system is configured to use them. The System itself has a relatively small configuration surface area - the list of components and the HTTP Port used for REST calls. Configuring Edge Data Store port System_Port.json specifies the port on which the System is listening for REST API calls. The same port is used for configuration and for writing data to OMF and SDS. The default configuration port is 5590. The default System_Port.json file installed is: { \"Port\": 5590 } Allowable ports are in the range of 1024-65535. Before you change the default, ensure that no other service or application on the computer running the EdgeDataStore is using that port - only one application or service can use a port. The Edge Data Store must be restarted if the port number changes through the REST API. To change the Edge Data Store port you can save the JSON containing the new port number in the JSON fomrat above to a file named EdgePort.json and run the following script: curl -i -d \"@EdgePort.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/system/port http:  localhost:5590 api v1 configuration system port After the REST command completes, the Edge Data Store will need to be restarted for the change to take effect. Configuring Edge Data Store components The default System_Components.json file for the System component is below. The Storage component is required for this initial release for Edge Data Store to run. With later releases of the Edge Data Store, the storage component may not be required. [ { \"ComponentId\": \"Storage\", \"ComponentType\": \"EDS.Component\" } ] Additional Modbus and Opc Ua components can be added if desired, but only a single Storage component is supported. To add a new component, in this example a Modbus EDS adapter, create the following JSON. Please note a unique ComponentId is necessary for each component in the system. For this example we will use the ComponentId Modbus1 since it is the first Modbus EDS adapter: { \"ComponentId\": \"Modbus1\", \"ComponentType\": \"Modbus\" } Save the JSON in a file named AddComponent.json. From the same directory where the file exists run the following curl script: curl -i -d \"@AddComponent.json\" -H \"Content-Type: application/json\" application json\" -X POST http://localhost:5590/api/v1/configuration/system/components http:  localhost:5590 api v1 configuration system components After the curl command completes successfully the new component can be configured or used. Configuring entire Edge Data Store Minimum Edge Data Store Configuration The following JSON file represents minimal configuration of an Edge Data Store. There are no Modbus or Opc Ua components, and the Storage component configurations are set to the default. If a system were configured with this JSON file, any existing Modbus or Opc Ua components would be disabled and removed. No storage data would be deleted or modified, and OMF and SDS data access would not be impacted. {{ \"Storage\": { \"PeriodicEgressEndpoints\": [], \"Runtime\": { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\", \"checkpointRateInSec\": 30, \"transactionLogLimitMB\": 250, \"enableTransactionLog\": true }, \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 } }, \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 }, \"Components\": [ { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ] } } Save or copy the JSON in a file named EdgeMinimumConfiguration.json in any directory on a device with Edge Data Store installed. When the following curl command is run from the directory where the file exists, this will be set as the configuration of a running Edge Data Store (run the command from the directory where the file is located): curl -i -d \"@EdgeMinimumConfiguration.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration The configuration takes effect immediately after the command completes. The above example will result in a minimal configuration of Edge Data Store. It will only support OMF and SDS operations using REST. No egress is configured, so no data will be forwarded to either OCS or PI Web API . Maximum Edge Data Store Configuration The following JSON file represents maximal configuration of an Edge Data Store. There are Modbus and Opc Ua components, and egress is configured to send to both PI Web API and OCS. If a system were configured with this JSON file. In this example both operational data (namespace = default) and diagnostic data for the system and the adapters (namespace = diagnostics). { \"Modbus1\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"DataSource\": { \"IpAddress\": \"\u003cModbus IP address\u003e\", \"Port\": 502, \"ConnectTimeout\": 15000, \"ReconnectInterval\": 5000, \"RequestTimeout\": 9000, \"DelayBetweenRequests\": 0, \"MaxResponseDataLength\": 250 }, \"DataSelection\": [{ \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 1, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 2, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 3, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 4, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 5, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 } ] }, \"Storage\": { \"Runtime\": { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\" }, \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"PeriodicEgressEndpoints\": [{ \"Id\": \"OCS\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"\u003cOCS OMF URL for your tenant and namespace\u003e\", \"ClientId\": \"\u003cOCS ClientId\u003e\", \"ClientSecret\": \"\u003cOCS ClientSecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null }, { \"Id\": \"PWA\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"https://\u003cyour \"https:  \u003cyour PI Web API server\u003e/piwebapi/omf/\", server\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null }, { \"Id\": \"OCSDiag\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"diagnostics\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"\u003cOCS OMF URL for your tenant and namespace\u003e\", \"ClientId\": \"\u003cOCS ClientId\u003e\", \"ClientSecret\": \"\u003cOCS ClientSecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null }, { \"Id\": \"PWADiag\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"diagnostics\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"https://\u003cyour \"https:  \u003cyour PI Web API server\u003e/piwebapi/omf/\", server\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null } ] }, \"OpcUa1\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"DataSource\": { \"EndpointUrl\": \"opc.tcp://\u003cOPC \"opc.tcp:  \u003cOPC UA server IP and port\u003e/OSIsoftTestServer\", port\u003e OSIsoftTestServer\", \"UseSecureConnection\": false, \"UserName\": null, \"Password\": null, \"RootNodeIds\": null, \"IncomingTimestamp\": \"Source\", \"StreamIdPrefix\": \"OpcUa\" }, \"DataSelection\": [{ \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Cold Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Cold Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.ColdSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Hot Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.HotSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.HotSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Power\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_001.Power\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Efficiency\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_001.Efficiency\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Flowrate\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_001.Flowrate\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Power\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_002.Power\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Efficiency\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_002.Efficiency\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Flowrate\", \"NodeId\": \"ns=2;s=Line1.SF_Pump_002.Flowrate\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Level\", \"NodeId\": \"ns=2;s=Line1.Tank1.Level\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Mass\", \"NodeId\": \"ns=2;s=Line1.Tank1.Mass\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Volume\", \"NodeId\": \"ns=2;s=Line1.Tank1.Volume\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Level\", \"NodeId\": \"ns=2;s=Line1.Tank2.Level\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Mass\", \"NodeId\": \"ns=2;s=Line1.Tank2.Mass\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Volume\", \"NodeId\": \"ns=2;s=Line1.Tank2.Volume\", \"StreamId\": null } ] }, \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"Components\": [{ \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"Modbus1\", \"componentType\": \"Modbus\" }, { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ], \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 } } } Please be sure to fill in any credentials or IP addresses with with appropriate values for your environment Save the edited version of the JSON above in a file named EdgeMaximumConfiguration.json in any directory. When the following curl command is run, this will be set as the configuration of a running Edge Data Store (the command should be run from the same directory where the file is located): curl -i -d \"@EdgeMaximumConfiguration.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration The configuration takes effect immediately after the command completes. Full JSON definition of configuration parameters: Edge Data Store Configuration"
                                                      },
    "V1/Administration/ManagementTools.html":  {
                                                   "href":  "V1/Administration/ManagementTools.html",
                                                   "title":  "Edge Data Store management tools",
                                                   "keywords":  "Edge Data Store management tools Command Line Configuration The edgecmd utility on both Linux and Windows can be used to configure and manage Edge Data Store. REST tools The following tools are available to facilitate the execution of REST calls. cURL Edge Data Store documentation displays cURL commands for configuration and management examples. cURL is a command line tool supported on Windows and Linux, used to make HTTP calls. cURL is a versatile tool with a large range of capabilities: any Edge Data Store administrative or programming task can be accomplished with cURL. cURL is also easily scripted, using BASH or Powershell on either Linux or Windows, and is the recommended tool for managing Edge Data Store. Any system that can run Edge Data Store supports cURL. Postman Postman is a very popular and effective REST tool for systems with Graphical UI components (Edge Data Store is supported on platforms that lack this capability). It is particularly useful for learning more about Edge Data Store REST APIs. C#, Python, Go Any modern programming language can also be used to make REST calls to administer and write programs for Edge Data Store. Since the administrative and programming interfaces are unified in using REST, it is possible to write applications that both manage Edge Data Store and read and write data. The Diagnostics namespace, for example, can be accessed locally to monitor and act upon the local system state if desired. System Tools Many OSIsoft customers use Windows computers, even though they may deploy Linux devices to host Edge Storage. Edge Data Store can be installed on Windows 10, and the same custom applications developed on Windows should work on Linux, as long as the application development environment is supported on Linux. Edge Data Store has been designed to use platform independent programming. To facilitate working with Linux devices, Windows tools like PuTTY and WinSCP are very useful for copying files and remotely accessing Linux command lines."
                                               },
    "V1/Administration/LoggingConfiguration.html":  {
                                                        "href":  "V1/Administration/LoggingConfiguration.html",
                                                        "title":  "Edge Data Store logging",
                                                        "keywords":  "Edge Data Store logging Logging is used for diagnosing deployment or production issues, and it can be set dynamically without restarting the system. Edge Data Store logging configuration Edge Data Store and all loaded components provide the ability to configure logging at the component level. The following is an example logging configuration: { \"LogLevel\": \"Information\", \"LogFileSizeLimitBytes\": 34636833, \"LogFileCountLimit\": 31 }"
                                                    },
    "V1/Administration/Administration.html":  {
                                                  "href":  "V1/Administration/Administration.html",
                                                  "title":  "Edge Data Store administration",
                                                  "keywords":  "Edge Data Store administration The Edge Data Store provides a number of administration level functions. Reset Edge Data Store Edge Data Store provides a method of performing a complete reset of the product. When you perform a reset, all event data and Edge Data Store configuration is deleted, and the product is restarted. Note: All configuration and stored data will be lost as a result of performing this action. To reset the Edge Data Store, use any REST client and make a request using one of the following: Method: POST Endpoint: http://localhost:5590/api/v1/administration/System/Reset http:  localhost:5590 api v1 administration System Reset Header: Content-Type application/json application json Example using cURL: curl -v -d \"\" -X POST http://localhost:5590/api/v1/Administration/System/Reset http:  localhost:5590 api v1 Administration System Reset An HTTP status 204 message indicates success. Reset the Edge Storage Component Edge Data Store provides a method by which a user may delete and reset all event and configuration data related to the Edge Data Store component, after which the product will be restarted. To reset the Storage component, use any REST client and make a request using one of the following: Method: POST Endpoint: http://localhost:5590/api/v1/administration/Storage/Reset http:  localhost:5590 api v1 administration Storage Reset Header: Content-Type application/json application json Example using cURL: curl -v -d \"\" -X POST http://localhost:5590/api/v1/Administration/Storage/Reset http:  localhost:5590 api v1 Administration Storage Reset An HTTP status 204 message indicates success. Stop and Start an Edge Data Store EDS adapter Edge Data Store provides the ability to stop and start EDS adapters. By default, when Edge Data Store starts, all currently configured EDS adapters are started and remain running until the product shuts down. Stop a EDS adapter To stop an individual EDS adapter, use any REST client and make a request using one of the following: Method: POST Endpoint: http://localhost:5590/api/v1/administration/EDS http:  localhost:5590 api v1 administration EDS adapterId/Stop adapterId Stop Header: Content-Type application/json application json Example using cURL: curl -v -d \"\" -X POST http://localhost:5590/api/v1/Administration/EDS http:  localhost:5590 api v1 Administration EDS adapterId/Stop adapterId Stop Note: Replace EDS adapterId with the id of the EDS adapter you wish to stop. An HTTP status 204 message indicates success. Start a EDS adapter Adapter To start an individual EDS adapter, use any REST client and make a request using the following: Method: POST Endpoint: http://localhost:5590/api/v1/administration/EDS http:  localhost:5590 api v1 administration EDS adapterId/Start adapterId Start Header: Content-Type application/json application json Example using cURL: curl -v -d \"\" -X POST http://localhost:5590/api/v1/Administration/EDS http:  localhost:5590 api v1 Administration EDS adapterId/Start adapterId Start Note: Replace EDS adapterId with the id of the EDS adapter you wish to start. An HTTP status 204 message indicates success."
                                              },
    "docfx.console.2.43.2/content/index.html":  {
                                                    "href":  "docfx.console.2.43.2/content/index.html",
                                                    "title":  "This is the HOMEPAGE.",
                                                    "keywords":  "This is the HOMEPAGE . Refer to Markdown for how to write markdown files. Quick Start Notes: Add images to images folder if the file is referencing an image."
                                                },
    "docfx.console.2.43.2/content/api/index.html":  {
                                                        "href":  "docfx.console.2.43.2/content/api/index.html",
                                                        "title":  "PLACEHOLDER",
                                                        "keywords":  "PLACEHOLDER TODO: Add .NET projects to src folder and run docfx to generate a REAL API Documentation !"
                                                    },
    "V1/Security/SecurityOverview.html":  {
                                              "href":  "V1/Security/SecurityOverview.html",
                                              "title":  "Edge Data Store security overview",
                                              "keywords":  "Edge Data Store security overview EDS adapter REST APIs Edge Data Store supports REST APIs for configuration, data reading (through SDS), and data writing (through OMF and SDS). Edge Data Store is built to provide only localhost access to REST APIs. Any code that reads or writes to the REST APIs must reside on the computer or device that the Edge Data Store is running on. REST access is through HTTP. The default port is 5590. The port number can be changed during installation or during configuration after installation. URLs must be of the form \"http://localhost:{port}/\" \"http:  localhost:{port} \" or \"http://127.0.0.1:{port}/\". \"http:  127.0.0.1:{port} \". Note: Do not use the host\u0027s name or IP Address in the URL. Note for Docker users: You must use the \"host\" networking mode for the container. For an example of running a container using this mode, see the section pertaining to Docker containers . Data egress Writing data to OSIsoft Cloud Services or OSIsoft PI Web API is not limited to the local machine and data can be written to either of these destinations using HTTPS. Adapters Modbus and Opc Ua are not limited to the local machine. Both are enabled to access remote data sources through binary protocols. Secure storage Sensitive information, such as passwords and client secrets, are saved in configuration files in an encrypted form. Only the Edge Data Store runtime can properly store and retrieve these protected data items. Note: Do not manually edit configuration files. Altering encrypted values will cause failures. The only time unencrypted values for sensitive information are available is when you provide them to the system through the REST API, for example for initial configuration or update. From that point forward, the unencrypted values are not available, neither in the configuration files nor through the REST API. The REST API will only return a placeholder string (for example \"****\") for such values. You should take care when you submit sensitive data items, for example, you should remove a temporary file, used to submit configuration to the REST API containing unencrypted credentials, from the system. Service and file system security The installer creates a specific user account that the Edge Data Store service runs under. You can only use this account for running the service, for example you can not use it for interactive sessions and so on. Typically, you can not configure this service account. Modifying the service configuration in this respect could cause system failure. The Edge Data Store binary files, configuration files, and data files are configured by the installer and runtime to allow appropriate access by the service account. Normally, you do not need to modify the permission and ownership assignments for these files, and should not as failures could occur."
                                          },
    "V1/SDS/Writing_Data_API.html":  {
                                         "href":  "V1/SDS/Writing_Data_API.html",
                                         "title":  "API calls for writing data",
                                         "keywords":  "API calls for writing data Example type, stream, and data Many of the following API methods descriptions following contain example requests and responses in JSON to highlight usage and specific behaviors. The following type, stream, and data are used in the examples: Example type SimpleType is an SdsType with a single index and two additional properties. This type is defined in Python and Javascript: Python class State(Enum): Ok = 0 Warning = 1 Alarm = 2 class SimpleType(object): Time = property(getTime, setTime) def getTime(self): return self.__time def setTime(self, time): self.__time = time State = property(getState, setState) def getState(self): return self.__state def setState(self, state): self.__state = state Measurement = property(getValue, setValue) def getValue(self): return self.__measurement def setValue(self, measurement): self.__measurement = measurement JavaScript var State = { Ok: 0, Warning: 1, Alarm: 2, } var SimpleType = function () { this.Time = null; this.State = null; this.Value = null; } Example Stream Simple is an SdsStream of type SimpleType . Example Data Simple has stored values as follows: 11/23/2017 11 23 2017 12:00:00 PM: Ok 0 11/23/2017 11 23 2017 1:00:00 PM: Ok 10 11/23/2017 11 23 2017 2:00:00 PM: Ok 20 11/23/2017 11 23 2017 3:00:00 PM: Ok 30 11/23/2017 11 23 2017 4:00:00 PM: Ok 40 All times are represented at offset 0, GMT. Insert Values Inserts data into the specified stream. Returns an error if data is already present at the index of any event. Request POST api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Parameters string namespaceId default or diagnostics string streamId The stream identifier Request Body A serialized list of one or more events of the stream type Response The response includes a status code Note: This request will return an error if an event already exists for any index in the request. If any individual index encounters a problem, the entire operation is rolled back and no insertions are made. The streamId and index that caused the issue are included in the error response. Example The following request is used to insert events into stream Simple of SimpleType , POST api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data The request body specifies the values to insert: [ { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 50 }, { \"Time\": \"2017-11-23T18:00:00Z\", \"State\": 0, \"Measurement\": 60 } ] Patch Values Modifies the specified stream event(s). Patching affects only the data item parameters that are included in the call. Request PATCH api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?select={selectExpression} Parameters string namespaceId default or diagnostics string streamId The stream identifier string selectExpression Comma-separated list of strings that indicates the event fields to be changed in stream events Request Body A serialized collection of one or more patch property events Response The response includes a status code Consider you have a stream Simple of SimpleType , to change one property, Measurement , for one event specify the following request PATCH api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?select=measurement With the following request body, [ { \"Time\":\"2017-11-23T12:00:00Z\", \"Measurement\":500.0 } ] This request will only change the Measurement value at the specified event index. Note: Patching is used to patch the events of the selected fields for one or more events in the stream. Only the fields indicated in selectExpression are modified. The events to be modified are indicated by the index value of each entry in the collection. If there is a problem patching any individual event, the entire operation is rolled back and the error will indicate the streamId and index of the problem. Remove Values There are two options for specifying which events to remove from a stream: Index Collection : One or more indexes can be specified in the request. Window : A window can be specified with a start index and end index. Index Collection Removes the event at each index from the specified stream. Different overloads are available to make it easier to indicate the index where you want to remove a data event. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?index={index}[\u0026index={index}???] Parameters string namespaceId default or diagnostics string streamId The stream identifier string index One or more indexes of events to remove Response The response includes a status code Note: If any individual event fails to be removed, the entire operation is rolled back and no events are removed. The streamId and index that caused the issue are included in the error response. If you attempt to remove events at indexes that have no events, an error is returned. If this occurs, you can use Window request format to remove any events from a specified ???window??? of indexes, which will not return an error if no data is found. Window Removes events at and between the start index and end index. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?startIndex={startIndex}\u0026endIndex={endIndex} Parameters string namespaceId default or diagnostics string streamId The stream identifier string startIndex The index defining the beginning of the window string endIndex The index defining the end of the window Response The response includes a status code Note: If any individual event fails to be removed, the entire operation is rolled back and no removes are done. Replace Values Writes one or more events over existing events in the specified stream. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?allowCreate=false Parameters string namespaceId default or diagnostics string streamId The stream identifier Request Body A serialized list of one or more events of the stream type Response The response includes a status code Note: This request returns an error if the stream does not have an event to be replaced at the specified index. If any individual event fails to be replaced, the entire operation is rolled back and no replaces are performed. The index that caused the issue and the streamId are included in the error response. Update Values Writes one or more events to the specified stream. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Parameters string namespaceId default or diagnostics string streamId The stream identifier Request Body A serialized list of one or more events of the stream type Response The response includes a status code Note: This request performs an insert or a replace depending on whether an event already exists at the event indexes. If any item fails to write, the entire operation is rolled back and no events are written to the stream. The index that caused the issue is included in the error response."
                                     },
    "V1/SDS/Writing_Data.html":  {
                                     "href":  "V1/SDS/Writing_Data.html",
                                     "title":  "Write data",
                                     "keywords":  "Write data The SDS REST APIs provide programmatic access to read and write SDS data. This topic describes the APIs used to write SdsStream data. All writes rely on a stream???s key or primary index. The primary index determines the order of events in the stream. Secondary indexes are updated, but they do not contribute to the request. All references to indexes are to the primary index. Single stream writes The following support writing multiple values: Insert Values inserts a collection of events. Patch Values updates specific fields for a collection of events. Replace Values replaces a collection of events. Remove Values deletes the events based on the request parameters. Update Values add or replaces a collection of events. The base URI for writing SDS data to a single stream is: api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Parameters string namespaceId default or diagnostics string streamId The stream identifier Request body format With the exception of Remove Values, all single stream write calls require a request body containing the events to insert or modify. The events must be formatted as a serialized JSON array of the stream\u0027s type. JSON arrays are comma-delimited lists of a type enclosed within square brackets. The following code shows a list of three WaveData events that are properly formatted for insertion. For the complete example, see the OCS-Samples . [ { \"Order\":2, \"Tau\":0.25722883666666846, \"Radians\":1.6162164471269089, \"Sin\":1.9979373673043652, \"Cos\":-0.090809010174665111, \"Tan\":-44.003064529862513, \"Sinh\":4.8353589272389, \"Cosh\":5.2326566823391856, \"Tanh\":1.8481468289554672 }, { \"Order\":4, \"Tau\":0.25724560000002383, \"Radians\":1.6163217742567466, \"Sin\":1.9979277915696148, \"Cos\":-0.091019446679060964, \"Tan\":-43.901119254534827, \"Sinh\":4.8359100947709592, \"Cosh\":5.233166005842703, \"Tanh\":1.8481776000882766 }, { \"Order\":6, \"Tau\":0.25724560000002383, \"Radians\":1.6163217742567466, \"Sin\":1.9979277915696148, \"Cos\":-0.091019446679060964, \"Tan\":-43.901119254534827, \"Sinh\":4.8359100947709592, \"Cosh\":5.233166005842703, \"Tanh\":1.8481776000882766 } ] You can serialize your data using one of many available JSON serializers available at Introducing JSON . Response format Supported response formats include JSON, verbose JSON, and SDS. The default response format for SDS is JSON, which is used in all examples in this documentation. Default JSON responses do not include any values that are equal to the default value for their type. Verbose JSON responses include all values in the returned JSON payload, including defaults. To specify verbose JSON return, add the header Accept-Verbosity with a value of verbose to the request. Verbose has no impact on writes; writes return only error messages. To specify SDS format, set the Accept header in the request to application/sds application sds . Indexes SDS writes rely on the primary index for positioning within streams and locating existing events. Most writes use the index as specified by the value. Deletes are the exception to this rule. When deleting, indexes are specified as strings in the URI. For more details about working with indexes, see the Indexes page. To specify compound indexes in the URI, specify each field that composes the index, in the specified order, separated by the pipe character, ???|???."
                                 },
    "V1/SDS/Units_of_Measure.html":  {
                                         "href":  "V1/SDS/Units_of_Measure.html",
                                         "title":  "Units of measure",
                                         "keywords":  "Units of measure The Sequential Data Store (SDS) provides a collection of built-in units of measure (Uom). These units of measure can be associated with SdsStreams and SdsTypes in order to provide unit information for stream data that model measurable quantities. If data has unit information associated with it, SDS is able to support unit conversions when retrieving data. For more information, see Reading data . Since a unit of measurement (that is meter) defines the magnitude of a quantity (that is Length), SDS represents this through two objects: SdsUom and SdsUomQuantity. SdsUom A SdsUom represents a single unit of measure, such as \u0027meter\u0027. The following table shows the required and optional SdsUom fields. Property Type Optionality Description Example Id String Required Unique identifier for the unit of measure meters per second Abbreviation String Optional Abbreviation for the unit of measure m/s m s Name String Optional Full name for the unit of measure Meters per second DisplayName String Optional Friendly display name for the unit of measure meters per second QuantityId String Required The identifier associated with the quantity that this unit is a measure of Velocity ConversionFactor Double Required Used for unit conversions. When a value of this unit is multiplied by the ConversionFactor and then incremented by the ConversionOffset, the value in terms of the base unit of the corresponding quantity is returned. 1.0 ConversionOffset Double Required Used for unit conversions. See details for ConversionFactor 0.0 SdsUomQuantity Represents a single measurable quantity (i.e. Length) The following table shows the required and optional SdsUomQuantity fields. Property Type Optionality Description Example Id String Required Unique identifier for the quantity Velocity Name String Optional Full name for the quantity Velocity BaseUom SdsUom Required The base unit of measure for this quantity. All other Uom\u0027s measuring this quantity will have ConversionFactor\u0027s and ConversionOffsets relative to the BaseUom SdsUom representing \"meters per second\" Dimensions short[] Optional Reserved for internal use. Represents the seven base SI dimensions: Length, Mass, Time, Electric Current, Thermodynamic Temperature, Amount of Substance, and Luminous Density. [1,0,-1,0,0,0,0] Supported Quantities A list of the supported quantities and their base unit of measures is below. Supported quantities are read-only. Quantity Id Base Uom Id Angular Velocity radian per second Area square meter Computer Storage byte Density kilogram per cubic meter Dynamic Viscosity pascal second Electric Charge coulomb Electric Current ampere Electric Potential volt Electric Resistance ohm Energy joule Entropy and Heat Capacity joule per kelvin Force newton Frequency hertz Length meter Luminous Intensity candela Mass kilogram Mass Flow Rate kilogram per second Molar Flow Rate mole per second Molecular Weight kilogram per mole Amount of Substance mole Plane Angle radian Power watt Pressure pascal Quantity count Ratio percent Specific Energy joule per kilogram Specific Entropy and Specific Heat Capacity joule per kilogram kelvin Specific Volume cubic meter per kilogram Speed meter per second Temperature kelvin Temperature (Delta) delta kelvin Time second Volume cubic meter Volume Flow Rate cubic meter per second Supported Units of Measure A list of the supported units of measure is below. Supported units of measure are read-only. Uom Id Abbreviation Quantity Id Conversion Factor Conversion Offset count count Quantity 1 0 Ampere hour Ah Electric Charge 3600 0 coulomb C Electric Charge 1 0 kilogram per second kg/s kg s Mass Flow Rate 1 0 long ton per day lton/d lton d Mass Flow Rate 0.011759802 0 million pound per day MMlb/d MMlb d Mass Flow Rate 5.24991169 0 short ton per day ston/d ston d Mass Flow Rate 0.010499823 0 thousand pound per day klb/d klb d Mass Flow Rate 0.005249912 0 gram per second g/s g s Mass Flow Rate 0.001 0 pound per second lb/s lb s Mass Flow Rate 0.45359237 0 tonne per day t/d t d Mass Flow Rate 0.011574074 0 long ton lton Mass 1016.046909 0 million pound MM lb Mass 453592.37 0 ounce oz Mass 0.028349523 0 short ton ston Mass 907.18474 0 thousand pound klb Mass 453.59237 0 ton ton Mass 907.18474 0 gram g Mass 0.001 0 milligram mg Mass 1.00E-06 0 pound lb Mass 0.45359237 0 tonne t Mass 1000 0 kilogram kg Mass 1 0 second s Time 1 0 hour h Time 3600 0 day d Time 86400 0 month month Time 2628000 0 week week Time 604800 0 year yr Time 31536000 0 minute min Time 60 0 dyne dyne Force 1.00E-05 0 kilogram-force kgf Force 9.80665 0 pound-force lbf Force 4.448221615 0 newton N Force 1 0 watt W Power 1 0 million British thermal unit per day MM Btu/d Btu d Power 12211.29459 0 million British thermal unit per hour MM Btu/h Btu h Power 293071.0702 0 gigawatt GW Power 1000000000 0 megawatt MW Power 1000000 0 British thermal unit per hour Btu/h Btu h Power 0.29307107 0 calorie per second cal/s cal s Power 4.1868 0 horsepower hp Power 745.6998716 0 joule per second J/s J s Power 1 0 kilowatt kW Power 1000 0 megajoule per hour MJ/h MJ h Power 277.7777778 0 million calorie per hour MMcal/h MMcal h Power 1163 0 mole per second mol/s mol s Molar Flow Rate 1 0 gram mole per second gmol/s gmol s Molar Flow Rate 1 0 kilogram mole per second kmol/s kmol s Molar Flow Rate 1000 0 pound mole per second lbmol/s lbmol s Molar Flow Rate 453.59237 0 meter m Length 1 0 centimeter cm Length 0.01 0 inch in Length 0.0254 0 International nautical mile nmi Length 1852 0 kilometer km Length 1000 0 millimeter mm Length 0.001 0 foot ft Length 0.3048 0 mile mi Length 1609.344 0 sixteenth of an inch sxi Length 0.0015875 0 yard yd Length 0.9144 0 candela cd Luminous Intensity 1 0 meter per second m/s m s Speed 1 0 centimeter per second cm/s cm s Speed 0.01 0 foot per second ft/s ft s Speed 0.3048 0 International nautical mile per hour nmi/h nmi h Speed 0.514444444 0 kilometer per hour km/h km h Speed 0.277777778 0 mile per hour mi/h mi h Speed 0.44704 0 revolution per minute rpm Angular Velocity 0.104719755 0 radian per second rad/s rad s Angular Velocity 1 0 barrel per day bbl/d bbl d Volume Flow Rate 1.84E-06 0 cubic centimeter per second cm3/s cm3 s Volume Flow Rate 1.00E-06 0 cubic foot per second ft3/s ft3 s Volume Flow Rate 0.028316847 0 cubic meter per hour m3/h m3 h Volume Flow Rate 0.000277778 0 Imperial gallon per minute Imp gal/min gal min Volume Flow Rate 7.58E-05 0 liter per second L/s L s Volume Flow Rate 0.001 0 US gallon per minute US gal/min gal min Volume Flow Rate 6.31E-05 0 cubic meter per second m3/s m3 s Volume Flow Rate 1 0 pascal Pa Pressure 1 0 atmosphere atm Pressure 101325 0 bar bar Pressure 100000 0 inches of mercury inHg Pressure 3386.388158 0 kilogram-force per square centimeter kgf/cm2 kgf cm2 Pressure 98066.5 0 kilogram-force per square meter kgf/m2 kgf m2 Pressure 9.80665 0 kilopascal kPa Pressure 1000 0 millimeter of mercury mmHg Pressure 133.3223684 0 newton per square meter N/m2 N m2 Pressure 1 0 pound-force per square inch psi Pressure 6894.757293 0 pound-force per square inch (customary) psia Pressure 6894.757293 0 torr torr Pressure 133.3223684 0 square meter m2 Area 1 0 square foot ft2 Area 0.09290304 0 acre acre Area 4046.856422 0 square mile mi2 Area 2589988.11 0 square yard yd2 Area 0.83612736 0 hectare ha Area 10000 0 square centimeter cm2 Area 0.0001 0 square inch in2 Area 0.00064516 0 square kilometer km2 Area 1000000 0 square millimeter mm2 Area 1.00E-06 0 yobibyte YiB Computer Storage 1.21E+24 0 zebibyte ZiB Computer Storage 1.18E+21 0 exbibyte EiB Computer Storage 1.15E+18 0 pebibyte PiB Computer Storage 1.13E+15 0 tebibyte TiB Computer Storage 1.10E+12 0 gibibyte GiB Computer Storage 1073741824 0 mebibyte MiB Computer Storage 1048576 0 kibibyte KiB Computer Storage 1024 0 yottabyte YB Computer Storage 1.00E+24 0 zettabyte ZB Computer Storage 1.00E+21 0 exabyte EB Computer Storage 1.00E+18 0 petabyte PB Computer Storage 1.00E+15 0 terabyte TB Computer Storage 1.00E+12 0 gigabyte GB Computer Storage 1000000000 0 megabyte MB Computer Storage 1000000 0 kilobyte kB Computer Storage 1000 0 byte B Computer Storage 1 0 kelvin K Temperature 1 0 degree Celsius ??C Temperature 1 273.15 degree Rankine ??R Temperature 0.555555556 -2.56E-13 degree Fahrenheit ??F Temperature 0.555555556 255.3722222 milliampere mA Electric Current 0.001 0 ampere A Electric Current 1 0 joule per gram J/g J g Specific Energy 1000 0 joule per kilogram J/kg J kg Specific Energy 1 0 British thermal unit per pound Btu/lb Btu lb Specific Energy 2326 0 kilocalorie per kilogram kcal/kg kcal kg Specific Energy 4186.8 0 kilojoule per kilogram kJ/kg kJ kg Specific Energy 1000 0 kilojoule per pound kJ/lb kJ lb Specific Energy 2204.622622 0 British thermal unit per degree Rankine Btu/??R Btu ??R Entropy and Heat Capacity 1899.100535 0 British thermal unit per degree Fahrenheit Btu/??F Btu ??F Entropy and Heat Capacity 1899.100535 0 kilojoule per kelvin kJ/K kJ K Entropy and Heat Capacity 1000 0 joule per kelvin J/K J K Entropy and Heat Capacity 1 0 cubic foot per pound ft3/lb ft3 lb Specific Volume 0.062427961 0 cubic centimeter per gram cm3/g cm3 g Specific Volume 0.001 0 cubic meter per kilogram m3/kg m3 kg Specific Volume 1 0 hertz Hz Frequency 1 0 mole mol Amount of Substance 1 0 gram mole gmol Amount of Substance 1 0 kilogram mole kmol Amount of Substance 1000 0 pound mole lbmol Amount of Substance 453.59237 0 percent % Ratio 1 0 parts per billion ppb Ratio 1.00E-07 0 parts per million ppm Ratio 0.0001 0 ohm ?? Electric Resistance 1 0 gram per gram mole g/gmol g gmol Molecular Weight 0.001 0 pound per pound mole lb/lbmol lb lbmol Molecular Weight 0.001 0 kilogram per mole kg/mol kg mol Molecular Weight 1 0 kilogram per kilogram mole kg/kmol kg kmol Molecular Weight 0.001 0 British thermal unit per pound degree Rankine Btu/(lb Btu (lb ??R) Specific Entropy and Specific Heat Capacity 4186.8 0 British thermal unit per pound degree Fahrenheit Btu/(lb Btu (lb ??F) Specific Entropy and Specific Heat Capacity 4186.8 0 joule per gram kelvin J/(g J (g K) Specific Entropy and Specific Heat Capacity 1000 0 kilojoule per kilogram kelvin kJ/(kg kJ (kg K) Specific Entropy and Specific Heat Capacity 1000 0 joule per kilogram kelvin J/(kg J (kg K) Specific Entropy and Specific Heat Capacity 1 0 kilovolt kV Electric Potential 1000 0 millivolt mV Electric Potential 0.001 0 megavolt MV Electric Potential 1000000 0 volt V Electric Potential 1 0 joule J Energy 1 0 gigawatt hour GWh Energy 3.60E+12 0 megawatt hour MWh Energy 3600000000 0 watt hour Wh Energy 3600 0 British thermal unit Btu Energy 1055.055853 0 calorie cal Energy 4.1868 0 gigajoule GJ Energy 1000000000 0 kilojoule kJ Energy 1000 0 kilowatt hour kWh Energy 3600000 0 megajoule MJ Energy 1000000 0 watt second Ws Energy 1 0 kilocalorie kcal Energy 4186.8 0 million calorie MMcal Energy 4186800 0 million British thermal unit MM Btu Energy 1055055853 0 acre foot acre ft Volume 1233.481838 0 million imperial gallon Imp Mgal Volume 4546.09 0 thousand imperial gallon Imp kgal Volume 4.54609 0 barrel bbl Volume 0.158987295 0 Imperial gallon Imp gal Volume 0.00454609 0 million US gallon US Mgal Volume 3785.411784 0 thousand US gallon US kgal Volume 3.785411784 0 cubic centimeter cm3 Volume 1.00E-06 0 cubic foot ft3 Volume 0.028316847 0 kiloliter kL Volume 1 0 liter L Volume 0.001 0 megaliter M L Volume 1000 0 milliliter mL Volume 1.00E-06 0 thousand cubic meter k m3 Volume 1000 0 US gallon US gal Volume 0.003785412 0 million barrel MMbbl Volume 158987.2949 0 thousand barrel kbbl Volume 158.9872949 0 cubic meter m3 Volume 1 0 kilogram per cubic meter kg/m3 kg m3 Density 1 0 gram per liter g/L g L Density 1 0 kilogram per liter kg/L kg L Density 1000 0 pound per barrel lb/bbl lb bbl Density 2.853010174 0 pound per cubic foot lb/ft3 lb ft3 Density 16.01846337 0 pound per US gallon lb/US lb US gal Density 119.8264273 0 tonne per cubic meter t/m3 t m3 Density 1000 0 radian rad Plane Angle 1 0 degree ?? Plane Angle 0.017453293 0 revolution r Plane Angle 6.283185307 0 pascal second Pa*s Dynamic Viscosity 1 0 poise P Dynamic Viscosity 0.1 0 delta degree Fahrenheit delta ??F Temperature (Delta) 0.555555556 0 delta degree Rankine delta ??R Temperature (Delta) 0.555555556 0 delta kelvin delta K Temperature (Delta) 1 0 delta degree Celsius delta ??C Temperature (Delta) 1 0 SdsUomQuantity API The REST APIs provide programmatic access to read and write SDS data. The APIs in this section interact with SdsUomQuantitys. For general SdsUomQuantity information, see Units of Measure . Get Quantity Returns the quantity corresponding to the specified quantityId within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Quantities/{quantityId} api v1 Tenants default Namespaces {namespaceId} Quantities {quantityId} Parameters string namespaceId default or diagnostics string quantityId The quantity identifier Response The response includes a status code and a response body. Response body The requested SdsUomQuantity. Example response body for quantityId = \"Length\": HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\": \"Length\", \"Name\": \"Length\", \"BaseUom\": { \"Id\": \"meter\", \"Abbreviation\": \"m\", \"Name\": \"meter\", \"DisplayName\": \"meter\", \"QuantityId\": \"Length\", \"ConversionFactor\": 1 }, \"Dimensions\": [ 1, 0, 0, 0, 0, 0, 0 ] } Get Quantities Returns a list of all quantities available within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Quantities?skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} Quantities?skip={skip}\u0026count={count} Parameters string namespaceId default or diagnostics int skip An optional parameter representing the zero-based offset of the first SdsUomQuantity to retrieve. If not specified, a default value of 0 is used. int count An optional parameter representing the maximum number of SdsUomQuantity to retrieve. If not specified, a default value of 100 is used. Response The response includes a status code and a response body. Response body A list of SdsUomQuantity objects Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\": \"Angular Velocity\", \"Name\": \"Angular Velocity\", \"BaseUom\": { \"Id\": \"radian per second\", \"Abbreviation\": \"rad/s\", \"rad s\", \"Name\": \"radian per second\", \"DisplayName\": \"radian per second\", \"QuantityId\": \"Angular Velocity\", \"ConversionFactor\": 1 }, \"Dimensions\": [ 0, 0, -1, 0, 0, 0, 0 ] }, { \"Id\": \"Area\", \"Name\": \"Area\", \"BaseUom\": { \"Id\": \"square meter\", \"Abbreviation\": \"m2\", \"Name\": \"square meter\", \"DisplayName\": \"square meter\", \"QuantityId\": \"Area\", \"ConversionFactor\": 1 }, \"Dimensions\": [ 2, 0, 0, 0, 0, 0, 0 ] }, ] Get Quantity Uom Returns the unit of measure associated with the specified uomId belonging to the quantity with the specified quantityId. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Quantities/{quantityId}/Units/{uomId} api v1 Tenants default Namespaces {namespaceId} Quantities {quantityId} Units {uomId} Parameters string namespaceId default or diagnostics string quantityId The quantity identifier string uomId The unit of measure identifier Response The response includes a status code and a response body. Response body The requested SdsUom Example response for quantityId = \"Length\" and uomId =\"mile\": HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\": \"mile\", \"Abbreviation\": \"mi\", \"Name\": \"mile\", \"DisplayName\": \"mile\", \"QuantityId\": \"Length\", \"ConversionFactor\": 1609.344 } Get Quantity Uoms Returns the list of units of measure that belongs to the quantity with the specified quantityId. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Quantities/{quantityId}/Units api v1 Tenants default Namespaces {namespaceId} Quantities {quantityId} Units Parameters string namespaceId default or diagnostics string quantityId The quantity identifier Response The response includes a status code and a response body. Response body A collection of SdsUom objects for the specified quantity Example response for quantityId = \"Electric Current\": HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\": \"milliampere\", \"Abbreviation\": \"mA\", \"Name\": \"milliampere\", \"DisplayName\": \"milliampere\", \"QuantityId\": \"Electric Current\", \"ConversionFactor\": 0.001 }, { \"Id\": \"ampere\", \"Abbreviation\": \"A\", \"Name\": \"ampere\", \"DisplayName\": \"ampere\", \"QuantityId\": \"Electric Current\", \"ConversionFactor\": 1 } ] SdsUom API The REST APIs provide programmatic access to read and write SDS data. The APIs in this section interact with SdsUoms. For general SdsUom information, see Units of Measure . Get Uom Returns the unit of measure corresponding to the specified uomId within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Units/{uomId} api v1 Tenants default Namespaces {namespaceId} Units {uomId} Parameters string namespaceId default or diagnostics string uomId The unit of measure identifier Response The response includes a status code and a response body. Response body The requested SdsUom Example response body for uomId = \"ounce\": HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\": \"ounce\", \"Abbreviation\": \"oz\", \"Name\": \"ounce\", \"DisplayName\": \"ounce\", \"QuantityId\": \"Mass\", \"ConversionFactor\": 0.028349523 } Get Uoms Returns a list of all available units of measure in the system. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Units?skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} Units?skip={skip}\u0026count={count} Parameters string namespaceId default or diagnostics int skip An optional parameter representing the zero-based offset of the first SdsUomQuantity to retrieve. If not specified, a default value of 0 is used. int count An optional parameter representing the maximum number of SdsUomQuantity to retrieve. If not specified, a default value of 100 is used. Response The response includes a status code and a response body. Response body A list of SdsUom objects Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\": \"count\", \"Abbreviation\": \"count\", \"Name\": \"count\", \"DisplayName\": \"count\", \"QuantityId\": \"Quantity\", \"ConversionFactor\": 1 }, { \"Id\": \"Ampere hour\", \"Abbreviation\": \"Ah\", \"Name\": \"Ampere hour\", \"DisplayName\": \"Ampere hour\", \"QuantityId\": \"Electric Charge\", \"ConversionFactor\": 3600 }, { \"Id\": \"coulomb\", \"Abbreviation\": \"C\", \"Name\": \"coulomb\", \"DisplayName\": \"coulomb\", \"QuantityId\": \"Electric Charge\", \"ConversionFactor\": 1 } ] Associate a unit of measure with an SdsType At SdsType creation, you can associate an SdsUom with a SdsTypeProperty . Associate a unit of measure with an SdsStream At SdsStream creation, you can override any unit of measure associated with an SdsTypeProperty belonging to the SdsType of the stream. This enables the reuse of an SdsType that may have default unit information associated with it already."
                                     },
    "V1/SDS/table_format.html":  {
                                     "href":  "V1/SDS/table_format.html",
                                     "title":  "Table format",
                                     "keywords":  "Table format A table is a convenient structure for analytics and display. The REST APIs for retrieving multiple events from the data store supports returning results in a table. You can set the form variable to specify a table or a table with headers. You can apply table format to any read that returns multiple values and summaries. The following is a request to retrieve values using the window parameters: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-04-01T07:00:00Z\u0026endIndex=2017-04-01T07:10:00Z The following response would be returned from the above code: Content-Type: application/json application json [ { \"Time\":\"2017-04-01T07:00:00Z\", \"State\":1 }, { \"Time\":\"2017-04-01T07:01:00Z\", \"State\":1, \"Measurement\":1.0 }, { \"Time\":\"2017-04-01T07:02:00Z\", \"State\":1, \"Measurement\":2.0 }, { \"Time\":\"2017-04-01T07:03:00Z\", \"State\":1, \"Measurement\":3.0 }, { \"Time\":\"2017-04-01T07:04:00Z\", \"State\":1, \"Measurement\":4.0 }, { \"Time\":\"2017-04-01T07:05:00Z\", \"State\":1, \"Measurement\":5.0 }, { \"Time\":\"2017-04-01T07:06:00Z\", \"State\":1, \"Measurement\":6.0 }, { \"Time\":\"2017-04-01T07:07:00Z\", \"State\":1, \"Measurement\":7.0 }, { \"Time\":\"2017-04-01T07:08:00Z\", \"State\":1, \"Measurement\":8.0 }, { \"Time\":\"2017-04-01T07:09:00Z\", \"State\":1, \"Measurement\":9.0 } ] To retrieve the results in table format, add the form variable and specify table . GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-04-01T07:00:00Z\u0026endIndex=2017-04-01T07:10:00Z \u0026form=table Response Content-Type: application/json application json { \"Name\":\"Simple\", \"Columns\":[ { \"Name\":\"Time\", \"Type\":\"DateTime\" }, { \"Name\":\"State\", \"Type\":\"Int32Enum\" }, { \"Name\":\"Measurement\", \"Type\":\"Double\" } ], \"Rows\":[ [ \"2017-04-01T07:00:00Z\", 1, 0.0 ], [ \"2017-04-01T07:01:00Z\", 1, 1.0 ], [ \"2017-04-01T07:02:00Z\", 1, 2.0 ], [ \"2017-04-01T07:03:00Z\", 1, 3.0 ], [ \"2017-04-01T07:04:00Z\", 1, 4.0 ], [ \"2017-04-01T07:05:00Z\", 1, 5.0 ], [ \"2017-04-01T07:06:00Z\", 1, 6.0 ], [ \"2017-04-01T07:07:00Z\", 1, 7.0 ], [ \"2017-04-01T07:08:00Z\", 1, 8.0 ], [ \"2017-04-01T07:09:00Z\", 1, 9.0 ] ] } To retrieve the results in table format with column headers, add the form variable and specify tableh . GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-04-01T07:00:00Z\u0026endIndex=2017-04-01T07:10:00Z \u0026form=tableh Response Content-Type: application/json application json { \"Name\":\"Simple\", \"Columns\":[ { \"Name\":\"Time\", \"Type\":\"DateTime\" }, { \"Name\":\"State\", \"Type\":\"Int32Enum\" }, { \"Name\":\"Measurement\", \"Type\":\"Double\" } ], \"Rows\":[ [ \"Time\", \"State\", \"Measurement\" ], [ \"2017-04-01T07:00:00Z\", 1, 0.0 ], [ \"2017-04-01T07:01:00Z\", 1, 1.0 ], [ \"2017-04-01T07:02:00Z\", 1, 2.0 ], [ \"2017-04-01T07:03:00Z\", 1, 3.0 ], [ \"2017-04-01T07:04:00Z\", 1, 4.0 ], [ \"2017-04-01T07:05:00Z\", 1, 5.0 ], [ \"2017-04-01T07:06:00Z\", 1, 6.0 ], [ \"2017-04-01T07:07:00Z\", 1, 7.0 ], [ \"2017-04-01T07:08:00Z\", 1, 8.0 ], [ \"2017-04-01T07:09:00Z\", 1, 9.0 ] ] }"
                                 },
    "V1/SDS/SequentialDataStore.html":  {
                                            "href":  "V1/SDS/SequentialDataStore.html",
                                            "title":  "OSIsoft Sequential Data Store (SDS)",
                                            "keywords":  "OSIsoft Sequential Data Store (SDS) The Edge Data Store includes the Sequential Data Store (SDS) REST APIs for reading and writing data stored locally on the device where the Edge Data Store is running. SDS is the same technology that is used in OCS for storing data, so the usage of the REST APIs is very similar to OCS for reading and writing data. All data from all sources on the Edge Data Store (Modbus, OPC UA, OMF, SDS) can be read using the SDS REST APIs locally on the device in the default tenant and the default namespace. In addition the default tenant has a diagnostics namespace where diagnostic data are written by the Edge Data Store and installed components that can be read to monitor the health of a running system using the SDS REST APIs."
                                        },
    "V1/SDS/Searching.html":  {
                                  "href":  "V1/SDS/Searching.html",
                                  "title":  "Searching",
                                  "keywords":  "Searching Search in SDS provides a way to search text, fields, and so on across the Sequential Data Store. This topic covers the searching for SdsStreams, SdsTypes, and SdsStreamViews. Searching for Streams The search functionality for streams is exposed through the REST API. The searchable properties are below. Property Searchable Id Yes TypeId Yes Name Yes Description Yes Indexes No InterpolationMode No ExtrapolationMode No PropertyOverrides No Tags * Yes Metadata * Yes Searching for streams is possible using the REST API and specifying the optional query parameter, as shown here: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query={query}\u0026skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} Streams?query={query}\u0026skip={skip}\u0026count={count} The Stream fields valid for search are identified in the fields table located on the Streams page. Note: Stream Metadata has unique syntax rules. For more information, see How Searching Works: Stream Metadata . Searching for Types Similarly, the search functionality for types is also exposed through REST API. The query syntax and the request parameters are the same. The only difference is the resource you\u0027re searching on. You can search on different properties for types than for streams. The searchable properties are below. For more information, see Types . Property Searchable Id Yes Name Yes Description Yes SdsTypeCode No InterpolationMode No ExtrapolationMode No Properties Yes, with limitations Searching for types is also possible using the REST API and specifying the optional query parameter, as shown here: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Types?query={query}\u0026skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} Types?query={query}\u0026skip={skip}\u0026count={count} The Type fields valid for search are identified in the fields table located on the Types page. The Properties field is identified as being searchable but with limitations: Each SdsTypeProperty of a given SdsType has its Name and Id included in the Properties field. This includes nested SdsTypes of the given SdsType. Therefore, the searching of Properties will distinguish SdsTypes by their respective lists of relevant SdsTypeProperty Ids and Names. Searching for Stream Views Similarly, the search functionality for stream views is also exposed through REST API. The query syntax and the request parameters are the same. The only difference is the resource you are searching on. You can match on different properties for stream views than for streams and types. The searchable properties are below. For more information, see Stream Views . Property Searchable Id Yes Name Yes Description Yes SourceTypeId Yes TargetTypeId Yes Properties Yes, with limitations As previously mentioned, searching for stream views is also possible using the REST API and specifying the optional query parameter, as shown here: GET api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews?query={query}\u0026skip={skip}\u0026count={count} api v1 Tenants default Namespaces {namespaceId} StreamViews?query={query}\u0026skip={skip}\u0026count={count} The Stream View fields valid for search are identified in the fields table located on the Stream Views page. The Properties field is identified as being searchable with limitations because SdsStreamViewProperty objects are not searchable. Only the SdsStreamViewProperty\u0027s SdsStreamView is searchable by its Id, SourceTypeId, and TargetTypeId, which are used to return the top level SdsStreamView object when searching. This includes nested SdsStreamViewProperties. How Searching Works The query parameter will be applied across all searchable fields of objects that are searched on by default. For example, you can assume that a namespace contains the following Streams: streamId Name Description stream1 tempA The temperature from DeviceA stream2 pressureA The pressure from DeviceA stream3 calcA calculation from DeviceA values Using the stream data above, the following table shows the results of a call to get streams with different Query values: QueryString Streams returned temperature Only stream1 returned. calc* Only stream3 returned. DeviceA* All three streams returned. humidity* No streams returned. The skip and count parameters determine which items are returned when a large number of them match the query criteria. count indicates the maximum number of items returned. The maximum value of the count parameter is 1000. skip indicates the number of matched items to skip over before returning matching items. You use the skip parameter when more items match the search criteria than can be returned in a single call. The orderby parameter is supported for searching both the streams and types. The basic functionality of it is to search the items and then return the result in sorted order. The default value for orderby parameter is ascending order. You can change it to descending order by specifying desc alongside the orderby field value. It can be used in conjunction with query , skip , and count parameters. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure\u0026orderby=name GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure\u0026orderby=id asc GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure\u0026orderby=name desc GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure\u0026orderby=name desc\u0026skip=10\u0026count=20 Search operators You can specify search operators in the query string to return more specific search results. Operators Description AND AND operator. For example, cat AND dog searches for streams containing both \"cat\" and \"dog\". AND must be in all caps. OR OR operator. For example, cat OR dog searches for streams containing either \"cat\" or \"dog\" or both. OR must be in all caps. NOT NOT operator. For example, cat NOT dog searches for streams that have the \"cat\" term or do not have \"dog\". NOT must be in all caps. * Wildcard operator. For example, cat* searches for streams that have a term that starts with \"cat\", ignoring case. : Field-scoped query. For example, id:stream* will search for streams where the id field starts with \"stream\", but will not search on other fields like name or description . Note: Field names are camel case and are case sensitive. ( ) Precedence operator. For example, motel AND (wifi OR luxury) searches for streams containing the motel term and either wifi or luxury (or both). Notes regarding wildcard operator * : You can use the wildcard * only once for each search term, except for the case of a Contains type query clause. In that case, two wildcards are allowed: one as prefix and one as suffix for example, *Tank* is valid but *Ta*nk , Ta*nk* , and *Ta*nk* are currently not supported. The wildcard * only works when specifying a single search term. For example, you can search for Tank* , *Tank , Ta*nk but not Tank Meter* . : Operator You can also determine which fields are searched by using the following syntax: fieldname:fieldvalue Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=name:pump api v1 Tenants default Namespaces {namespaceId} Streams?query=name:pump name:pressure * Operator You can use the \u0027*\u0027 character as a wildcard to specify an incomplete string. Query string Matches field value Does not match field value log* log logger analog *log analog alog logg *log* analog alogger lop l*g log logg lop Supported Not Supported * *log l*g log* *log* *l*g* *l*g l*g* Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=log* api v1 Tenants default Namespaces {namespaceId} Streams?query=log* Other operators examples Query string Matches field value Does not match field value mud AND log log mud mud log mud log mud OR log log mud mud log mud AND (NOT log) mud mud log mud AND (log OR pump*) mud log mud pumps mud bath name:stream* AND (description:pressure OR description:pump) The name starts with \"stream\" and the description includes either term \"pressure\" or term \"pump\" How Searching Works: Stream Metadata Stream Metadata modifies the aforementioned search syntax rules and each operator\u0027s behavior is described below. For example, assume that a namespace contains the following Streams and the respective Metadata Key-Value pair(s) for each stream. streamId Metadata stream1 { manufacturer, company } { serial, abc } stream2 { serial, a1 } stream3 { status, active } { second key, second value } : Operator A Stream Metadata key is only searchable in association with a Stream Metadata value. This pairing is defined using the same field scoping \u0027:\u0027 operator, like myStreamMetadataKey:streamMetadataValue If the \u0027:\u0027 operator is not used within an individual search clause, Metadata Keys are not searched against.Instead, Metadata values are searched against (along with the other searchable Stream fields). QueryString Streams returned manufacturer:company Only stream1 returned. company Only stream1 returned. a* All three streams returned. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=manufacturer:company api v1 Tenants default Namespaces {namespaceId} Streams?query=manufacturer:company * Operator For searching on Metadata values, the \u0027*\u0027 character is again used as a wildcard to specify an incomplete string. Additionally, you can use this wildcard character with the Metadata key as well. This is not supported for any other \"fields\". By including a wildcard in a field (defined as a value to the immediate left of a \u0027:\u0027 operator), the query will only be valid against Stream Metadata. QueryString Streams returned manufa*turer:compan* Only stream1 returned. ser*al:a* Stream1 and stream2 are returned. s*:a* All three streams returned. Id:stream* All three streams returned. Id*:stream* Nothing returned. Note: In the final example nothing matches on a Stream\u0027s Id value because including \u0027*\u0027 in a search clause\u0027s field prevents non-Stream Metadata fields from being searched. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query=manufa*turer:compan* api v1 Tenants default Namespaces {namespaceId} Streams?query=manufa*turer:compan*"
                              },
    "V1/SDS/SDS_Views.html":  {
                                  "href":  "V1/SDS/SDS_Views.html",
                                  "title":  "Stream Views",
                                  "keywords":  "Stream Views An SdsStreamView provides a way to map Stream data requests from one data type to another. You can apply a Stream View to any read or GET operation. SdsStreamView is used to specify the mapping between source and target types. SDS attempts to determine how to map Properties from the source to the destination. When the mapping is straightforward, such as when the properties are in the same position and of the same data type, or when the properties have the same name, SDS will map the properties automatically. When SDS is unable to determine how to map a source property, the property is removed. If SDS encounters a target property that it cannot map to, the property is added and configured with a default value. To map a property that is beyond the ability of SDS to map on its own, you should define an SdsStreamViewProperty and add it to the SdsStreamView???s Properties collection. The following table shows the required and optional SdsStreamView fields. Fields that are not included are reserved for internal SDS use. For more information on search limitations, see Searching . Property Type Optionality Searchability Details Id String Required Yes Identifier for referencing the stream view Name String Optional Yes Friendly name Description String Optional Yes Description text SourceTypeId String Required Yes Identifier of the SdsType of the SdsStream TargetTypeId String Required Yes Identifier of the SdsType to convert events to Properties IList\u003cSdsStreamViewProperty\u003e Optional Yes, with limitations Property level mapping Rules for the Stream View Identifier (SdsStreamView.Id) Is not case sensitive Can contain spaces Cannot contain forward slash (\"/\") (\" \") Can contain a maximum of 100 characters Properties /   SdsStreamViewProperty The SdsStreamView Properties collection provides detailed instructions for specifying the mapping of event properties. Each SdsStreamViewProperty in the properties collection defines the mapping of an event???s property. SdsStreamView properties are required only when property mapping is not straightforward. Additionally, if you do not want a type property mapped, it is not necessary to create an SdsStreamView property for it. The following table shows the required and optional SdsStreamViewProperty fields. Property Type Optionality Details SourceId String Required Identifier of the SdsTypeProperty from the source SdsType Properties list TargetId String Required Identifier of the SdsTypeProperty from the target SdsType Properties list SdsStreamView SdsStreamView Optional Additional mapping instructions for derived types The SdsStreamView field supports nested Properties. SdsStreamViewMap When an SdsStreamView is added, SDS defines a plan mapping. Plan details are retrieved as an SdsStreamViewMap. The SdsStreamViewMap provides a detailed Property-by-Property definition of the mapping. The following table shows the SdsStreamViewMap fields. The SdsStreamViewMap cannot be written to SDS, so required and optional have no meaning. Property Type Optionality Details SourceTypeId String Required Identifier of the SdsType of the SdsStream TargetTypeId String Required Identifier of the SdsType to convert events to Properties IList\u003cSdsStreamViewMapProperty\u003e Optional Property level mapping Properties /   SdsStreamViewMapProperty The SdsStreamViewMapProperty is similar an SdsStreamViewProperty but adds a Mode detailing one or more actions taken on the property. The following table shows the SdsStreamViewMapProperty fields. The SdsStreamViewMap cannot be written; it can only be retrieved from SDS, so required and optional have no meaning. Property Type Details SourceTypeId String Identifier of the SdsType of the SdsStream TargetTypeId String Identifier of the SdsType to convert events to Mode SdsStreamViewMode Aggregate of actions applied to the properties. SdsStreamViewModes are combined via binary arithmetic SdsStreamViewMap SdsStreamViewMap Mapping for derived types The available SdsStreamViewModes are shown in the following table. Name Value Description None 0x0000 No action FieldAdd 0x0001 Add a property matching the specified SdsTypeProperty FieldRemove 0x0002 Remove the property matching the specified SdsTypeProperty FieldRename 0x0004 Rename the property matching the source SdsTypeProperty to the target SdsTypeProperty FieldMove 0x0008 Move the property from the location in the source to the location in the target FieldConversion 0x0016 Converts the source property to the target type InvalidFieldConversion 0x0032 Cannot perform the specified mapping Changing Stream Type Stream Views can be used to change the Type defining a Stream. You cannot modify the SdsType; types are immutable. But you can map a stream from its current type to a new type. To update a Stream\u0027s Type, define an SdsStreamView and PUT the stream view to the following: PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Type?streamViewId={streamViewId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Type?streamViewId={streamViewId} For details, see Update Stream Type . Working with SdsStreamViews When working with Stream Views either invoke HTTP directly or use some of the sample code. Both Python and JavaScript samples have SdsStreamView definitions. The JSON for a simple mapping between a source type with identifier Sample and a target type with identifier Sample1 would appear as follows. { \"Id\":\"StreamView\", \"Name\":\"StreamView\", \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple1\" } The SdsStreamViewMap would appear as follows. { \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple1\", \"Properties\":[ { \"SourceId\":\"Time\", \"TargetId\":\"Time\" }, { \"SourceId\":\"State\", \"TargetId\":\"State\" }, { \"SourceId\":\"Measurement\", \"TargetId\":\"Value\", \"Mode\":4 } ] } SdsStreamView API The REST APIs provide programmatic access to read and write SDS data. The APIs in this section interact with SdsStreamViews. See Stream Views for general SdsStreamView information. Get Stream View Returns the stream view corresponding to the specified streamViewId within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId} api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Parameters string namespaceId default or diagnostics string streamViewId The stream view identifier Response The response includes a status code and a response body. Response body The requested SdsStreamView. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\":\"StreamView\", \"Name\":\"StreamView\", \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple3\", \"Properties\":[ { \"SourceId\":\"Time\", \"TargetId\":\"Time\" }, { \"SourceId\":\"State\", \"TargetId\":\"State\" }, { \"SourceId\":\"Measurement\", \"TargetId\":\"Value\" } ] } Get Stream View Map Returns the stream view map corresponding to the specified streamViewId within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId}/Map api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Map Parameters string namespaceId default or diagnostics string streamViewId The stream view identifier Response The response includes a status code and a response body. Response body The requested SdsStreamView. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple3\", \"Properties\":[ { \"SourceId\":\"Time\", \"TargetId\":\"Time\" }, { \"SourceId\":\"Measurement\", \"TargetId\":\"Value\", \"Mode\":20 }, { \"SourceId\":\"State\", \"Mode\":2 }, { \"TargetId\":\"State\", \"Mode\":1 } ] } Get Stream Views Returns a list of stream views within a given namespace. If specifying the optional search query parameter, the list of stream views returned will match the search criteria. If the search query parameter is not specified, the list will include all stream views in the Namespace. See Searching for information about specifying those respective parameters. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} api v1 Tenants default Namespaces {namespaceId} StreamViews?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} Parameters string namespaceId default or diagnostics string query An optional parameter representing a string search. For information about specifying the search parameter, see Searching . int skip An optional parameter representing the zero-based offset of the first SdsStreamView to retrieve. If not specified, a default value of 0 is used. int count An optional parameter representing the maximum number of SdsStreamViews to retrieve. If not specified, a default value of 100 is used. string orderby An optional parameter representing sorted order which SdsStreamViews will be returned. A field name is required. The sorting is based on the stored values for the given field (of type string). For example, orderby=name would sort the returned results by the name values (ascending by default). Additionally, a value can be provided along with the field name to identify whether to sort ascending or descending, by using values asc or desc , respectively. For example, orderby=name desc would sort the returned results by the name values, descending. If no value is specified, there is no sorting of results. Response The response includes a status code and a response body. Response body A collection of zero or more SdsStreamViews. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\":\"StreamView\", \"Name\":\"StreamView\", \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple3\" }, { \"Id\":\"StreamViewWithProperties\", \"Name\":\"StreamViewWithProperties\", \"SourceTypeId\":\"Simple\", \"TargetTypeId\":\"Simple3\", \"Properties\":[ { \"SourceId\":\"Time\", \"TargetId\":\"Time\" }, { \"SourceId\":\"State\", \"TargetId\":\"State\" }, { \"SourceId\":\"Measurement\", \"TargetId\":\"Value\" } ] } ] Get or Create Stream View If a stream view with a matching identifier already exists, the stream view passed in is compared with the existing stream view. If the stream views are identical, a Found (302) status is returned and the stream view. If the stream views are different, the Conflict (409) error is returned. If no matching identifier is found, the specified stream view is created. Request POST api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId} api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Parameters string namespaceId default or diagnostics string streamViewId The stream view identifier. The identifier must match the SdsStreamView.Id field. Request body The request content is the serialized SdsStreamView. Response The response includes a status code and a response body. Response body The newly created or matching SdsStreamView. Create or Update Stream View Creates or updates the definition of a stream view. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId} api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Parameters string namespaceId default or diagnostics string streamViewId The stream view identifier Request body The request content is the serialized SdsStreamView. Response The response includes a status code and a response body. Response body The newly created or updated SdsStreamView. Delete Stream View Deletes a stream view from the specified tenant and namespace. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/StreamViews/{streamViewId} api v1 Tenants default Namespaces {namespaceId} StreamViews {streamViewId} Parameters string namespaceId default or diagnostics string streamViewId The stream view identifier Response The response includes a status code."
                              },
    "V1/Overview/OpcUaQuickStart.html":  {
                                             "href":  "V1/Overview/OpcUaQuickStart.html",
                                             "title":  "Edge OPC UA quick start",
                                             "keywords":  "Edge OPC UA quick start This topic is a quick tour of setting up the Edge OPC UA component. It is possible to add a single EDS OPC UA adapter during Edge Data Store installation named OpcUa1. If multiple EDS OPC UA adapters are desired, please reference Edge Data Store Configuration on how to add a new component to Edge Data Store. The example below covers configuring the adapter added during installation. If another adapter has been installed, please substitute the name of the installed adapter in the below example for OpcUa1. Configure an OPC UA data source Create a file in JSON format describing the location of the data source. Modify the following values to match your environment. { \"EndpointUrl\": \"opc.tcp://\u003cip \"opc.tcp:  \u003cip address\u003e:\u003cport - often 62541\u003e/\u003cserver 62541\u003e \u003cserver path\u003e\", \"UseSecureConnection\": false, \"UserName\": null, \"Password\": null, \"RootNodeIds\": null, \"IncomingTimestamp\": \"Source\", \"StreamIdPrefix\": \"OpcUa\" } Enter the correct IP address and port for your OPC UA data source. Save the file with the name OpcUa1Datasource.json. Run the following curl script from the same directory where the file is located. You should run the script on the same computer where the Edge Data Store is installed: curl -i -d \"@OpcUa1Datasource.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/OpcUa1/Datasource http:  localhost:5590 api v1 configuration OpcUa1 Datasource When this command completes successfully (a 204 is returned by curl), your OPC UA data source has been created. If you get a 400 error, check your JSON file for errors. If you get a 404 or 500 error, check to make sure Edge Data Store is running on your computer. Configure OPC UA data selection Select the OPC UA data you want to store in Edge Data Store by configuring OPC UA data selection. The following is a sample JSON for five OPC UA values. Modify the values as appropriate for your environment. [{ \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.HotSideOutletTemperature\", \"StreamId\": null } ] Save the JSON content above in a text file and name it OpcUa1Dataselection.json. Run the following curl script so the system will be configured to collect Opc Ua data values. curl -i -d \"@OpcUa1Dataselection.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/OpcUa1/Dataselection http:  localhost:5590 api v1 configuration OpcUa1 Dataselection To see the streams that have been created in Edge Storage to store the data you are writing, you can run the following curl script: curl http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/ http:  localhost:5590 api v1 tenants default namespaces default streams  To view the data in the streams being written, you can refer to the SDS part of this documentation. To egress the data to OSIsoft Cloud Services or the PI System, see the egress documentation or quick starts."
                                         },
    "V1/Overview/OMFQuickStart.html":  {
                                           "href":  "V1/Overview/OMFQuickStart.html",
                                           "title":  "Edge Storage OMF Quick Start",
                                           "keywords":  "Edge Storage OMF Quick Start This document is a quick tour of getting data into the Edge Storage component using the OSisoft Message Format (OMF), and then retrieving the data using the Sequential Data Store (SDS) API. Both OMF data ingress and SDS data retrieval are accomplished using REST APIs. This tour assumes the Edge Data Store has been installed, and is accessible via a REST API using the default installed port (5590). This tour will use curl, a commonly available tool on both Windows and Linux, and use command line commands. The same operations can be used with any programming language or tool that supports making REST calls. In addition data retrieval steps (GET commands) can be accomplished using a browser if one is available on the device. Create an OMF Type The first step in OMF data ingress is to create an OMF type that describes the format of the data to be stored in a container. In our example the data to be written is a timestamp and a numeric value, so the OMF JSON describing the type is: [{ \"id\": \"MyCustomType\", \"classification\": \"dynamic\", \"type\": \"object\", \"properties\": { \"Timestamp\": { \"type\": \"string\", \"format\": \"date-time\", \"isindex\": true }, \"Value\": { \"type\": \"number\", \"format\": \"float32\" } } }] The value is indexed by a timestamp and the numeric value that will be stored is a 32 bit floating point value. In order to create the OMF type in the Edge Storage, the JSON should be stored as a file with the name OmfCreateType.json and run the following curl script: curl -i -d \"@OmfCreateType.json\" -H \"Content-Type: application/json\" application json\" -H \"producertoken: x \" -H \"omfversion: 1.1\" -H \"action: create\" -H \"messageformat: json\" -H \"messagetype: type\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf  When this command completes successfully, an SDS type with the same name will have been created on the server. Any number of containers can be created from the type, as long as they use a timestamp as an index and a 32 bit floating point value. Type creation only needs to be done the first time you send using a custom application, but it does not cause an error if you resend the same definition at a later time. Create an OMF Container The next step in writing OMF data is to create a container. As with an OMF Type, this only needs to be done once before sending data events, and resending the same definition repeatedly does not cause an error. [{ \"id\": \"MyCustomContainer\", \"typeid\": \"MyCustomType\" }] This container references the type that was created in the last step, and an error will occur if the type does not exist when the container is created. In order to create the OMF container in the Edge Storage, the JSON should be stored as a file with the name OmfCreateContainer.json and the following curl script run: curl -i -d \"@OmfCreateContainer.json\" -H \"Content-Type: application/json\" application json\" -H \"producertoken: x \" -H \"omfversion: 1.1\" -H \"action: create\" -H \"messageformat: json\" -H \"messagetype: container\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/omf/ http:  localhost:5590 api v1 tenants default namespaces default omf  When this command completes successfully, an SDS stream will have been created to store data defined by the type. Write Data Events to the OMF Container Now that the type and container have been created, we can write data using OMF: [{ \"containerid\": \"MyCustomContainer\", \"values\": [{ \"Timestamp\": \"2019-07-16T15:18:24.9870136Z\", \"Value\": 12345.6789 }, { \"Timestamp\": \"2019-07-16T15:18:25.9870136Z\", \"Value\": 12346.6789 } ] }] This example includes two data events that will be stored in the SDS Stream that was created in the previous steps. It is generally a best practice to batch OMF values when writing them for the best performance. In order to write the data in the Edge Storage, the JSON should be stored as a file with the name OmfCreateDataEvents.json and the following curl script run: curl -i -d \"@SDSWriteData.json\" -H \"Content-Type: application/json\" application json\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data When this command completes successfully, two values will have been written to the SDS stream. Read Last Data written using SDS In order to read the data back from the server that has been written, you can use the SDS REST API. Here is an example curl script that reads back the last value entered: curl http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data/Last http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data Last When run this GET command returns the last value written: {\"Time\":\"2017-11-23T18:00:00Z\",\"Measurement\":60.0} Read a range of data events written using SDS In order to read the data back from the server that has been written, you can use the SDS REST API. Here is an example curl script that reads back a time range of values that have been written: curl \"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data?startIndex=2017-07-08T13:00:00Z\u0026count=100\" \"http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data?startIndex=2017-07-08T13:00:00Z\u0026count=100\" This command will return up to 100 values after the startIndex specified: [{\"Time\":\"2017-11-23T17:00:00Z\",\"Measurement\":50.0},{\"Time\":\"2017-11-23T18:00:00Z\",\"Measurement\":60.0}] Both values that were entered were returned - up to 100 values after the specified timestamp would be returned. For more information on SDS APIs see the SDS section of this documentation."
                                       },
    "V1/Overview/OCSEgressQuickStart.html":  {
                                                 "href":  "V1/Overview/OCSEgressQuickStart.html",
                                                 "title":  "OSIsoft Cloud Services (OCS) egress Quick Start",
                                                 "keywords":  "OSIsoft Cloud Services (OCS) egress Quick Start This topic is a quick tour of getting data stored in the Edge Data Store into OCS. You can accomplish this by using the OCS OMF endpoint which is configured for OCS authentication. Create a periodic egress configuration Configure Edge Storage periodic egress for the Osisoft Cloud Services (OCS) endpoint and credentials: [{ \"Id\": \"OCS\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"ChangeMe\", \"TypePrefix\": \"ChangeMe\", \"Endpoint\": \"https:/\u003cyour \"https: \u003cyour OCS OMF end point endpoint\u003e\", \"ClientId\": \"\u003cyour OCS ClientId\u003e\", \"ClientSecret\": \"\u003cyour OCS ClientSecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null }] Edit the JSON above to add the URL of your OCS OMF endpoint. Add a ClientId and ClientSecret that can write data to your OCS tenant and namespace. The StreamPrefix and TypePrefix can be used to ensure uniqueness on the destination system, if required. If a StreamPrefix is specified it will be used to create a unique stream id on OCS. Run the following curl script to configure the Edge Storage to send data to OCS. This configuration is set up to send all stream data to OCS. Save the JSON with the file name PeriodicEgressEndpoints.json. Run the following curl script in the same directory where the file exists on the device where the Edge Data Store is installed. The file and curl script can be run from any directory on the device as long as the file and the curl script are run from the same directory: curl -i -d \"@PeriodicEgressEndpoints.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/storage/PeriodicEgressEndpoints/ http:  localhost:5590 api v1 configuration storage PeriodicEgressEndpoints  When this command completes successfully, data will start being sent to OCS."
                                             },
    "V1/Overview/ModbusQuickStart.html":  {
                                              "href":  "V1/Overview/ModbusQuickStart.html",
                                              "title":  "Edge Modbus Quick Start",
                                              "keywords":  "Edge Modbus Quick Start This topic is a quick tour of setting up the Edge Modbus TCP component. It is possible to add a single EDS Modbus TCP adapter during installation named Modbus1. If multiple EDS Modbus TcP adapters are desired, please reference Edge Data Store Configuration on how to add a new component to Edge Data Store. The examples below will change if a different adapter is being configured - please replace Modbus1 with the name of the component you have added. Configure a Modbus TCP data source Create a file in JSON format describing the location of the Modbus data source. The timeouts are in milliseconds. { \"IpAddress\": \"\u003cModbus IP Address\u003e\", \"Port\": \u003cPort - usually 502\u003e, \"ConnectTimeout\": 15000, \"ReconnectInterval\": 5000, \"RequestTimeout\": 9000, \"DelayBetweenRequests\": 0, \"MaxResponseDataLength\": 250 } Enter the correct IP address and port for your Modbus data source. Save the file with the name Modbus1DataSource.json. Run the following curl script from the same directory where the file is located. Note: You should run the script on the same computer where the Edge Data Store is installed: curl -i -d \"@Modbus1Datasource.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/Modbus1/Datasource http:  localhost:5590 api v1 configuration Modbus1 Datasource When this command completes successfully (a 204 is returned by curl), your Modbus TCP data source has been created. If you get a 400 error, check your JSON file for errors. If you get a 404 or 500 error, check to make sure Edge Data Store is running on your computer. Configure Modbus data selection Select the Modbus TCP data you want to store in Edge Data Store by configuring Modbus data selection. The following is a sample JSON for 5 Modbus values. Modify the values as appropriate for your Modbus environment. [{ \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 1, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 2, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 3, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 4, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 5, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 } ] Save the JSON content above in a text file and name it Modbus1Dataselection.json. Note: When you run the following curl script, the system will be configured to collect Modbus data values. curl -i -d \"@Modbus1Dataselection.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/Modbus1/Dataselection http:  localhost:5590 api v1 configuration Modbus1 Dataselection To see the streams that have been created in Edge Storage to store the data you are writing, you can run the following curl script: curl http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/ http:  localhost:5590 api v1 tenants default namespaces default streams  To view the data in the streams being written by Modbus, you can refer to the SDS part of this documentation. To egress the data to OSIsoft Cloud Services or the PI System, see the egress documentation or quick starts."
                                          },
    "V1/Overview/EdgeSystemOverview.html":  {
                                                "href":  "V1/Overview/EdgeSystemOverview.html",
                                                "title":  "Edge Data Store overview",
                                                "keywords":  "Edge Data Store overview Edge Data Store is a cross-platform component based application framework that is designed to host EDS adapters (adapters such as Modbus TCP and OPC UA), and other components such as Storage. In the future the same framework will be used to host other adapters. Installation of the Edge Data Store The Edge Data Store can be installed on both Linux and Windows: Edge Data Store Installation Overview . Data Ingress to the Edge Data Store The Edge Data Store can store (ingress) data in a number of ways. There are two built-in adapters - Modbus and OPC UA . In addition data can be ingressed using OSIsoft Message Format (OMF) and the Sequential Data Store SDS REST APIs. During installation of the Edge Data Store, options are presented to install either a Modbus TCP EDS adapter, or an OPC UA EDS adapter, or both. The Modbus and OPC UA adapters require additional configuration of data source and data selection before they will collect data in the Edge Data Store. For OMF data ingress, once the Edge Data Store is installed OMF ingress can be started with no further configuration steps. The Edge Data Store is composed of components and is designed to allow the addition at a later date of additional EDS adapters if desired. Local Data Read and Write Access All data in the Edge Data Store storage can be accessed using the Sequential Data Store SDS REST API. Data Egress from the Edge Data Store The Edge Data Store can send data on to both the PI Data Archive (using PI Web API ) and OSIsoft Cloud Services ( OCS ). Additional configuration is necessary to send data to both OCS and PI Web API after the Edge Data Store is installed."
                                            },
    "V1/Overview/CommandLineQuickStartWindows.html":  {
                                                          "href":  "V1/Overview/CommandLineQuickStartWindows.html",
                                                          "title":  "Edge Data Store Command Line Quick Start - Windows",
                                                          "keywords":  "Edge Data Store Command Line Quick Start - Windows One of the ways to configure the Edge Data Store is with the edgecmd.exe command line tool. To access the tool on Windows open a command prompt and navigate to the directory where the Edge Data Store has been installed. This is usually in the following location: C:\\Program Files\\OSIsoft\\EdgeDataStore\\ It is recommended that you do not copy or delete any files in that directory. To invoke the tool you can use the full path from a different directory: C:\\Users\\John\u003e\"C:\\Program Files\\OSIsoft\\EdgeDataStore\\edgecmd.exe\" Help ************************************************************************************************************************ Welcome to OSIsoft Edge Data Store configuration utility. Utility version: 1.0.0.148 ************************************************************************************************************************ --------------------------------------------------------------------------------------------------------- Command-line options =\u003e \u0027Configuration\u0027, \u0027Help\u0027 --------------------------------------------------------------------------------------------------------- Please enter ID of a component you would like to configure or to get component specific help output. Example: .\\edgecmd.exe Help ComponentId .\\edgecmd.exe Configuration ComponentId To get set of components registered to the Edge Data Store please run: .\\edgecmd.exe Configuration System Components To configure the system, please use \u0027System\u0027 as the ComponentId. Example of getting System help output: .\\edgecmd.exe Help System Example of configuring System Logging level: .\\edgecmd.exe Configuration System logging LogLevel=Warning C:\\Users\\John\u003e Most configurations options that can be done using REST can also be done using the edgecmd utility and command line arguments. Generally the configuration and administrative REST interfaces are exposed via the command line. Access to reading and writing data to the Edge Data Store Storage Component - OMF Ingress and SDS Read/Write Read Write capabilities are only available using the REST API."
                                                      },
    "V1/Overview/CommandLineLinuxQuickStart.html":  {
                                                        "href":  "V1/Overview/CommandLineLinuxQuickStart.html",
                                                        "title":  "Edge Data Store Command Line Quick Start - Linux",
                                                        "keywords":  "Edge Data Store Command Line Quick Start - Linux One of the ways to configure the Edge Data Store is with the edgecmd command line tool. To access the tool on Linux open a command prompt. The utility is available to use in any directory on Linux. debian@beaglebone:~$ edgecmd help ************************************************************************************************************************ Welcome to OSIsoft Edge Data Store configuration utility. Utility version: 1.0.0.148 ************************************************************************************************************************ --------------------------------------------------------------------------------------------------------- Command-line options =\u003e \u0027Configuration\u0027, \u0027Help\u0027 --------------------------------------------------------------------------------------------------------- Please enter ID of a component you would like to configure or to get component specific help output. Example: ./edgecmd . edgecmd Help ComponentId ./edgecmd . edgecmd Configuration ComponentId To get set of components registered to the Edge Data Store please run: ./edgecmd . edgecmd Configuration System Components To configure the system, please use \u0027System\u0027 as the ComponentId. Example of getting System help output: ./edgecmd . edgecmd Help System Example of configuring System Logging level: ./edgecmd . edgecmd Configuration System logging LogLevel=Warning debian@beaglebone:~$ Most configurations options that can be done using REST can also be done using the edgecmd utility and command line arguments. Generally the configuration and administrative REST interfaces are exposed via the command line. Access to reading and writing data to the Edge Data Store Storage Component - OMF Ingress and SDS Read/Write Read Write capabilities are only available using the REST API."
                                                    },
    "V1/Overview/AnalyticsQuickStart.html":  {
                                                 "href":  "V1/Overview/AnalyticsQuickStart.html",
                                                 "title":  "Edge Data Store Analytics quick start",
                                                 "keywords":  "Edge Data Store Analytics quick start This document is a quick tour of a very simple analytic that can written using the Edge Data Store. The intended input device for this example is a Modbus TCP or other sensor that outputs 4 boolean values. The normal range of operation is that the values are neither all true or all false. If all values are true, the exception condition High is triggered. If all values are false, the exception condition Low is triggered. Any other combination of boolean values is Normal. Three analytic streams are created to track these changes. The ValueRangeHigh stream is 1 when High and 0 when anything else. The ValueRangeLow stream is -1 when Low and 0 when anything else. The ValueRangeOut stream is -1 when Low, 0 when Normal, and 1 when High. This example assumes the Edge Data Store was installed with the default port (5590). using System; using System.Collections.Generic; using System.Net.Http; using System.Text; using Newtonsoft.Json; using Newtonsoft.Json.Linq; namespace ExceptionReportingSample { class ModbusField { public string StreamId { get; set; } public int ScanRate { get; set; } } enum Alert { Normal, High, Low } class ExceptionReporting { static HttpClient _client = new HttpClient(); private static List\u003cstring\u003e StreamIds = new List\u003cstring\u003e(new string[] { \"SwitchState1\", \"SwitchState2\", \"SwitchState3\", \"SwitchState4\" }); private const string ValueRangeHigh = \"ValueRangeHigh\"; private const string ValueRangeLow = \"ValueRangeLow\"; private const string ValueRangeOut = \"ValueRangeOut\"; private const string TypeId = \"ValueRange\"; private const string ModbusComponentId = \"Modbus1\"; private const double lowValue = -1.0; private const double highValue = 1.0; private const double normalValue = 0.0; public static Alert _alert = Alert.Normal; static TimeSpan GetPollingIntervalFromModbus(string modbusComponentId, List\u003cstring\u003e StreamIds) { int pollingMilliseconds = 5000; string endpoint = $\"http://localhost:5590/api/v1/configuration/{modbusComponentId}/DataSelection\"; $\"http:  localhost:5590 api v1 configuration {modbusComponentId} DataSelection\"; string modbusConfig = _client.GetStringAsync(endpoint).Result; List\u003cModbusField\u003e values = JsonConvert.DeserializeObject\u003cList\u003cModbusField\u003e\u003e(modbusConfig); foreach (var value in values) { foreach (string StreamId in StreamIds) { if (StreamId == value.StreamId \u0026\u0026 value.ScanRate \u003c pollingMilliseconds) { pollingMilliseconds = value.ScanRate; } } } return TimeSpan.FromMilliseconds(pollingMilliseconds); } static bool GetStreamValue(string StreamId) { bool value = false; string lastValueUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/{0}/Data/Last\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces default streams {0} Data Last\", StreamId); string lastValueJson = _client.GetStringAsync(lastValueUri).Result; Dictionary\u003cstring, object\u003e values = JsonConvert.DeserializeObject\u003cDictionary\u003cstring, object\u003e\u003e(lastValueJson); object objValue = values[\"Value\"]; if (objValue is Boolean) value = (bool)objValue; return value; } static bool FindOrCreateType(string typeId) { string typeUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/default/types/{0}\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces default types {0}\", typeId); HttpResponseMessage response = _client.GetAsync(typeUri).Result; if (response.IsSuccessStatusCode) return true; string typeJson = @\"{\"\"Id\"\": \"\"\" + typeId + @\"\"\",\"\"Name\"\": \"\"\" + typeId + @\"\"\",\"\"SdsTypeCode\"\": 1,\"\"Properties\"\": [{\"\"Id\"\": \"\"Time\"\",\"\"Name\"\": \"\"Time\"\",\"\"IsKey\"\": true,\"\"SdsType\"\": {\"\"SdsTypeCode\"\": 16}},{\"\"Id\"\": \"\"Measurement\"\",\"\"Name\"\": \"\"Measurement\"\",\"\"SdsType\"\": {\"\"SdsTypeCode\"\": 14}}]}\"; var content = new StringContent(typeJson, Encoding.UTF8, \"application/json\"); \"application json\"); response = _client.PostAsync(typeUri, content).Result; return response.IsSuccessStatusCode; } static bool FindOrCreateStream(string streamId, string typeId) { string streamUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/{0}/\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces default streams {0} \", streamId); HttpResponseMessage response = _client.GetAsync(streamUri).Result; if (response.IsSuccessStatusCode) return true; string streamJson = @\"{\"\"Id\"\": \"\"\" + streamId + @\"\"\",\"\"Name\"\": \"\"\" + streamId + @\"\"\",\"\"TypeId\"\": \"\"\" + typeId + @\"\"\"}\"; var content = new StringContent(streamJson, Encoding.UTF8, \"application/json\"); \"application json\"); response = _client.PostAsync(streamUri, content).Result; return response.IsSuccessStatusCode; } static bool WriteStreamValue(string StreamId, double value, DateTime timestamp) { string dataUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/{0}/Data\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces default streams {0} Data\", StreamId); string dataJson = @\"[{\"\"Time\"\": \"\"\" + timestamp.ToString(\"o\") + @\"\"\",\"\"Measurement\"\":\" + value.ToString() + \"}]\"; var content = new StringContent(dataJson, Encoding.UTF8, \"application/json\"); \"application json\"); HttpResponseMessage response = _client.PostAsync(dataUri, content).Result; return response.IsSuccessStatusCode; } static Alert CheckStatus(int numberTrue) { if (numberTrue \u003e 3) return Alert.High; if (numberTrue \u003c 1) return Alert.Low; return Alert.Normal; } static bool ReportChange(Alert oldAlert, Alert newAlert) { bool success = true; DateTime now = DateTime.UtcNow; switch (oldAlert) { case Alert.Normal: if (Alert.Low == newAlert) { return WriteStreamValue(ValueRangeLow, lowValue, now) \u0026\u0026 WriteStreamValue(ValueRangeOut, lowValue, now); } if (Alert.High == newAlert) { return WriteStreamValue(ValueRangeHigh, highValue, now) \u0026\u0026 WriteStreamValue(ValueRangeOut, highValue, now); } break; case Alert.High: if (Alert.Low == newAlert) { return WriteStreamValue(ValueRangeLow, lowValue, now) \u0026\u0026 WriteStreamValue(ValueRangeOut, lowValue, now) \u0026\u0026 WriteStreamValue(ValueRangeHigh, normalValue, now); } if (Alert.Normal == newAlert) { return WriteStreamValue(ValueRangeOut, normalValue, now) \u0026\u0026 WriteStreamValue(ValueRangeHigh, normalValue, now); } break; case Alert.Low: if (Alert.Normal == newAlert) { return WriteStreamValue(ValueRangeOut, normalValue, now) \u0026\u0026 WriteStreamValue(ValueRangeLow, normalValue, now); } if (Alert.High == newAlert) { return WriteStreamValue(ValueRangeLow, normalValue, now) \u0026\u0026 WriteStreamValue(ValueRangeOut, highValue, now) \u0026\u0026 WriteStreamValue(ValueRangeHigh, highValue, now); } break; default: break; } return success; } static void Main(string[] args) { TimeSpan pollingInterval = GetPollingIntervalFromModbus(ModbusComponentId, StreamIds); FindOrCreateType(TypeId); FindOrCreateStream(ValueRangeHigh, TypeId); FindOrCreateStream(ValueRangeLow, TypeId); FindOrCreateStream(ValueRangeOut, TypeId); while (true) { int numberTrue = 0; foreach (string StreamId in StreamIds) { bool value = GetStreamValue(StreamId); if (value) numberTrue++; } Alert currentAlert = CheckStatus(numberTrue); if (currentAlert != _alert) { if (ReportChange(_alert, currentAlert)) { _alert = currentAlert; } } System.Threading.Thread.Sleep(pollingInterval); Console.WriteLine(\"ValueRange should be \" + _alert); } } } }"
                                             },
    "V1/Docker/EdgeDocker.html":  {
                                      "href":  "V1/Docker/EdgeDocker.html",
                                      "title":  "Using Edge Data Store with Docker",
                                      "keywords":  "Using Edge Data Store with Docker Docker is a set of tools that can be used on Linux to manage application deployments. It is beyond the scope of this document to explain concepts behind Docker containers, and it is assumed that if a reader wants to use Docker they are familiar with the underlying technology and have determined it is appropriate for their planned use of the Edge Data Store. The objective of this document is to provide examples of how to successfully create a Docker container with the Edge Data Store, if it is decided Docker is desirable. Docker is not a requirement to use the Edge Data Store. Creating a Docker container containing the Edge Data Store ARM32 Processor Create the following Dockerfile in the directory where you wish to create and/or and or run the container: FROM mcr.microsoft.com/dotnet/core/sdk:2.2 mcr.microsoft.com dotnet core sdk:2.2 ARG source WORKDIR /   ADD ./EdgeDataStore_linux-arm.tar . EdgeDataStore_linux-arm.tar . ENTRYPOINT [\"./EdgeDataStore_linux-arm/OSIsoft.Data.System.Host\"] [\". EdgeDataStore_linux-arm OSIsoft.Data.System.Host\"] Copy the EdgeDataStore_linux-arm.tar file to the same directory as the Dockerfile. Run the following command line (sudo may be necessary): docker build -t EdgeDataStore . AMD64 (x64) Processor Create the following Dockerfile in the directory where you wish to create and/or and or run the container: FROM mcr.microsoft.com/dotnet/core/sdk:2.2 mcr.microsoft.com dotnet core sdk:2.2 ARG source WORKDIR /   ADD ./EdgeDataStore_linux-x64.tar . EdgeDataStore_linux-x64.tar . ENTRYPOINT [\"./EdgeDataStore_linux-x64/OSIsoft.Data.System.Host\"] [\". EdgeDataStore_linux-x64 OSIsoft.Data.System.Host\"] Copy the EdgeDataStore_linux-x64.tar file to the same directory as the Dockerfile. Run the following command line (sudo may be necessary): docker build -t EdgeDataStore . Running Edge Data Store Docker Containers REST access from the local machine from Docker To run the container you can use the command line (sudo may be necessary): docker run -d --network host EdgeDataStore Port 5590 will be accessible from the host and REST calls can be made to the Edge Data Store from applications on the local host computer. With this configuration, all data stored by the Edge Data Store is stored in the container itself, and when the container is deleted the data stored will also be deleted. Persistent storage on the local file system from Docker To run the container you can use the command line (sudo may be necessary): docker run -d --network host -v /edgeds:/usr/share/OSIsoft/  edgeds: usr share OSIsoft  EdgeDataStore Port 5590 will be accessible from the host and REST calls can be made to the Edge Data Store from applications on the local host computer. In addition, in this example, all data that would be written to the container is written instead to the host directory /edgeds.  edgeds. This directory can be anything the user wishes - this example just uses a simple directory on the local machine. Changing Port number from Docker If a port other than 5590 is desired, see the section regarding Port configuration of the Edge Data Store. Changing the configuration of the Edge Data Store running in the container will change the port exposed to the local machine. Limiting local host access to Docker If the --network host option is removed from the docker run command no REST access is possible from outside the container. This may be of value where a user wishes to host an application in the same container as the EdgeDataStore, and does not wish to have external REST access enabled."
                                  },
    "V1/Diagnostics/Diagnostics.html":  {
                                            "href":  "V1/Diagnostics/Diagnostics.html",
                                            "title":  "Edge Data Store diagnostics",
                                            "keywords":  "Edge Data Store diagnostics Edge Data Store and its components produce diagnostics data which is stored locally in the Storage component, and may be queried locally and/or and or egressed to PI Web API endpoints or the OSIsoft Cloud Services. Diagnostics data is stored within the \u0027diagnostics\u0027 namespace of Edge Storage. Local access to this data is available via the Sds methods. Egressing diagnostics data via PeriodicEgressEndpoints To egress diagnositcs related data, configure a periodic egress endpoint and specify diagnostics as the NamespaceId in the periodic egress endpoint configuration. Diagnostics produced by Edge Data Store Edge Data Store produces the following diagnostics streams: The Diagnostics.System dynamic type includes these values which are logged in a stream with the id System.Diagnostics. This diagnostic stream contains system level information related to the host platform that the Edge Data Store is running on. Type Property Description string timestamp Timestamp of event int ProcessIdentifier Process id of the host process string StartTime When the host process started long WorkingSet Amount of physical memory, in bytes, allocated for the host process double TotalProcessorTime (uom=s) Total processor time for the host process expressed in seconds double TotalUserProcessorTime (uom=s) User processor time for the host process expressed in seconds double TotalPrivilegedProcessorTime (uom=s) Privileged processor time for the host process expressed in seconds int ThreadCount Number of threads in the host process int HandleCount Number of handles opened by the host process double ManagedMemorySize (uom=MB) Number of bytes currently thought to be allocated in managed memory double PrivateMemorySize (uom=MB) Amount of paged memory, in bytes, allocated for the host process double PeakPagedMemorySize (uom=MB) Maximum amount of memory in the virtual memory paging file, in bytes, used by the host process. double StorageTotalSize (uom=MB) Total size of the storage medium in use by the Edge Data Store double StorageFreeSpace (uom=MB) Free space available Edge EDS adapter diagnostics Each EDS adapter of the Edge Data Store produces its own diagnostics streams. Stream count The Diagnostics.StreamCountEvent dynamic type includes these values, which are logged in a stream with the id {componentid}.StreamCount. The stream count and type count include only types and streams created for sequential data received from a data source. Type Property Description string timestamp Timestamp of event int StreamCount Number of streams created by the adapter instance int TypeCount Number of types created by the adapter instance IO rate The Diagnostics.Adapter.IORate dynamic type includes these values, which are logged in a stream with the id {componentid}.IORate. IO rate includes only sequential data collected from a data source. Type Property Description string timestamp Timestamp of event double IORate 10-minute rolling average of data rate (streams/second) (streams second) Error rate The Diagnostics.Adapter.ErrorRate dynamic type includes these values, and are logged in a stream with the id {componentid}.ErrorRate. Type Property Description string timestamp Timestamp of event double ErrorRate 10-minute rolling average of error rate (streams/second) (streams second) Edge Storage diagnostics The Storage component of Edge Data Store produces the following diagnostics streams. Storage.default.default.Counts The Storage.default.default.Counts stream includes counts of the types, streams and stream views of the default namespace. Type Property Description string timestamp Timestamp of event integer TypeCount Count of types integer StreamCount Count of streams integer StreamViewCount Count of stream views Storage.default.diagnostics.Counts The Storage.default.default.Counts stream includes counts of the types, streams and stream views of the diagnostics namespace. Type Property Description string timestamp Timestamp of event integer TypeCount Count of types integer StreamCount Count of streams integer StreamViewCount Count of stream views Storage.Total.Counts The Storage.Totals.Counts stream includes counts of the types, streams and stream views of all namespaces of the storage component. Type Property Description string timestamp Timestamp of event integer TypeCount Count of types integer StreamCount Count of streams integer StreamViewCount Count of stream views"
                                        },
    "V1/Design/ScalePerformance.html":  {
                                            "href":  "V1/Design/ScalePerformance.html",
                                            "title":  "Edge Data Store design considerations",
                                            "keywords":  "Edge Data Store design considerations Edge Storage role The Edge Storage component that ships with the Edge Data Store is a new component in the OSIsoft software ecosystem. It is not designed to replace any existing storage technology produced by OSIsoft. It differs from the PI Data Archive and OSIsoft Cloud Services in that it is not intended as a permanent repository for customer data. The Edge Storage component is intended as a store that is resilient and reliable, but limited in duration and scope, as appropriate for an Edge software component. The Edge storage component is designed to roll off data in a FIFO (first in first out) process - as new data comes and the size of streams exceeds the configured limits, older data is purged. If data exists in the Edge Storage component that needs to be permanently retained, it should be egressed to either the PI Data Archive (using PI Web API OMF end point) or to OSIsoft Cloud Services, using the OCS OMF ingress end point. Edge Storage scale The Edge Storage component has been designed to provide an appropriate level of storage performance on small devices. For the smallest of these devices, throughput may be limited to 10s of events per second. For larger devices with faster processors, memory, and storage, this could increase to up to 3,000 events per second. The Edge Storage component\u0027s design is focused on small devices in Edge scenarios: if high throughput or large stream counts are required, OSIsoft Cloud Services or the PI Data Archive are more appropriate choices. Sizing of Edge Devices For the Edge Data Store, there are three supported tiers of performance: Small Devices - 1 Core CPU, 512 MB RAM - 30 events/second events second 200 streams total Medium Devices - 2 Core CPU, 1 GB RAM - 300 events/second events second 2000 streams total Large Devices - 4 Core CPU, 4 GB RAM, SSD storage - 3000 events/second events second 3000 streams total These performance metrics assume solid state storage, which is commonly used in Edge devices."
                                        },
    "V1/Configuration/Schemas/System_Components_schema.html":  {
                                                                   "href":  "V1/Configuration/Schemas/System_Components_schema.html",
                                                                   "title":  "Sample Edge Data Store components configuration",
                                                                   "keywords":  "Sample Edge Data Store components configuration [ { \"ComponentId\": \"OpcUa1\", \"ComponentType\": \"OpcUa\" }, { \"ComponentId\": \"Modbus1\", \"ComponentType\": \"Modbus\" }, { \"ComponentId\": \"Storage\", \"ComponentType\": \"EDS.Component\" } ] Edge Data Store components schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden System_Components_schema.json EdgeDataStoreConfig definitions Property Type Group ComponentId string #/definitions/EdgeComponentConfig # definitions EdgeComponentConfig ComponentType string #/definitions/EdgeComponentConfig # definitions EdgeComponentConfig ComponentId ComponentId is optional type: string defined in this schema ComponentId type string , nullable ComponentType ComponentType is optional type: string defined in this schema ComponentType type string , nullable EdgeDataStoreConfig properties Property Type Required Nullable Defined by ComponentConfigurations reference Optional Yes EdgeDataStoreConfig (this schema) ComponentConfigurations ComponentConfigurations is optional type: reference defined in this schema ComponentConfigurations type Array type: reference All items must be of the type: ??? #/definitions/EdgeComponentConfig # definitions EdgeComponentConfig All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required ComponentConfigurations array Optional ComponentConfigurations ComponentConfigurations is optional type: reference ComponentConfigurations type Array type: reference All items must be of the type: ??? #/definitions/EdgeComponentConfig # definitions EdgeComponentConfig"
                                                               },
    "V1/Configuration/Schemas/Storage_schema.html":  {
                                                         "href":  "V1/Configuration/Schemas/Storage_schema.html",
                                                         "title":  "StorageConfiguration schema",
                                                         "keywords":  "StorageConfiguration schema \"Storage\": { \"Runtime\": { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\" }, \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"PeriodicEgressEndpoints\": [] } Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden Modbus_Logging_schema.json Properties Property Type Required Nullable Defined by Runtime StorageRuntimeConfiguration Optional Yes StorageRuntimeConfiguration Logging StorageLoggingConfiguration Optional Yes StorageLoggingConfiguration PeriodicEgressEndpoints [PeriodicEgressEndpointsConfiguration] Optional Yes PeriodicEgressEndpointsConfiguration Runtime is optional type: StorageRuntimeConfiguration Logging is optional type: StorageLoggingConfiguration PeriodicEgressEndpoints is optional type: [PeriodicEgressEndpointsConfiguration]"
                                                     },
    "V1/Configuration/Schemas/Storage_Runtime_schema.html":  {
                                                                 "href":  "V1/Configuration/Schemas/Storage_Runtime_schema.html",
                                                                 "title":  "Sample storage runtime configuration",
                                                                 "keywords":  "Sample storage runtime configuration { \"StreamStorageLimitMb\": 2, \"StreamStorageTargetMb\": 1, \"IngressDebugExpiration\": \"0001-01-01T00:00:00\" } Storage runtime configuration schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden Storage_Runtime_schema.json StorageRuntimeConfiguration properties Property Type Required Nullable Defined by IngressDebugExpiration string Required No StorageRuntimeConfiguration (this schema) StreamStorageLimitMb integer Required No StorageRuntimeConfiguration (this schema) StreamStorageTargetMb integer Required No StorageRuntimeConfiguration (this schema) IngressDebugExpiration IngressDebugExpiration is required type: string defined in this schema Ingress Debug Expiration is a property that can be used when debugging OMF. If the date and time is the future incoming OMF messages will be logged until the date and time specified. Once the configured time is past OMF messages will no longer be logged for debugging purposes. IngressDebugExpiration type string format: date-time ??? date and time (according to RFC 3339, section 5.6 ) minimum length: 1 characters StreamStorageLimitMb StreamStorageLimitMb is required type: integer defined in this schema StreamStorageLimitMb type integer minimum value: 2 maximum value: 2147483647 StreamStorageLimitMb is the maximum size in megabytes that a stream can reach. When a stream exceeds the size specified, older data will be deleted from the file. Data will be removed from the stream until the stream is at or below the StreamStorageTargetMb value. It is recommended that the target value be smaller than the limit since trimming can be an expensive operation and should be done infrequently. StreamStorageTargetMb StreamStorageTargetMb is required type: integer defined in this schema StreamStorageTargetMb type integer minimum value: 1 maximum value: 2147483647 StreamStorageTargetMb is the size in megabytes that a stream will be reduced to after StreamStorageLimitMb size is reached for a single stream. When a stream exceeds the size specified, older data will be deleted from the file. Data will be removed from the stream until the stream is at or below the StreamStorageTargetMb value. It is recommended that the target value be smaller than the limit since trimming can be an expensive operation and should be done infrequently. All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required IngressDebugExpiration string Required StreamStorageLimitMb integer Required StreamStorageTargetMb integer Required"
                                                             },
    "V1/Configuration/Schemas/Storage_PeriodicEgressEndpoints_schema.html":  {
                                                                                 "href":  "V1/Configuration/Schemas/Storage_PeriodicEgressEndpoints_schema.html",
                                                                                 "title":  "Periodic egress configuration schema",
                                                                                 "keywords":  "Periodic egress configuration schema This schema is used to configure data egress from Edge Data Store to a PI Server or to OCS. Sample periodic egress configuration file [{ \"Id\": \"OCS Data\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cmakeunique\u003e\", \"TypePrefix\": \"\u003cmakeunique\u003e\", \"Endpoint\": \"https://\u003cOCS \"https:  \u003cOCS OMF endpoint\u003e\", \"ClientId\": \"\u003cclientid\u003e\", \"ClientSecret\": \"\u003cclientsecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null }, { \"Id\": \"PI Web API Data\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cmakeunique\u003e\", \"TypePrefix\": \"\u003cmakeunique\u003e\", \"Endpoint\": \"https://\u003cyourserver\u003e/piwebapi/omf/\", \"https:  \u003cyourserver\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null }, { \"Id\": \"OCS Diagnostics\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"diagnostics\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cmakeunique\u003e\", \"TypePrefix\": \"\u003cmakeunique\u003e\", \"Endpoint\": \"https://\u003cOCS \"https:  \u003cOCS OMF endpoint\u003e\", \"ClientId\": \"\u003cclientid\u003e\", \"ClientSecret\": \"\u003cclientsecret\u003e\", \"UserName\": null, \"Password\": null, \"DebugExpiration\": null }, { \"Id\": \"PI Web API Diagnostics\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"diagnostics\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cmakeunique\u003e\", \"TypePrefix\": \"\u003cmakeunique\u003e\", \"Endpoint\": \"https://\u003cyourserver\u003e/piwebapi/omf/\", \"https:  \u003cyourserver\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null } ] Abstract Extensible Status Identifiable Custom properties Additional properties Defined Ii Can be instantiated Yes Experimental No Forbidden Forbidden Storage_PeriodicEgressEndpoints_schema.json PeriodicEgressConfiguration properties Property Type Required Nullable Defined by Backfill boolean Optional No PeriodicEgressConfiguration (this schema) ClientId string Optional Yes PeriodicEgressConfiguration (this schema) ClientSecret string Optional Yes PeriodicEgressConfiguration (this schema) DebugExpiration string Optional Yes PeriodicEgressConfiguration (this schema) Description string Optional Yes PeriodicEgressConfiguration (this schema) EgressFilter string Optional Yes PeriodicEgressConfiguration (this schema) Enabled boolean Optional No PeriodicEgressConfiguration (this schema) Endpoint string Required No PeriodicEgressConfiguration (this schema) ExecutionPeriod string Required No PeriodicEgressConfiguration (this schema) Id string Required No PeriodicEgressConfiguration (this schema) Name string Optional Yes PeriodicEgressConfiguration (this schema) NamespaceId string Optional Yes PeriodicEgressConfiguration (this schema) Password string Optional Yes PeriodicEgressConfiguration (this schema) StreamPrefix string Optional Yes PeriodicEgressConfiguration (this schema) TypePrefix string Optional Yes PeriodicEgressConfiguration (this schema) UserName string Optional Yes PeriodicEgressConfiguration (this schema) Backfill Backfill is optional type: boolean defined in this schema Backfill type boolean ClientId ClientId is optional type: string defined in this schema ClientId type string , nullable ClientSecret ClientSecret is optional type: string defined in this schema ClientSecret type string , nullable DebugExpiration DebugExpiration is optional type: string defined in this schema DebugExpiration type string , nullable format: date-time ??? date and time (according to RFC 3339, section 5.6 ) Description Description is optional type: string defined in this schema Description type string , nullable EgressFilter EgressFilter is optional type: string defined in this schema EgressFilter type string , nullable Enabled Enabled is optional type: boolean defined in this schema Enabled type boolean Endpoint Endpoint is required type: string defined in this schema Endpoint type string minimum length: 1 characters ExecutionPeriod ExecutionPeriod is required type: string defined in this schema ExecutionPeriod type string minimum length: 1 characters Id Id is required type: string defined in this schema Id type string minimum length: 1 characters Name Name is optional type: string defined in this schema Name type string , nullable NamespaceId NamespaceId is optional type: string defined in this schema NamespaceId type string , nullable Password Password is optional type: string defined in this schema Password type string , nullable StreamPrefix StreamPrefix is optional type: string defined in this schema StreamPrefix type string , nullable TypePrefix TypePrefix is optional type: string defined in this schema TypePrefix type string , nullable UserName UserName is optional type: string defined in this schema UserName type string , nullable All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required Backfill boolean Optional ClientId string Optional ClientSecret string Optional DebugExpiration string Optional Description string Optional EgressFilter string Optional Enabled boolean Optional Endpoint string Required ExecutionPeriod string Required Id string Required Name string Optional NamespaceId string Optional Password string Optional StreamPrefix string Optional TypePrefix string Optional UserName string Optional Backfill Backfill is optional type: boolean Backfill type boolean ClientId ClientId is optional type: string ClientId type string , nullable ClientSecret ClientSecret is optional type: string ClientSecret type string , nullable DebugExpiration DebugExpiration is optional type: string DebugExpiration type string , nullable format: date-time ??? date and time (according to RFC 3339, section 5.6 ) Description Description is optional type: string Description type string , nullable EgressFilter EgressFilter is optional type: string EgressFilter type string , nullable Enabled Enabled is optional type: boolean Enabled type boolean Endpoint Endpoint is required type: string Endpoint type string minimum length: 1 characters ExecutionPeriod ExecutionPeriod is required type: string ExecutionPeriod type string minimum length: 1 characters Id Id is required type: string Id type string minimum length: 1 characters Name Name is optional type: string Name type string , nullable NamespaceId NamespaceId is optional type: string NamespaceId type string , nullable Password Password is optional type: string Password type string , nullable StreamPrefix StreamPrefix is optional type: string StreamPrefix type string , nullable TypePrefix TypePrefix is optional type: string TypePrefix type string , nullable UserName UserName is optional type: string UserName type string , nullable"
                                                                             },
    "V1/Configuration/Schemas/OpcUa_schema.html":  {
                                                       "href":  "V1/Configuration/Schemas/OpcUa_schema.html",
                                                       "title":  "OpcUaConfiguration Schema",
                                                       "keywords":  "OpcUaConfiguration Schema Abstract Extensible Status Identifiable Custom Properties Additional Properties Defined In Can be instantiated Yes Experimental No Forbidden Forbidden OpcUa_Logging_schema.json Properties Property Type Required Nullable Defined by Logging OpcUaLoggingConfiguration Optional Yes EdgeLoggerConfiguration DataSource DataSourceConfiguration Optional Yes ComponentsConfiguration DataSelection [OpcUaDataSelectionConfiguration] Optional Yes DataSelectionConfiguration Logging is optional type: OpcUaLoggingConfiguration DataSource is optional type: DataSourceConfiguration DataSelection is optional type: [OpcUaDataSelectionConfiguration]"
                                                   },
    "V1/Configuration/Schemas/OpcUa_Logging_schema.html":  {
                                                               "href":  "V1/Configuration/Schemas/OpcUa_Logging_schema.html",
                                                               "title":  "OPC UA logger configuration schema",
                                                               "keywords":  "OPC UA logger configuration schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden OpcUa_Logging_schema.json OpcUaLoggerConfiguration Properties Property Type Required Nullable Defined by LogFileCountLimit integer Optional Yes EdgeLoggerConfiguration (this schema) LogFileSizeLimitBytes integer Optional Yes EdgeLoggerConfiguration (this schema) LogLevel reference Optional No EdgeLoggerConfiguration (this schema) LogFileCountLimit LogFileCountLimit is optional type: integer defined in this schema LogFileCountLimit type integer , nullable LogFileSizeLimitBytes LogFileSizeLimitBytes is optional type: integer defined in this schema LogFileSizeLimitBytes type integer , nullable LogLevel LogLevel is optional type: reference defined in this schema LogLevel type ??? #/definitions/EdgeLogLevel # definitions EdgeLogLevel All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required LogFileCountLimit integer Optional LogFileSizeLimitBytes integer Optional LogLevel Optional LogFileCountLimit LogFileCountLimit is optional type: integer LogFileCountLimit type integer , nullable LogFileSizeLimitBytes LogFileSizeLimitBytes is optional type: integer LogFileSizeLimitBytes type integer , nullable LogLevel LogLevel is optional type: reference LogLevel type ??? #/definitions/EdgeLogLevel # definitions EdgeLogLevel"
                                                           },
    "V1/Configuration/Schemas/OpcUa_DataSource_schema.html":  {
                                                                  "href":  "V1/Configuration/Schemas/OpcUa_DataSource_schema.html",
                                                                  "title":  "Sample Opc Ua data source configuration",
                                                                  "keywords":  "Sample Opc Ua data source configuration { \"EndpointUrl\": \"opc.tcp://\u003cip \"opc.tcp:  \u003cip address\u003e:\u003cport - often 62541\u003e/\u003cserver 62541\u003e \u003cserver path\u003e\", \"UseSecureConnection\": false, \"UserName\": null, \"Password\": null, \"RootNodeIds\": null, \"IncomingTimestamp\": \"Source\", \"StreamIdPrefix\": \"OpcUa\" } OPC UA data source configuration schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden OpcUa_DataSource_schema.json DataSourceConfiguration properties Property Type Required Nullable Defined by EndpointUrl string Optional Yes DataSourceConfiguration (this schema) IncomingTimestamp reference Optional No DataSourceConfiguration (this schema) Password string Optional Yes DataSourceConfiguration (this schema) RootNodeIds string Optional Yes DataSourceConfiguration (this schema) StreamIdPrefix string Optional Yes DataSourceConfiguration (this schema) UseSecureConnection boolean Optional No DataSourceConfiguration (this schema) UserName string Optional Yes DataSourceConfiguration (this schema) EndpointUrl EndpointUrl is optional type: string defined in this schema EndpointUrl type string , nullable IncomingTimestamp IncomingTimestamp is optional type: reference defined in this schema IncomingTimestamp type ??? #/definitions/IncomingTimestampType # definitions IncomingTimestampType Password Password is optional type: string defined in this schema Password type string , nullable RootNodeIds RootNodeIds is optional type: string defined in this schema RootNodeIds type string , nullable StreamIdPrefix StreamIdPrefix is optional type: string defined in this schema StreamIdPrefix type string , nullable UseSecureConnection UseSecureConnection is optional type: boolean defined in this schema UseSecureConnection type boolean UserName UserName is optional type: string defined in this schema UserName type string , nullable All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required EndpointUrl string Optional IncomingTimestamp Optional Password string Optional RootNodeIds string Optional StreamIdPrefix string Optional UseSecureConnection boolean Optional UserName string Optional EndpointUrl EndpointUrl is optional type: string EndpointUrl type string , nullable IncomingTimestamp IncomingTimestamp is optional type: reference IncomingTimestamp type ??? #/definitions/IncomingTimestampType # definitions IncomingTimestampType Password Password is optional type: string Password type string , nullable RootNodeIds RootNodeIds is optional type: string RootNodeIds type string , nullable StreamIdPrefix StreamIdPrefix is optional type: string StreamIdPrefix type string , nullable UseSecureConnection UseSecureConnection is optional type: boolean UseSecureConnection type boolean UserName UserName is optional type: string UserName type string , nullable"
                                                              },
    "V1/Configuration/Schemas/OpcUa_DataSelection_schema.html":  {
                                                                     "href":  "V1/Configuration/Schemas/OpcUa_DataSelection_schema.html",
                                                                     "title":  "Sample Opc Ua data selection configuration",
                                                                     "keywords":  "Sample Opc Ua data selection configuration [{ \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.HotSideOutletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Hot Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1002.HotSideOutletTemperature\", \"StreamId\": null } ] # OPC UA data collection item schema | Abstract | Extensible | Status | Identifiable | Custom properties | Additional properties | Defined in | | ------------------- | ---------- | ------------ | ------------ | ----------------- | --------------------- | ------------------------------------------------------------------ | | Can be instantiated | Yes | Experimental | No | Forbidden | Forbidden | [OpcUa_DataSelection_schema.json](OpcUa_DataSelection_schema.json) | # DataCollectionItem properties | Property | Type | Required | Nullable | Defined by | | --------------------- | --------- | -------- | -------- | -------------------------------- | | [Name](#name) | `string` | Optional | Yes | DataCollectionItem (this schema) | | [NodeId](#nodeid) | `string` | Optional | Yes | DataCollectionItem (this schema) | | [Selected](#selected) | `boolean` | Optional | No | DataCollectionItem (this schema) | | [StreamId](#streamid) | `string` | Optional | Yes | DataCollectionItem (this schema) | ## Name `Name` - is optional - type: `string` - defined in this schema ### Name type `string`, nullable ## NodeId `NodeId` - is optional - type: `string` - defined in this schema ### NodeId type `string`, nullable ## Selected `Selected` - is optional - type: `boolean` - defined in this schema ### Selected type `boolean` ## StreamId `StreamId` - is optional - type: `string` - defined in this schema ### StreamId type `string`, nullable **All** of the following _requirements_ need to be fulfilled. #### Requirement 1 - []() ??? `#/definitions/EdgeConfigurationBase` `# definitions EdgeConfigurationBase` #### Requirement 2 `object` with following properties: | Property | Type | Required | | ---------- | ------- | -------- | | `Name` | string | Optional | | `NodeId` | string | Optional | | `Selected` | boolean | Optional | | `StreamId` | string | Optional | #### Name `Name` - is optional - type: `string` ##### Name type `string`, nullable #### NodeId `NodeId` - is optional - type: `string` ##### NodeId type `string`, nullable #### Selected `Selected` - is optional - type: `boolean` ##### Selected type `boolean` #### StreamId `StreamId` - is optional - type: `string` ##### StreamId type `string`, nullable"
                                                                 },
    "V1/Configuration/Schemas/Modbus_DataSource_schema.html":  {
                                                                   "href":  "V1/Configuration/Schemas/Modbus_DataSource_schema.html",
                                                                   "title":  "Sample Modbus data source configuration",
                                                                   "keywords":  "Sample Modbus data source configuration { \"IpAddress\": \"\u003cModbus IP Address\u003e\", \"Port\": \u003cPort - usually 502\u003e, \"ConnectTimeout\": 15000, \"ReconnectInterval\": 5000, \"RequestTimeout\": 9000, \"DelayBetweenRequests\": 0, \"MaxResponseDataLength\": 250 } Modbus data source configuration schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden Modbus_DataSource_schema.json DataSourceConfiguration properties Property Type Required Nullable Defined by ConnectTimeout integer Optional No DataSourceConfiguration (this schema) DelayBetweenRequests integer Optional No DataSourceConfiguration (this schema) IpAddress string Optional Yes DataSourceConfiguration (this schema) MaxResponseDataLength integer Optional No DataSourceConfiguration (this schema) Port integer Optional No DataSourceConfiguration (this schema) ReconnectInterval integer Optional No DataSourceConfiguration (this schema) RequestTimeout integer Optional No DataSourceConfiguration (this schema) StreamIdPrefix string Optional Yes DataSourceConfiguration (this schema) ConnectTimeout ConnectTimeout is optional type: integer defined in this schema ConnectTimeout type integer DelayBetweenRequests DelayBetweenRequests is optional type: integer defined in this schema DelayBetweenRequests type integer IpAddress IpAddress is optional type: string defined in this schema IpAddress type string , nullable MaxResponseDataLength MaxResponseDataLength is optional type: integer defined in this schema MaxResponseDataLength type integer Port Port is optional type: integer defined in this schema Port type integer ReconnectInterval ReconnectInterval is optional type: integer defined in this schema ReconnectInterval type integer RequestTimeout RequestTimeout is optional type: integer defined in this schema RequestTimeout type integer StreamIdPrefix StreamIdPrefix is optional type: string defined in this schema StreamIdPrefix type string , nullable All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required ConnectTimeout integer Optional DelayBetweenRequests integer Optional IpAddress string Optional MaxResponseDataLength integer Optional Port integer Optional ReconnectInterval integer Optional RequestTimeout integer Optional StreamIdPrefix string Optional ConnectTimeout ConnectTimeout is optional type: integer ConnectTimeout type integer DelayBetweenRequests DelayBetweenRequests is optional type: integer DelayBetweenRequests type integer IpAddress IpAddress is optional type: string IpAddress type string , nullable MaxResponseDataLength MaxResponseDataLength is optional type: integer MaxResponseDataLength type integer Port Port is optional type: integer Port type integer ReconnectInterval ReconnectInterval is optional type: integer ReconnectInterval type integer RequestTimeout RequestTimeout is optional type: integer RequestTimeout type integer StreamIdPrefix StreamIdPrefix is optional type: string StreamIdPrefix type string , nullable"
                                                               },
    "V1/Configuration/Schemas/Modbus_DataSelection_schema.html":  {
                                                                      "href":  "V1/Configuration/Schemas/Modbus_DataSelection_schema.html",
                                                                      "title":  "Sample Modbus data selection configuration",
                                                                      "keywords":  "Sample Modbus data selection configuration [{ \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 1, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 2, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 3, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 4, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 }, { \"Selected\": \"true\", \"UnitId\": 1, \"RegisterType\": 3, \"RegisterOffset\": 5, \"DataTypeCode\": 20, \"BitMap\": \"16151413\", \"ConversionFactor\": 2, \"ConversionOffset\": 3.4, \"ScanRate\": 500 } ] Modbus DataSelectionConfiguration schema Abstract Extensible Status Identifiable Custom properties Additional properties Defined in Can be instantiated Yes Experimental No Forbidden Forbidden Modbus_DataSelection_schema.json DataSelectionConfiguration properties Property Type Required Nullable Defined by BitMap string Optional Yes DataSelectionConfiguration (this schema) ConversionFactor number Optional Yes DataSelectionConfiguration (this schema) ConversionOffset number Optional Yes DataSelectionConfiguration (this schema) DataTypeCode integer Optional No DataSelectionConfiguration (this schema) Name string Optional Yes DataSelectionConfiguration (this schema) RegisterOffset integer Optional No DataSelectionConfiguration (this schema) RegisterType reference Optional No DataSelectionConfiguration (this schema) ScanRate integer Optional No DataSelectionConfiguration (this schema) Selected boolean Optional No DataSelectionConfiguration (this schema) StreamId string Optional Yes DataSelectionConfiguration (this schema) UnitId integer Optional No DataSelectionConfiguration (this schema) BitMap BitMap is optional type: string defined in this schema BitMap type string , nullable ConversionFactor ConversionFactor is optional type: number defined in this schema ConversionFactor type number , nullable ConversionOffset ConversionOffset is optional type: number defined in this schema ConversionOffset type number , nullable DataTypeCode DataTypeCode is optional type: integer defined in this schema DataTypeCode type integer Name Name is optional type: string defined in this schema Name type string , nullable RegisterOffset RegisterOffset is optional type: integer defined in this schema RegisterOffset type integer RegisterType RegisterType is optional type: reference defined in this schema RegisterType type ??? #/definitions/ModbusRegisterType # definitions ModbusRegisterType ScanRate ScanRate is optional type: integer defined in this schema ScanRate type integer Selected Selected is optional type: boolean defined in this schema Selected type boolean StreamId StreamId is optional type: string defined in this schema StreamId type string , nullable UnitId UnitId is optional type: integer defined in this schema UnitId type integer All of the following requirements need to be fulfilled. Requirement 1 ??? #/definitions/EdgeConfigurationBase # definitions EdgeConfigurationBase Requirement 2 object with following properties: Property Type Required BitMap string Optional ConversionFactor number Optional ConversionOffset number Optional DataTypeCode integer Optional Name string Optional RegisterOffset integer Optional RegisterType Optional ScanRate integer Optional Selected boolean Optional StreamId string Optional UnitId integer Optional BitMap BitMap is optional type: string BitMap type string , nullable ConversionFactor ConversionFactor is optional type: number ConversionFactor type number , nullable ConversionOffset ConversionOffset is optional type: number ConversionOffset type number , nullable DataTypeCode DataTypeCode is optional type: integer DataTypeCode type integer Name Name is optional type: string Name type string , nullable RegisterOffset RegisterOffset is optional type: integer RegisterOffset type integer RegisterType RegisterType is optional type: reference RegisterType type ??? #/definitions/ModbusRegisterType # definitions ModbusRegisterType ScanRate ScanRate is optional type: integer ScanRate type integer Selected Selected is optional type: boolean Selected type boolean StreamId StreamId is optional type: string StreamId type string , nullable UnitId UnitId is optional type: integer UnitId type integer"
                                                                  },
    "V1/Configuration/Schemas/EdgeSystem_schema.html":  {
                                                            "href":  "V1/Configuration/Schemas/EdgeSystem_schema.html",
                                                            "title":  "EdgeDataStoreConfiguration schema",
                                                            "keywords":  "EdgeDataStoreConfiguration schema \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"Components\": [{ \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"Modbus1\", \"componentType\": \"Modbus\" }, { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ], \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 } } Edge Data Store configuration schema Properties Property Type Required Nullable Defined by Storage StorageConfiguration Optional Yes StorageConfiguration System SystemConfiguration Optional Yes SystemConfiguration {ComponentName} {ComponentConfiguration} Optional Yes {ComponentConfiguration} Storage is optional type: StorageConfiguration System is optional type: SystemConfiguration {ComponentName} EdgeDataStoreConfiguration Schema Edge Data Store Configuration Schema Properties Storage System {ComponentName}"
                                                        },
    "V1/CommandLine/CommandLine.html":  {
                                            "href":  "V1/CommandLine/CommandLine.html",
                                            "title":  "Command line configuration of Edge Data Store",
                                            "keywords":  "Command line configuration of Edge Data Store Configuration and administration of the Edge Data Store on Linux and Windows can also be accomplished using the edgecmd command line tool. On Windows it is located in the directory: C:\\Program Files\\OSIsoft\\EdgeDataStore\\edgecmd.exe You should specify the full path when using it on Windows. On Linux the utility is installed in: /opt/OSIsoft/EdgeDataStore/edgecmd  opt OSIsoft EdgeDataStore edgecmd On Linux it can be accessed without using the full path. For the sake of simplicity the utility for the rest of this topic will be referred to as edgecmd, even though it is named edgecmd.exe on Windows and edgecmd on Linux. Most configurations options that can be done using REST can also be done using the edgecmd utility and command line arguments. Generally the configuration and administrative REST interfaces are exposed via the command line. Access to reading and writing data to the Edge Data Store Storage Component - OMF Ingress and SDS Read/Write Read Write capabilities are only available using the REST API."
                                        },
    "V1/SDS/SDS_Types.html":  {
                                  "href":  "V1/SDS/SDS_Types.html",
                                  "title":  "Types",
                                  "keywords":  "Types The Sequential Data Store (SDS) stores streams of events and provides convenient ways to find and associate events. Events are stored in streams, called SdsStreams. An SdsType defines the shape or structure of the event and how to associate events within the SdsStream. SdsTypes can define simple atomic types, such as integers, floats, strings, arrays, and dictionaries. They can also define complex types using SdsTypes. You can define complex, nested types using the Properties collection of an SdsType. An SdsType used to define an SdsStream must have a Key. A Key is a property, or a combination of properties that constitute an ordered, unique identity. The Key is ordered, so it functions as an index. It is known as the Primary Index. While a timestamp (DateTime) is a very common type of Key, any type that can be ordered is permitted. Other indexes (secondary indexes), are defined in the SdsStream. For more details on indexes, see Indexes . When you define a type, consider how the events will be represented in a stream. The SdsType defines each event in the stream. An event is a single unit whose properties have values that relate to the index; that is, each property of an SdsType event is related to the event???s index. Each event is a single unit. An SdsType is referenced by its identifier or Id field. SdsType identifiers must be unique within a Namespace. An SdsType can also refer other SdsTypes by using their identifiers. This enables type re-usability. Nested types and base types are automatically created as separate types. For further information, see Type Reusability SdsTypes define how events are associated and read within a collection of events, or SdsStream. The read characteristics when attempting to read non-existent indexes, indexes that fall between, before or after existing indexes, are determined by the interpolation and extrapolation settings of the SdsType. For more information about read characteristics, see Interpolation and Extrapolation . SdsTypes are immutable. After you create an SdsType, you cannot change its definition. If the definition of an SdsType is incorrect, you must delete and recreate it. In addition, the SdsType may be deleted only if no streams, stream views, or types reference it. Only SdsTypes used to define SdsStreams or SdsStreamViews are required to be added to the Sequential data store. SdsTypes that define properties or base types are contained within the parent SdsType and are not required to be added to the Data Store independently. The following table shows the required and optional SdsType fields. Fields that are not included are reserved for internal SDS use. For search limitations, see the Searching . Property Type Optionality Searchable Details Id String Required Yes Identifier for referencing the type Name String Optional Yes Friendly name Description String Optional Yes Description text SdsTypeCode SdsTypeCode Required No Numeric code identifying the base SdsType InterpolationMode SdsInterpolationMode Optional No Interpolation setting of the type. Default is Continuous. ExtrapolationMode SdsExtrapolationMode Optional No Extrapolation setting of the type. Default is All. Properties IList\u003cSdsTypeProperty\u003e Required Yes, with limitations List of SdsTypeProperty items Rules for the Type Identifier (SdsType.Id) Is not case sensitive Can contain spaces Cannot contain forward slash (\"/\") (\" \") Can contain a maximum of 100 characters SdsTypeCode The SdsTypeCode is a numeric identifier used by the Data Store to identify SdsTypes. A SdsTypeCode exists for every supported type. Atomic types, such as strings, floats and arrays, are defined entirely by the SdsTypeCode. Atomic types do not need fields to define the type. Types requiring additional definition, such as enums and objects, are identified using a generic SdsTypeCode, such as ByteEnum, Int32Enum, NullableInt32Enum, or Object, plus additional SdsProperty fields. Supported Types The following types are supported and defined by the SdsTypeCode: Type SdsTypeCode Array 400 Boolean 3 BooleanArray 203 Byte 6 ByteArray 206 ByteEnum 606 Char 4 CharArray 204 DateTime 16 DateTimeArray 216 DateTimeOffset 20 DateTimeOffsetArray 220 DBNull 2 Decimal 15 DecimalArray 215 Double 14 DoubleArray 214 Empty 0 Guid 19 GuidArray 219 IDictionary 402 IEnumerable 403 IList 401 Int16 7 Int16Array 207 Int16Enum 607 Int32 9 Int32Array 209 Int32Enum 609 Int64 11 Int64Array 211 Int64Enum 611 NullableBoolean 103 NullableByte 106 NullableByteEnum 706 NullableChar 104 NullableDateTime 116 NullableDateTimeOffset 120 NullableDecimal 115 NullableDouble 114 NullableGuid 119 NullableInt16 107 NullableInt16Enum 707 NullableInt32 109 NullableInt32Enum 709 NullableInt64 111 NullableInt64Enum 711 NullableSByte 105 NullableSByteEnum 705 NullableSingle 113 NullableTimeSpan 121 NullableUInt16 108 NullableUInt16Enum 708 NullableUInt32 110 NullableUInt32Enum 710 NullableUInt64 112 NullableUInt64Enum 712 Object 1 SdsColumn 510 SdsObject 512 SdsStream 507 SdsStreamIndex 508 SdsTable 509 SdsType 501 SdsTypeProperty 502 SdsValues 511 SdsStreamView 503 SdsStreamViewMap 505 SdsStreamViewMapProperty 506 SdsStreamViewProperty 504 SByte 5 SByteArray 205 SByteEnum 605 Single 13 SingleArray 213 String 18 StringArray 218 TimeSpan 21 TimeSpanArray 221 UInt16 8 UInt16Array 208 UInt16Enum 608 UInt32 10 UInt32Array 210 UInt32Enum 610 UInt64 12 UInt64Array 212 UInt64Enum 612 Version 22 VersionArray 222 Interpolation Interpolation determines how a stream behaves when asked to return an event at an index between two existing events. InterpolationMode determines how the returned event is constructed. The table below lists InterpolationModes: Mode Enumeration value Operation Default 0 The default InterpolationMode is Continuous Continuous 0 Interpolates the data using previous and next index values StepwiseContinuousLeading 1 Returns the data from the previous index StepwiseContinuousTrailing 2 Returns the data from the next index Discrete 3 Returns ???null??? Note that Continuous cannot return events for values that cannot be interpolated, such as when the type is not numeric. The table below describes how the Continuous InterpolationMode affects indexes that occur between data in a stream: InterpolationMode = Continuous or Default Type Result for an index between data in a stream Comment Numeric Types Interpolated* Rounding is done as needed for integer types Time related Types Interpolated DateTime, DateTimeOffset, TimeSpan Nullable Types Interpolated** Limited support for nullable numeric types Array and List Types No event is returned String Type No event is returned Boolean Type Returns value of nearest index Enumeration Types Returns Enum value at 0 This may have a value for the enumeration GUID No event is returned Version No event is returned IDictionary or IEnumerable No event is returned Dictionary, Array, List, and so on. *When extreme values are involved in an interpolation (for example Decimal.MaxValue) the call might result in a BadRequest exception. **Nullable types are interpolated in the same manner as their non-nulllable equivalents as long as the values surrounding the desired interpolation index are non-null. If either of the values are null, the interpolated value will be null. If the InterpolationMode is not assigned, the events are interpolated in the default manner, unless the interpolation mode is overridden in the SdsTypeProperty or the SdsStream. For more information on overriding the interpolation mode on a specific type property, see SdsTypeProperty . For more information on overriding the interpolation mode for a specific stream, see Sds Streams . Extrapolation Extrapolation defines how a stream responds to requests with indexes that precede or follow all data in the steam. ExtrapolationMode acts as a master switch to determine whether extrapolation occurs and at which end of the data. ExtrapolationMode works with the InterpolationMode to determine how a stream responds. The following tables show how ExtrapolationMode affects returned values for each InterpolationMode value: ExtrapolationMode with InterpolationMode = Default or Continuous ExtrapolationMode Enumeration value Index before data Index after data All 0 Returns first data value Returns last data value None 1 No event is returned No event is returned Forward 2 No event is returned Returns last data value Backward 3 Returns first data value No event is returned ExtrapolationMode with InterpolationMode = Discrete ExtrapolationMode Enumeration value Index before data Index after data All 0 No event is returned No event is returned None 1 No event is returned No event is returned Forward 2 No event is returned No event is returned Backward 3 No event is returned No event is returned ExtrapolationMode with InterpolationMode = StepwiseContinuousLeading ExtrapolationMode Enumeration value Index before data Index after data All 0 Returns first data value Returns last data value None 1 No event is returned No event is returned Forward 2 No event is returned Returns last data value Backward 3 Returns first data value No event is returned ExtrapolationMode with InterpolationMode = StepwiseContinuousTrailing ExtrapolationMode Enumeration value Index before data Index after data All 0 Returns first data value Returns last data value None 1 No event is returned No event is returned Forward 2 No event is returned Returns last data value Backward 3 Returns first data value No event is returned If the ExtrapolationMode is not assigned, the events are extrapolated in the default manner, unless the extrapolation mode is overridden on the SdsStream. For more information on overriding the extrapolation mode on a specific stream, see Sds Streams . For additional information about the effect of read characteristics, see the documentation on the read method you are using. SdsTypeProperty The Properties collection define the fields in an SdsType. The following table shows the required and optional SdsTypeProperty fields. Fields that are not included are reserved for internal SDS use. Property Type Optionality Details Id String Required Identifier for referencing the type Name String Optional Friendly name Description String Optional Description text SdsType SdsType Required Field defining the property\u0027s Type IsKey Boolean Required Identifies the property as the Key (Primary Index) Value Object Optional Value of the property Order Int Optional Order of comparison within a compound index InterpolationMode SdsInterpolationMode Optional Interpolation setting of the property. Default is null. Uom String Optional Unit of Measure of the property The SdsTypeProperty???s identifier follows the same rules as the SdsType???s identifier. IsKey is a Boolean value used to identify the SdsType???s Key. A Key defined by more than one Property is called a compound key. The maximum number of Properties that can define a compound key is three. In a compound key, each Property that is included in the Key is specified as IsKey. The Order field defines the precedence of fields applied to the Index. The Value field is used for properties that represent a value. An example of a property with a value is an enum???s named constant. When representing an enum in a SdsType, the SdsType???s Properties collection defines the enum???s constant list. The SdsTypeProperty???s Identifier represents the constant???s name and the SdsTypeProperty???s Value represents the constant???s value (see the enum State definitions below). InterpolationMode is assigned when the property of the event should be interpolated in a specific way that differs from the InterpolationMode of the SdsType. InterpolationMode is only applied to a property that is not part of the Index. If the InterpolationMode is not set, the property is are interpolated in the manner defined by the SdsType???s IntepolationMode. An SdsType with the InterpolationMode set to Discrete cannot have a Property with an InteroplationMode. For more information on interpolation of events, see Interpolation . Uom is the unit of measure for the property. The Uom of a property may be specified by the name or the abbreviation. The names and abbreviations of Uoms are case sensitive. The InterpolationMode and Uom of a property can be overridden on the stream. For more information, see Streams . Supported Units of Measure For a list of units of measures that are supported for an SdsTypeProperty, see Units of Measure . Working with SdsTypes The following discussion refers to the following types and are defined in Python and JavaScript samples. In the sample code, SdsType , SdsTypeProperty , and SdsTypeCode are defined as in the code snippets shown here: Python class SdsTypeCode(Enum): Empty = 0 Object = 1 DBNull = 2 Boolean = 3 Char = 4 ... class SdsTypeProperty(object): \"\"\"SDS type property definition\"\"\" def __init__(self): self.__isKey = False @property def Id(self): return self.__id @Id.setter def Id(self, id): self.__id = id ... @property def IsKey(self): return self.__isKey @IsKey.setter def IsKey(self, iskey): self.__isKey = iskey @property def SdsType(self): return self.__SdsType @SdsType.setter def SdsType(self, SdsType): self.__SdsType=SdsType ... class SdsType(object): \"\"\"SDS type definitions\"\"\" def __init__(self): self.SdsTypeCode = SdsTypeCode.Object @property def Id(self): return self.__id @Id.setter def Id(self, id): self.__id = id ... @property def BaseType(self): return self.__baseType @BaseType.setter def BaseType(self, baseType): self.__baseType = baseType @property def SdsTypeCode(self): return self.__typeCode @SdsTypeCode.setter def SdsTypeCode(self, typeCode): self.__typeCode = typeCode @property def Properties(self): return self.__properties @Properties.setter def Properties(self, properties): self.__properties = properties JavaScript SdsTypeCodeMap: { Empty: 0, \"Object\": 1, DBNull: 2, \"Boolean\": 3, Char: 4, ... SdsTypeProperty: function (SdsTypeProperty) { if (SdsTypeProperty.Id) { this.Id = SdsTypeProperty.Id; } if (SdsTypeProperty.Name) { this.Name = SdsTypeProperty.Name; } if (SdsTypeProperty.Description) { this.Description = SdsTypeProperty.Description; } if (SdsTypeProperty.SdsType) { this.SdsType = SdsTypeProperty.SdsType; } if (SdsTypeProperty.IsKey) { this.IsKey = SdsTypeProperty.IsKey; } }, SdsType: function (SdsType) { if (SdsType.Id) { this.Id = SdsType.Id } if (SdsType.Name) { this.Name = SdsType.Name; } if (SdsType.Description) { this.Description = SdsType.Description; } if (SdsType.SdsTypeCode) { this.SdsTypeCode = SdsType.SdsTypeCode; } if (SdsType.Properties) { this.Properties = SdsType.Properties; } }, Working with the following types (both Python and JavaScript classes are shown): Python class State(Enum): Ok = 0 Warning = 1 Alarm = 2 class Simple(object): Time = property(getTime, setTime) def getTime(self): return self.__time def setTime(self, time): self.__time = time State = property(getState, setState) def getState(self): return self.__state def setState(self, state): self.__state = state Measurement = property(getMeasurement, setMeasurement) def getMeasurement(self): return self.__measurement def setMeasurement(self, measurement): self.__measurement = measurement JavaScript var State = { Ok: 0, Warning: 1, Alarm: 2, } var Simple = function () { this.Time = null; this.State = null; this.Measurement = null; } Define the SdsType as follows: Python # Create the properties # Time is the primary key time = SdsTypeProperty() time.Id = \"Time\" time.Name = \"Time\" time.IsKey = True time.SdsType = SdsType() time.SdsType.Id = \"DateTime\" time.SdsType.Name = \"DateTime\" time.SdsType.SdsTypeCode = SdsTypeCode.DateTime # State is not a pre-defined type. A SdsType must be defined to represent the enum stateTypePropertyOk = SdsTypeProperty() stateTypePropertyOk.Id = \"Ok\" stateTypePropertyOk.Value = State.Ok stateTypePropertyWarning = SdsTypeProperty() stateTypePropertyWarning.Id = \"Warning\" stateTypePropertyWarning.Value = State.Warning stateTypePropertyAlarm = SdsTypeProperty() stateTypePropertyAlarm.Id = \"Alarm\" stateTypePropertyAlarm.Value = State.Alarm stateType = SdsType() stateType.Id = \"State\" stateType.Name = \"State\" stateType.Properties = [ stateTypePropertyOk, stateTypePropertyWarning, \\ stateTypePropertyAlarm ] state = SdsTypeProperty() state.Id = \"State\" state.Name = \"State\" state.SdsType = stateType # Value property is a simple non-indexed, pre-defined type value = SdsTypeProperty() value.Id = \"Measurement\" value.Name = \"Measurement\" value.SdsType = SdsType() value.SdsType.Id = \"Double\" value.SdsType.Name = \"Double\" # Create the Simple SdsType simpleType = SdsType() simpleType.Id = \"Simple\" simpleType.Name = \"Simple\" simpleType.Description = \"Basic sample type\" simpleType.SdsTypeCode = SdsTypeCode.Object simpleType.Properties = [ time ] JavaScript //    Time is the primary key var timeProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Time\", \"IsKey\": true, \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"dateType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.DateTime }) }); //    State is not a pre-defined type. An SdsType must be defined to represent the enum var stateTypePropertyOk = new SdsObjects.SdsTypeProperty({ \"Id\": \"Ok\", \"Value\": State.Ok }); var stateTypePropertyWarning = new SdsObjects.SdsTypeProperty({ \"Id\": \"Warning\", \"Value\": State.Warning }); var stateTypePropertyAlarm = new SdsObjects.SdsTypeProperty({ \"Id\": \"Alarm\", \"Value\": State.Alarm }); var stateType = new SdsObjects.SdsType({ \"Id\": \"State\", \"Name\": \"State\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Int32Enum, \"Properties\": [stateTypePropertyOk, stateTypePropertyWarning, stateTypePropertyAlarm, stateTypePropertyRed] }); //    Measurement property is a simple non-indexed, pre-defined type var measurementProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"doubleType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Double }) }); //    Create the Simple SdsType var simpleType = new SdsObjects.SdsType({ \"Id\": \"Simple\", \"Name\": \"Simple\", \"Description\": \"This is a simple SDS type \", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Object, \"Properties\": [timeProperty, stateProperty, measurementProperty] }); Working with a derived class is easy. For the following derived class: class Derived(Simple): @property def Observation(self): return self.__observation @Observation.setter def Observation(self, observation): self.__observation = observation Extend the SdsType as follows: Python # Observation property is a simple non-indexed, standard data type observation = SdsTypeProperty() observation.Id = \"Observation\" observation.Name = \"Observation\" observation.SdsType = SdsType() observation.SdsType.Id = \"String\" observation.SdsType.Name = \"String\" observation.SdsType.SdsTypeCode = SdsTypeCode.String # Create the Derived SdsType derived = SdsType() derived.Id = \"Derived\" derived.Name = \"Derived\" derived.Description = \"Derived sample type\" derived.BaseType = simpleType # Set the base type to the derived type derived.SdsTypeCode = SdsTypeCode.Object derived.Properties = [ observation ] JavaScript var observationProprety = new SdsObjects.SdsTypeProperty({ \"Id\": \"Observation\", \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"strType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.String }) }); var derivedType = new SdsObjects.SdsType({ \"Id\": \"Derived\", \"Name\": \"Derived\", \"Description\": \" Derived sample type\", \"BaseType\": simpleType, \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Object, \"Properties\": [ observationProprety ] }); Type Reusability An SdsType can also refer other SdsTypes by using their identifiers. This enables type re-usability. For example, if there is a common index and value property for a group of types that may have additional properties, a base type can be created with those properties. { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"SdsTypeCode\": 16 } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] } If a new type should be created with properties additional to the ones above, you can add a reference to the base type by simply specifying the base type\u0027s Id. { \"Id\": \"Complex\", \"Name\": \"Complex\", \"SdsTypeCode\": 1, \"BaseType\":{ \"Id\":\"Simple\" }, \"Properties\": [ { \"Id\": \"Depth\", \"Name\": \"Depth\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] } The new type may also include the full type definition of the reference type instead of specifying only the Id. For example: { \"Id\": \"Complex\", \"Name\": \"Complex\", \"SdsTypeCode\": 1, \"BaseType\":{ \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"SdsTypeCode\": 16 } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] }, \"Properties\": [ { \"Id\": \"Depth\", \"Name\": \"Depth\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] } If the full definition is sent, the referenced types (base type \"Simple\" in the above example) should match the actual type initially created. If the full definition is sent and the referenced types do not exist, they will be created automatically by SDS. Further type creations can reference them as demonstrated above. Note: When trying to get types back from SDS, the results will also include types that were automatically created by SDS. Base types and properties of type Object, Enum, user-defined collections, such as, Array, List and Dictionary will be treated as referenced types. Note that streams cannot be created using these referenced types. If a stream of particular type is to be created, the type should contain at least one property with a valid index type as described in this section, Indexes . The index property may also be in the base type as shown in the example above. SdsType API The REST APIs provide programmatic access to read and write SDS data. The APIs in this section interact with SdsTypes. See Types for general SdsType information. Get Type Returns the type corresponding to the specified typeId within a given namespace. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Types/{typeId} api v1 Tenants default Namespaces {namespaceId} Types {typeId} Parameters string namespaceId default or diagnostics string typeId The type identifier Response The response includes a status code and a response body. Response body The requested SdsType Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"Id\": \"19a87a76-614a-385b-ba48-6f8b30ff6ab2\", \"Name\": \"DateTime\", \"SdsTypeCode\": 16 } }, { \"Id\": \"State\", \"Name\": \"State\", \"SdsType\": { \"Id\": \"e20bdd7e-590b-3372-ab39-ff61950fb4f3\", \"Name\": \"State\", \"SdsTypeCode\": 609, \"Properties\": [ { \"Id\": \"Ok\", \"Value\": 0 }, { \"Id\": \"Warning\", \"Value\": 1 }, { \"Id\": \"Alarm\", \"Value\": 2 } ] } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"Id\": \"6fecef77-20b1-37ae-aa3b-e6bb838d5a86\", \"Name\": \"Double\", \"SdsTypeCode\": 14 } } ] } Get Type Reference Count Returns a dictionary mapping the object name to the number of references held by streams, stream views and parent types for the specified type. For more information on the use of types to define streams and stream views, see Streams and Steam Views . For further details about type referencing, see: Type Reusability . Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Types/{typeId}/ReferenceCount api v1 Tenants default Namespaces {namespaceId} Types {typeId} ReferenceCount Parameters string namespaceId default or diagnostics string typeId The type identifier Response The response includes a status code and a response body. Response body A dictionary mapping object name to number of references. Example response body: { \"SdsStream\": 3, \"SdsStreamView\": 2, \"SdsType\": 1 } Get Types Returns a list of types within a given namespace. If specifying the optional search query parameter, the list of types returned will match the search criteria. If the search query parameter is not specified, the list will include all types in the namespace. For information about specifying those respective parameters, see Searching . Note: The results will also include types that were automatically created by SDS as a result of type referencing. For further details about type referencing, see: Type Reusability . Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Types?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} api v1 Tenants default Namespaces {namespaceId} Types?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} Parameters string namespaceId default or diagnostics string query An optional query string to match which SdsTypes will be returned. For information about specifying the query parameter, see the Searching topic. int skip An optional value representing the zero-based offset of the first SdsType to retrieve. If not specified, a default value of 0 is used. int count An optional value representing the maximum number of SdsTypes to retrieve. If not specified, a default value of 100 is used. string orderby An optional parameter representing sorted order which SdsTypes will be returned. A field name is required. The sorting is based on the stored values for the given field (of type string). For example, orderby=name would sort the returned results by the name values (ascending by default). Additionally, a value can be provided along with the field name to identify whether to sort ascending or descending, by using values asc or desc , respectively. For example, orderby=name desc would sort the returned results by the name values, descending. If no value is specified, there is no sorting of results. Response The response includes a status code and a response body. Response body A collection of zero or more SdsTypes Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"Id\": \"19a87a76-614a-385b-ba48-6f8b30ff6ab2\", \"Name\": \"DateTime\", \"SdsTypeCode\": 16 } }, { \"Id\": \"State\", \"Name\": \"State\", \"SdsType\": { \"Id\": \"e20bdd7e-590b-3372-ab39-ff61950fb4f3\", \"Name\": \"State\", \"SdsTypeCode\": 609, \"Properties\": [ { \"Id\": \"Ok\", \"Value\": 0 }, { \"Id\": \"Warning\", \"Value\": 1 }, { \"Id\": \"Alarm\", \"Value\": 2 } ] } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"Id\": \"6fecef77-20b1-37ae-aa3b-e6bb838d5a86\", \"Name\": \"Double\", \"SdsTypeCode\": 14 } } ] }, ] Get or Create Type Creates the specified type. If a type with a matching identifier already exists, SDS compares the existing type with the type that was sent. If the types are identical, a Found (302) error is returned with the Location header set to the URI where the type may be retrieved using a Get function. If the types do not match, a Conflict (409) error is returned. Note: A Conflict (409) error will also be returned if the type contains reference to any existing type, but the referenced type definition in the body does not match the existing type. You may reference an existing type without including the reference type definition in the body by using only the Ids. For further details about type referencing, see: Type Reusability . For a matching type ( Found ), clients that are capable of performing a redirect that includes the authorization header can automatically redirect to retrieve the type. However, most clients, including the .NET HttpClient, consider redirecting with the authorization token to be a security vulnerability. When a client performs a redirect and strips the authorization header, SDS cannot authorize the request and returns Unauthorized (401). For this reason, OSIsoft recommends that when using clients that do not redirect with the authorization header, you should disable automatic redirect and perform the redirect manually. Request POST api/v1/Tenants/default/Namespaces/{namespaceId}/Types/{typeId} api v1 Tenants default Namespaces {namespaceId} Types {typeId} Parameters string namespaceId default or diagnostics string typeId The type identifier. The identifier must match the SdsType.Id field in the request body. Request body The request content is the serialized SdsType. Example SdsType content: { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"Id\": \"19a87a76-614a-385b-ba48-6f8b30ff6ab2\", \"Name\": \"DateTime\", \"SdsTypeCode\": 16 } }, { \"Id\": \"State\", \"Name\": \"State\", \"SdsType\": { \"Id\": \"e20bdd7e-590b-3372-ab39-ff61950fb4f3\", \"Name\": \"State\", \"SdsTypeCode\": 609, \"Properties\": [ { \"Id\": \"Ok\", \"Value\": 0 }, { \"Id\": \"Warning\", \"Value\": 1 }, { \"Id\": \"Alarm\", \"Value\": 2 } ] } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"Id\": \"6fecef77-20b1-37ae-aa3b-e6bb838d5a86\", \"Name\": \"Double\", \"SdsTypeCode\": 14 } } ] } Response The response includes a status code and a response body. Response body The request content is the serialized SdsType. OSIsoft recommends that you use JSON. Example Response body: HTTP/1.1 HTTP 1.1 201 Content-Type: application/json application json { \"Id\": \"Simple\", \"Name\": \"Simple\", \"Description\": null, \"SdsTypeCode\": 1, \"IsGenericType\": false, \"IsReferenceType\": false, \"GenericArguments\": null, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"Description\": null, \"Order\": 0, \"IsKey\": true, \"FixedSize\": 0, \"SdsType\": { \"Id\": \"19a87a76-614a-385b-ba48-6f8b30ff6ab2\", \"Name\": \"DateTime\", \"Description\": null, \"SdsTypeCode\": 16, \"IsGenericType\": false, \"IsReferenceType\": false, \"GenericArguments\": null, \"Properties\": null, \"BaseType\": null, \"DerivedTypes\": null, \"InterpolationMode\": 0, \"ExtrapolationMode\": 0 }, \"Value\": null, \"Uom\": null, \"InterpolationMode\": null }, { \"Id\": \"State\", \"Name\": \"State\", \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": { \"Id\": \"e20bdd7e-590b-3372-ab39-ff61950fb4f3\", \"Name\": \"State\", \"Description\": null, \"SdsTypeCode\": 609, \"IsGenericType\": false, \"IsReferenceType\": false, \"GenericArguments\": null, \"Properties\": [ { \"Id\": \"Ok\", \"Name\": null, \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": null, \"Value\": 0, \"Uom\": null, \"InterpolationMode\": null }, { \"Id\": \"Warning\", \"Name\": null, \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": null, \"Value\": 1, \"Uom\": null, \"InterpolationMode\": null }, { \"Id\": \"Alarm\", \"Name\": null, \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": null, \"Value\": 2, \"Uom\": null, \"InterpolationMode\": null } ], \"BaseType\": null, \"DerivedTypes\": null, \"InterpolationMode\": 0, \"ExtrapolationMode\": 0 }, \"Value\": null, \"Uom\": null, \"InterpolationMode\": null }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"Description\": null, \"Order\": 0, \"IsKey\": false, \"FixedSize\": 0, \"SdsType\": { \"Id\": \"6fecef77-20b1-37ae-aa3b-e6bb838d5a86\", \"Name\": \"Double\", \"Description\": null, \"SdsTypeCode\": 14, \"IsGenericType\": false, \"IsReferenceType\": false, \"GenericArguments\": null, \"Properties\": null, \"BaseType\": null, \"DerivedTypes\": null, \"InterpolationMode\": 0, \"ExtrapolationMode\": 0 }, \"Value\": null, \"Uom\": null, \"InterpolationMode\": null } ], \"BaseType\": null, \"DerivedTypes\": null, \"InterpolationMode\": 0, \"ExtrapolationMode\": 0 } Delete Type Deletes a type from the specified tenant and namespace. Note that a type cannot be deleted if any streams, stream views, or other types reference it. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Types/{typeId} api v1 Tenants default Namespaces {namespaceId} Types {typeId} Parameters string namespaceId default or diagnostics string typeId The type identifier Response The response includes a status code."
                              },
    "V1/SDS/SDS_Streams.html":  {
                                    "href":  "V1/SDS/SDS_Streams.html",
                                    "title":  "Streams",
                                    "keywords":  "Streams SDS stores collections of events and provides convenient ways to find and associating events. Events of consistent structure are stored in streams, called SdsStreams. An SdsType defines the structure of events in an SdsStream. SdsStreams are referenced by their identifier or Id field. SdsStream identifiers must be unique within a namespace. An SdsStream must include a TypeId that references the identifier of an existing SdsType. When an SdsStream contains data, you must use a stream view to update the stream type. The following table shows the required and optional SdsStream fields. Fields not listed are reserved for internal SDS use. Property Type Optionality Searchability Details Id String Required Yes An identifier for referencing the stream TypeId String Required Yes The SdsType identifier of the type to be used for this stream Name String Optional Yes Friendly name Description String Optional Yes Description text Indexes IList\u003cSdsStreamIndex\u003e Optional No Used to define secondary indexes for stream InterpolationMode SdsInterpolationMode Optional No Interpolation setting of the stream. Default is null. ExtrapolationMode SdsExtrapolationMode Optional No Extrapolation setting of the stream. Default is null. PropertyOverrides IList\u003cSdsStreamPropertyOverride\u003e Optional No Used to define unit of measure and interpolation mode overrides for a stream. Tags * IList\u003cString\u003e Optional Yes A list of tags denoting special attributes or categories. Metadata * IDictionary\u003cString, String\u003e Optional Yes A dictionary of string keys and associated string values. * Notes regarding Tags and Metadata: Stream Tags and Metadata are accessed via the Tags API And Metadata API respectively. However, they are associated with SdsStream objects and can be used as search criteria. Rules for the Stream Identifier (SdsStream.Id) Is not case sensitive Can contain spaces Cannot contain forward slash (\"/\") (\" \") Can contain a maximum of 100 characters Indexes The Key or Primary Index is defined at the SdsType. Secondary Indexes are defined at the SdsStream. Secondary Indexes are applied to a single property; there are no compound secondary indexes. Only SdsTypeCodes that can be ordered are supported for use in a secondary index. Indexes are discussed in greater detail here: Indexes Interpolation and Extrapolation The InterpolationMode, ExtrapolationMode, and PropertyOverrides can be used to determine how a specific stream reads data. These read characteristics are inherited from the type if they are not defined at the stream level. For more information about type read characteristics and how these characteristics dictate how events are read see Types . PropertyOverrides PropertyOverrides provide a way to override interpolation behavior and unit of measure for individual SdsType Properties for a specific stream. The SdsStreamPropertyOverride object has the following structure: Property Type Optionality Details SdsTypePropertyId String Required SdsTypeProperty identifier InterpolationMode SdsInterpolationMode Optional Interpolation setting. Default is null Uom String Optional Unit of measure The unit of measure can be overridden for any type property defined by the stream type, including primary keys and secondary indexes. For more information about type property units of measure see Types . Read characteristics of the stream are determined by the type and the PropertyOverrides of the stream. The interpolation mode for non-index properties can be defined and overridden at the stream level. For more information about type read characteristics see Types . When specifying property interpolation overrides, if the SdsType InterpolationMode is Discrete , it cannot be overridden at any level. When InterpolationMode is set to Discrete and an event it not defined for that index, a null value is returned for the entire event. SdsStream API The REST APIs provide programmatic access to read and write SDS data. The APIs in this section interact with SdsStreams. See Streams for general SdsStream information. Get Stream Returns the specified stream. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code and a response body. Response body The requested SdsStream. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Id\":\"Simple\", \"Name\":\"Simple\", \"TypeId\":\"Simple\", } Get Streams Returns a list of streams. If the optional search query parameter is specified, the list of streams returned will match the search criteria. If the search query parameter is not specified, the list will include all streams in the namespace. See Searching for information about specifying those respective parameters. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} api v1 Tenants default Namespaces {namespaceId} Streams?query={query}\u0026skip={skip}\u0026count={count}\u0026orderby={orderby} Parameters string namespaceId default or diagnostics string query An optional parameter representing a string search. For information about specifying the search parameter, see Searching . int skip An optional parameter representing the zero-based offset of the first SdsStream to retrieve. If not specified, a default value of 0 is used. int count An optional parameter representing the maximum number of SdsStreams to retrieve. If not specified, a default value of 100 is used. string orderby An optional parameter representing sorted order which SdsStreams will be returned. A field name is required. The sorting is based on the stored values for the given field (of type string). For example, orderby=name would sort the returned results by the name values (ascending by default). Additionally, a value can be provided along with the field name to identify whether to sort ascending or descending, by using values asc or desc , respectively. For example, orderby=name desc would sort the returned results by the name values, descending. If no value is specified, there is no sorting of results. Response The response includes a status code and a response body. Response body A collection of zero or more SdsStreams. Example response body: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Id\":\"Simple\", \"TypeId\":\"Simple\" }, { \"Id\":\"Simple with Secondary\", \"TypeId\":\"Simple\", \"Indexes\":[ { \"SdsTypePropertyId\":\"Measurement\" } ] }, { \"Id\":\"Compound\", \"TypeId\":\"Compound\" }, ] Get Stream Type Returns the type definition that is associated with a given stream. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Type api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Type Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code and a response body. Response body The requested SdsType. Get or Create Stream Creates the specified stream. If a stream with a matching identifier already exists, SDS compares the existing stream with the stream that was sent. If the streams are identical, a Found (302) error is returned with the Location header set to the URI where the stream may be retrieved using a Get function. If the streams do not match, a Conflict (409) error is returned. For a matching stream (Found), clients that are capable of performing a redirect that includes the authorization header can automatically redirect to retrieve the stream. However, most clients, including the .NET HttpClient, consider redirecting with the authorization token to be a security vulnerability. When a client performs a redirect and strips the authorization header, SDS cannot authorize the request and returns Unauthorized (401). For this reason, it is recommended that when using clients that do not redirect with the authorization header, you should disable automatic redirect. Request POST api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Parameters string namespaceId default or diagnostics string streamId The stream identifier. The stream identifier must match the identifier in content. Request body The request content is the serialized SdsStream. Response The response includes a status code and a response body. Response body The newly created SdsStream. Create or Update Stream Creates the specified stream. If a stream with the same Id already exists, the definition of the stream is updated. The following changes are permitted: Name Description Indexes InterpolationMode ExtrapolationMode PropertyOverrides Note that modifying Indexes will result in re-indexing all of the stream\u0027s data for each additional secondary index. For more information on secondary indexes, see Indexes . Unpermitted changes result in an error. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Parameters string namespaceId default or diagnostics string streamId The stream identifier Request body The request content is the serialized SdsStream. Response The response includes a status code. Update Stream Type Updates a stream???s type. The type is modified to match the specified stream view. Defined Indexes and PropertyOverrides are removed when updating a stream type. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Type?streamViewId={streamViewId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Type?streamViewId={streamViewId} Parameters string namespaceId default or diagnostics string streamId The stream identifier string streamViewId The stream view identifier Request body The request content is the serialized SdsStream. Response The response includes a status code. Response body On failure, the content contains a message describing the issue. Delete Stream Deletes a stream. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code."
                                },
    "V1/SDS/SdsStreamExtra.html":  {
                                       "href":  "V1/SDS/SdsStreamExtra.html",
                                       "title":  "Stream Metadata and Tags",
                                       "keywords":  "Stream Metadata and Tags SdsStream metadata is represented as a dictionary of string keys and associated string values. It can be used to associate additional information with a stream. SdsStream tags are represented as a list of strings. Tags can be used to categorize or denote special attributes of streams. The SdsStream Metadata API And SdsStream Tags API do not accept the search query parameter in their respective Get calls. However, stream tags and metadata can be used as criteria in search query strings to return SdsStream results with the Stream API. SdsStream Metadata API Get stream metadata Returns the metadata dictionary for the specified stream. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Metadata api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Metadata Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code and a response body. Response body The metadata for the specified SdsStream. Sample response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"a metadata key\":\"a metadata value\", \"another key\":\"another value\" } Security Allowed for administrator and user accounts Get stream metadata value Returns the value for the specified key in the metadata dictionary of the specified stream. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Metadata/{key} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Metadata {key} Parameters string namespaceId default or diagnostics string streamId The stream identifier string key The key specifying the metadata value of interest Response The response includes a status code and a response body. Response body The metadata for the specified SdsStream. Sample response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"a metadata value??? } Security Allowed for administrator and user accounts Update stream metadata Replaces the metadata for the specified stream with the metadata in the request body. Overwrites any existing metadata; does not merge. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Metadata api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Metadata Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code. Security Allowed for administrator accounts Delete stream metadata Deletes the metadata for the specified stream. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Metadata api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Metadata Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code. Security Allowed for administrator accounts SdsStream Tags API Get stream tags Returns the tag list for the specified stream. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Tags api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Tags Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code and a response body. Response body The tags for the specified SdsStream. Sample response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ \"a tag\", \"another tag\" ] Security Allowed for administrator and user accounts Update stream tags Replaces the tag list for the specified stream with the tags listed in the request body. Overwrites any existing tags; does not merge. Request PUT api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Tags api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Tags Parameters string namespaceId default or diagnostics string streamId The stream identifier The request content is the serialized list of tags. Response The response includes a status code. Security Allowed by administrator accounts. Delete stream tags Deletes the tag list for the specified stream. Request DELETE api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Tags api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Tags Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code. Security Allowed for administrator accounts."
                                   },
    "V1/SDS/Reading_Data_API.html":  {
                                         "href":  "V1/SDS/Reading_Data_API.html",
                                         "title":  "API calls for reading data",
                                         "keywords":  "API calls for reading data Example Type, Stream, and Data Many of the API methods described below contain example requests and responses in JSON to highlight usage and specific behaviors. The following type, stream, and data are used in the examples. Example Type SimpleType is an SdsType with a single index. This type is defined in Python and Javascript: Python class State(Enum): Ok = 0 Warning = 1 Alarm = 2 class SimpleType(object): Time = property(getTime, setTime) def getTime(self): return self.__time def setTime(self, time): self.__time = time State = property(getState, setState) def getState(self): return self.__state def setState(self, state): self.__state = state Measurement = property(getValue, setValue) def getValue(self): return self.__measurement def setValue(self, measurement): self.__measurement = measurement JavaScript var State = { Ok: 0, Warning: 1, Alarm: 2, } var SimpleType = function () { this.Time = null; this.State = null; this.Value = null; } Example Stream Simple is an SdsStream of type SimpleType . Example Data Simple has stored values as follows: 11/23/2017 11 23 2017 12:00:00 PM: Ok 0 11/23/2017 11 23 2017 1:00:00 PM: Ok 10 11/23/2017 11 23 2017 2:00:00 PM: Ok 20 11/23/2017 11 23 2017 3:00:00 PM: Ok 30 11/23/2017 11 23 2017 4:00:00 PM: Ok 40 All times are represented at offset 0, GMT. Get First Value Returns the first value in the stream. If no values exist in the stream, null is returned. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/First api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data First Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code and a response body containing a serialized event. Get Last Value Returns the last value in the stream. If no values exist in the stream, null is returned. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Last api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Last Parameters string namespaceId default or diagnostics string streamId The stream identifier Response The response includes a status code and a response body containing a serialized event. Find Distinct Value Returns a stored event based on the specified index and searchMode . Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?index={index}\u0026searchMode={searchMode} Parameters string namespaceId default or diagnostics string streamId The stream identifier string index The index string searchMode The SdsSearchMode , the default is exact Response The response includes a status code and a response body containing a serialized collection with one event. Depending on the request index and searchMode , it is possible to have an empty collection returned. Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?index=2017-11-23T13:00:00Z\u0026searchMode=Next The request has an index that matches the index of an existing event, but since a SdsSearchMode of next was specified, the response contains the next event in the stream after the specified index: Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ] Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?index=2017-11-23T13:30:00Z\u0026searchMode=Next The request specifies an index that does not match an index of an existing event. The next event in the stream is retrieved. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ] Get Values Returns a collection of stored values at indexes based on request parameters. SDS supports three ways of specifying which stored events to return: Filtered : A filtered request accepts a filter expression . Range : A range request accepts a start index and a count. Window : A window request accepts a start index and end index. This request has an optional continuation token for large collections of events. Filtered Returns a collection of stored values as determined by a filter . The filter limits results by applying an expression against event fields. Filter expressions are explained in detail in the Filter expressions section. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?filter={filter} Parameters string namespaceId default or diagnostics string streamId The stream identifier string filter The filter expression (see Filter expressions ) Response The response includes a status code and a response body containing a serialized collection of events. Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?filter=Measurement gt 10 The events in the stream with Measurement greater than 10 are returned. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"Measurement\": 40 } ] Note: State is not included in the JSON as its value is the default value. Range Returns a collection of stored values as determined by a startIndex and count . Additional optional parameters specify the direction of the range, how to handle events near or at the start index, whether to skip a certain number of events at the start of the range, and how to filter the data. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data ?startIndex={startIndex}\u0026count={count}[\u0026skip={skip}\u0026reversed={reversed} \u0026boundaryType={boundaryType}\u0026filter={filter}] Parameters string namespaceId default or diagnostics string streamId The stream identifier string startIndex Index identifying the beginning of the series of events to return int count The number of events to return int skip Optional value specifying the number of events to skip at the beginning of the result bool reversed Optional specification of the direction of the request. By default, range requests move forward from startIndex, collecting events after startIndex from the stream. A reversed request will collect events before startIndex from the stream. SdsBoundaryType boundaryType Optional SdsBoundaryType specifies the handling of events at or near startIndex string filter Optional filter expression Response The response includes a status code and a response body containing a serialized collection of events. Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T13:00:00Z\u0026count=100 This request will return a response with up to 100 events starting at 13:00 and extending forward toward the end of the stream: Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"Measurement\": 40 } ] Note: State is not included in the JSON as its value is the default value. Example To reverse the direction of the request, set reversed to true. The following request will return up to 100 events starting at 13:00 and extending back toward the start of the stream: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T13:00:00Z\u0026count=100\u0026reversed=true Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"Measurement\": 10 }, { \"Time\": \"2017-11-23T12:00:00Z\" } ] Note: State is not included in the JSON as its value is the default value. Further, Measurement is not included in the second, 12:00:00, event as zero is the default value for numbers. The following request specifies a boundary type of Outside for a reversed-direction range request. The response will contain up to 100 events. The boundary type Outside indicates that up to one event outside the boundary will be included in the response. For a reverse direction range request, this means one event forward of the specified start index. In a default direction range request, it would mean one event before the specified start index. GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T13:00:00Z\u0026count=100\u0026reversed=true\u0026boundaryType=2 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 0 } ] The event outside of the index is the next event or the event at 14:00 because the request operates in reverse. Adding a filter to the request means only events that meet the filter criteria are returned: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T13:00:00Z\u0026count=100\u0026reversed=true\u0026boundaryType=2\u0026filter=Measurement gt 10 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ] Window Returns a collection of stored events based on the specified startIndex and endIndex . For handling events at and near the boundaries of the window, a single SdsBoundaryType that applies to both the start and end indexes can be passed with the request, or separate boundary types may be passed for the start and end individually. Paging is supported for window requests with a large number of events. To retrieve the next page of values, include the continuationToken from the results of the previous request. For the first request, specify a null or empty string for the continuationToken . Requests GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026endIndex={endIndex} GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026endIndex={endIndex}\u0026boundaryType={boundaryType} GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026startBoundaryType={startBoundaryType} \u0026endIndex={endIndex}\u0026endBoundaryType={endBoundaryType} GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026endIndex={endIndex} \u0026count={count}\u0026continuationToken={continuationToken} GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data? api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data? ?startIndex={startIndex}\u0026startBoundaryType={startBoundaryType} \u0026endIndex={endIndex}\u0026endBoundaryType={endBoundaryType}\u0026filter={filter}\u0026count={count} \u0026continuationToken={continuationToken} Parameters string namespaceId default or diagnostics string streamId The stream identifier string startIndex Index bounding the beginning of the series of events to return string endIndex Index bounding the end of the series of events to return int count Optional maximum number of events to return. If count is specified, a continuationToken must also be specified. SdsBoundaryType boundaryType Optional SdsBoundaryType specifies handling of events at or near the start and end indexes SdsBoundaryType startBoundaryType Optional SdsBoundaryType specifies the first value in the result in relation to the start index. If startBoundaryType is specified, endBoundaryType must be specified. SdsBoundaryType endBoundaryType Optional SdsBoundaryType specifies the last value in the result in relation to the end index. If startBoundaryType is specified, endBoundaryType must be specified. string filter Optional filter expression string continuationToken Optional token used to retrieve the next page of data. If count is specified, a continuationToken must also be specified. Response The response includes a status code and a response body containing a serialized collection of events. A continuation token can be returned if specified in the request. Example The following requests all stored events between 12:30 and 15:30: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026endIndex=2017-11-23T15:30:00Z The response will contain the event stored at the specified index: Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"Measurement\": 30 } ] Note: State is not included in the JSON as its value is the default value. Example When the request is modified to specify a boundary type of Outside, the value before 13:30 and the value after 15:30 are included: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026endIndex=2017-11-23T15:30:00Z \u0026boundaryType=2 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T12:00:00Z\" }, { \"Time\": \"2017-11-23T13:00:00Z\", \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"Measurement\": 40 } ] Note that State is not included in the JSON as its value is the default value. Further, Measurement is not included in the second, 12:00:00, event as zero is the default value for numbers. If instead a start boundary of Inside, only values inside the start boundary (after 13:30) are included in the result. With an end boundary of Outside one value outside the end index (after 15:30) is included: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026\u0026startBoundaryType=1 \u0026endIndex=2017-11-23T15:30:00Z\u0026endBoundaryType=2 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 } ] In order to page the results of the request, a continuation token may be specified. This requests the first page of the first two stored events between start index and end index by indicating count is 2 and continuationToken is an empty string: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026endIndex=2017-11-23T15:30:00Z \u0026count=2\u0026continuationToken= Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Results\": [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ], \"ContinuationToken\": \"2017-11-23T14:00:00.0000000Z\" } This request uses the continuation token from the previous page to request the next page of stored events: GET api/v1/Tenants/default}/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default} Namespaces {namespaceId} Streams Simple Data ?startIndex=2017-11-23T12:30:00Z\u0026endIndex=2017-11-23T15:30:00Z \u0026count=2\u0026continuationToken=2017-11-23T14:00:00Z Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json { \"Results\": [ { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 30 } ], \"ContinuationToken\": null } In this case, the results contain the final event. The returned continuation token is null. Get Interpolated Values Returns a collection of values based on request parameters. The stream\u0027s read characteristics determine how events are calculated for indexes at which no stored event exists. Interpolation is not supported for streams with compound indexes. SDS supports two ways of specifying which interpolated events to return: Index Collection : One or more indexes can be passed to the request in order to retrieve events at specific indexes. Interval : An interval can be specified with a start index, end index, and count. This will return the specified count of events evenly spaced from start index to end index. Index Collection Returns events at the specified indexes. If no stored event exists at a specified index, the stream\u0027s read characteristics determine how the returned event is calculated. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/ api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data  Interpolated?index={index}[\u0026index={index}...] Parameters string namespaceId default or diagnostics string streamId The stream identifier string index One or more indexes Response The response includes a status code and a response body containing a serialized collection of events. Depending on the specified indexes and read characteristics of the stream, it is possible to have less events returned than specified indexes. An empty collection can also be returned. Example Consider a stream of type Simple with the default InterpolationMode of Continuous and ExtrapolationMode of All . In the following request, the specified index matches an existing stored event: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default Namespaces {namespaceId} Streams Simple Data  Interpolated?index=2017-11-23T13:00:00Z The response will contain the event stored at the specified index. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 } ] The following request specifies an index for which no stored event exists: GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default Namespaces {namespaceId} Streams Simple Data  Interpolated?index=2017-11-23T13:30:00Z Because the index is a valid type for interpolation and the stream has a InterpolationMode of Continuous , this request receives a response with an event interpolated at the specified index: Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:30:00Z\", \"State\": 0, \"Measurement\": 15 } ] Consider a stream of type Simple with an InterpolationMode of Discrete and ExtrapolationMode of All . In the following request, the specified indexes only match two existing stored events: GET api/v1/Tenants/default}/Namespaces/{namespaceId}/Streams/Simple/Data api v1 Tenants default} Namespaces {namespaceId} Streams Simple Data Interpolated?index=2017-11-23T12:30:00Z\u0026index=2017-11-23T13:00:00Z\u0026index=2017-11-23T14:00:00Z For this request, the response contains events for two of the three specified indexes. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 } ] Interval Returns events at evenly spaced intervals based on the specified start index, end index, and count. If no stored event exists at an index interval, the stream\u0027s read characteristics determine how the returned event is calculated. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/ api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data  Interpolated?startIndex={startIndex}\u0026endIndex={endIndex}\u0026count={count} Parameters string namespaceId default or diagnostics string streamId The stream identifier string startIndex The index defining the beginning of the window string endIndex The index defining the end of the window int count The number of events to return. Read characteristics of the stream determine how the events are constructed. Response The response includes a status code and a response body containing a serialized collection of events. Depending on the read characteristics and input parameters, it is possible for a collection to be returned with less events than specified in the count. For a stream, named Simple, of type Simple for the following request: GET api/v1/Tenants/default}/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default} Namespaces {namespaceId} Streams Simple Data  Interpolated?startIndex=2017-11-23T13:00:00Z\u0026endIndex=2017-11-23T15:00:00Z\u0026count=3 The start and end fall exactly on event indexes, and the number of events from start to end match the count of three (3). Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 30 } ] Get Summaries Returns summary intervals between a specified start and end index. Index types that cannot be interpolated do not support summary requests. Strings are an example of indexes that cannot be interpolated. Summaries are not supported for streams with compound indexes. Interpolating between two indexes that consist of multiple properties is not defined and results in non-determinant behavior. Summary values supported by SdsSummaryType enum: Summary Enumeration value Count 1 Minimum 2 Maximum 4 Range 8 Mean 16 StandardDeviation 64 Total 128 Skewness 256 Kurtosis 512 WeightedMean 1024 WeightedStandardDeviation 2048 WeightedPopulationStandardDeviatio 4096 Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/ api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data  Summaries?startIndex={startIndex}\u0026endIndex={endIndex}\u0026count={count}\u0026filter={filter} Parameters string namespaceId default or diagnostics string streamId The stream identifier string startIndex The start index for the intervals string endIndex The end index for the intervals int count The number of intervals requested string filter Optional filter expression string streamViewId Optional stream view identifier Response The response includes a status code and a response body containing a serialized collection of SdsIntervals. Each SdsInterval has a start, end, and collection of summary values. Property Details Start The start of the interval End The end of the interval Summaries The summary values for the interval, keyed by summary type. The nested dictionary contains property name keys and summary calculation result values. Example The following request calculates two summary intervals between the startIndex and endIndex : GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default Namespaces {namespaceId} Streams Simple Data  Summaries?startIndex=2017-11-23T12:00:00Z\u0026endIndex=2017-11-23T16:00:00Z\u0026count=2 Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Start\": { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 0 }, \"End\": { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, \"Summaries\": { \"Count\": { \"Measurement\": 2 }, \"Minimum\": { \"Measurement\": 0 }, \"Maximum\": { \"Measurement\": 20 }, \"Range\": { \"Measurement\": 20 }, \"Total\": { \"Measurement\": 20 }, \"Mean\": { \"Measurement\": 10 }, \"StandardDeviation\": { \"Measurement\": 7.0710678118654755 }, \"PopulationStandardDeviation\": { \"Measurement\": 5 }, \"WeightedMean\": { \"Measurement\": 10 }, \"WeightedStandardDeviation\": { \"Measurement\": 7.0710678118654755 }, \"WeightedPopulationStandardDeviation\": { \"Measurement\": 5 }, \"Skewness\": { \"Measurement\": 0 }, \"Kurtosis\": { \"Measurement\": -2 } } }, { \"Start\": { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 20 }, \"End\": { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, \"Summaries\": { \"Count\": { \"Measurement\": 2 }, \"Minimum\": { \"Measurement\": 20 }, \"Maximum\": { \"Measurement\": 40 }, \"Range\": { \"Measurement\": 20 }, \"Total\": { \"Measurement\": 60 }, \"Mean\": { \"Measurement\": 30 }, \"StandardDeviation\": { \"Measurement\": 7.0710678118654755 }, \"PopulationStandardDeviation\": { \"Measurement\": 5 }, \"WeightedMean\": { \"Measurement\": 30 }, \"WeightedStandardDeviation\": { \"Measurement\": 7.0710678118654755 }, \"WeightedPopulationStandardDeviation\": { \"Measurement\": 5 }, \"Skewness\": { \"Measurement\": 0 }, \"Kurtosis\": { \"Measurement\": -2 } } } ] Get Sampled Values Returns data sampled by intervals between a specified start and end index. Sampling is driven by a specified property or properties of the stream\u0027s Sds Type. Property types that cannot be interpolated do not support sampling requests. Strings are an example of a property that cannot be interpolated. For more information see Interpolation. Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/ api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data  Sampled?startIndex={startIndex}\u0026endIndex={endIndex}\u0026intervals={intervals}\u0026sampleBy={sampleBy} \u0026boundaryType={boundaryType}\u0026startBoundaryType={startBoundaryType} \u0026endBoundaryType={endBoundaryType}\u0026filter={filter}\u0026streamViewId={streamViewId} Parameters string namespaceId default or diagnostics string streamId The stream identifier string startIndex The start index for the intervals string endIndex The end index for the intervals int intervals The number of intervals requested string sampleBy Property or properties to use when sampling SdsBoundaryType boundaryType Optional SdsBoundaryType specifies the handling of events at or near the startIndex and endIndex SdsBoundaryType startBoundaryType Optional SdsBoundaryType specifies the handling of events at or near the startIndex SdsBoundaryType endBoundaryType Optional SdsBoundaryType specifies the handling of events at or near the endIndex string filter Optional filter expression Response The response includes a status code and a response body containing a serialized collection of events. Example The following request returns two sample intervals between the startIndex and endIndex : GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/Simple/Data/ api v1 Tenants default Namespaces {namespaceId} Streams Simple Data  Sampled?startIndex=2019-01-01T00:00:00Z\u0026endIndex=2019-01-02T00:00:00Z\u0026intervals=2\u0026sampleBy=Measurement Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2019-01-01T00:00:01Z\", \"State\": 1, \"Measurement\": 1 }, { \"Time\": \"2019-01-01T00:11:50Z\", \"State\": 2, \"Measurement\": 0.00006028870675578446 }, { \"Time\": \"2019-01-01T11:55:33Z\", \"Measurement\": 6.277981349066863 }, { \"Time\": \"2019-01-01T12:00:00Z\", \"Measurement\": 3.101013140344655 }, { \"Time\": \"2019-01-01T12:00:01Z\", \"State\": 1, \"Measurement\": 4.101013140344655 }, { \"Time\": \"2019-01-01T12:01:50Z\", \"State\": 2, \"Measurement\": 0.0036776111121028521 }, { \"Time\": \"2019-01-01T23:57:23Z\", \"State\": 2, \"Measurement\": 6.2816589601789659 }, { \"Time\": \"2019-01-02T00:00:00Z\", \"Measurement\": 6.20202628068931 } ] Note: State is not included in the JSON when its value is the default value. Join Values Returns data from multiple streams, which are joined based on the request specifications. The streams must be of the same SdsType. SDS supports the following types of joins: SdsJoinMode Enumeration value Operation Inner 0 Results include the stored events with common indexes across specified streams. Outer 1 Results include the stored events for all indexes across all streams. Interpolated 2 Results include events for each index across all streams for the request index boundaries. Some events may be interpolated. MergeLeft 3 Results include events for each index across all streams selecting events at the indexes based on left to right order of the streams. MergeRight 4 Results include events for each index across all streams selecting events at the indexes based on right to left order of the streams. SDS supports two types of join requests: GET : The stream, joinMode, start index, and end index are specified in the request URI path. POST : Only the SdsJoinMode is specified in the URI. The streams and read specification for each stream are specified in the body of the request. GET Request GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams={streams}\u0026joinMode={joinMode} \u0026startIndex={startIndex}\u0026endIndex={endIndex} Parameters string namespaceId default or diagnostics string streams Commas separated list of stream identifiers SdsJoinMode joinMode Type of join, that is inner, outer, and so on. string startIndex Index identifying the beginning of the series of events to return string endIndex Index identifying the end of the series of events to return Response The response includes a status code and a response body containing multiple serialized events. See examples for specifics. Examples To join multiple streams, for example Simple1 and Simple2, assume that Simple1 presents the following data: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 } ] And assume that Simple2 presents the following data: HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 }, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] The following are responses for various Joins request options: Inner Join Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=inner \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response Measurements from both streams with common indexes. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 } ] ] Outer Join Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=outer \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response All Measurements from both Streams, with default values at indexes where a Stream does not have a value. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, null ], [ null, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 } ], [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, null ], [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 } ], [ null, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 } ], [ { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, null ], [ null, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] ] Interpolated Join Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=interpolated \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response All measurements from both Streams with missing values interpolated. If the missing values are between valid measurements within a stream, they are interpolated. If the missing values are outside of the boundary values, they are extrapolated. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 50 } ], [ { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 15 }, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 } ], [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 55 } ], [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 } ], [ { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 35 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 } ], [ { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 75 } ], [ { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 40 }, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] ] MergeLeft Join Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=mergeleft \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response This is similar to OuterJoin , but the value at each index is the first available value at that index when iterating the given list of streams from left to right. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] MergeRight Join Example GET api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?streams=Simple1,Simple2\u0026joinMode=mergeright \u0026startIndex=0001-01-01T00:00:00.0000000\u0026endIndex=9999-12-31T23:59:59.9999999 Response This is similar to OuterJoin , but the value at each index is the first available value at that index when iterating the given list of streams from right to left. Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, { \"Time\": \"2017-11-23T12:00:00Z\", \"State\": 0, \"Measurement\": 50 }, { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 60 }, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 }, { \"Time\": \"2017-11-23T16:00:00Z\", \"State\": 0, \"Measurement\": 40 }, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] POST Request POST api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?joinMode={joinMode} Parameters string namespaceId default or diagnostics SdsJoinMode joinMode Type of join, that is inner, outer, and so on. Request Body Read options specific to each stream. Response The response includes a status code and a response body containing multiple serialized events. Consider the following outer join request, POST api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data/Joins api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Joins ?joinMode=outer where in the request body, different start indexes and end indexes are specified per stream, [ { \"StreamId\": \"Simple1\", \"Options\": { \"StartIndex\": \"2017-11-23T11:00:00Z\", \"EndIndex\": \"2017-11-23T14:00:00Z\", \"StartBoundaryType\": \"Exact\", \"EndBoundaryType\": \"Exact\", \"Count\": 100, \"Filter\": \"\" } }, { \"StreamId\": \"Simple2\", \"Options\": { \"StartIndex\": \"2017-11-23T15:00:00Z\", \"EndIndex\": \"2017-11-23T17:00:00Z\", \"StartBoundaryType\": \"Exact\", \"EndBoundaryType\": \"Exact\", \"Count\": 100, \"Filter\": \"\" } } ] Only events within the stream\u0027s specified index boundaries are considered for the outer join operation Response body HTTP/1.1 HTTP 1.1 200 Content-Type: application/json application json [ [ { \"Time\": \"2017-11-23T11:00:00Z\", \"State\": 0, \"Measurement\": 10 }, null ], [ { \"Time\": \"2017-11-23T13:00:00Z\", \"State\": 0, \"Measurement\": 20 }, null ], [ { \"Time\": \"2017-11-23T14:00:00Z\", \"State\": 0, \"Measurement\": 30 }, null ], [ null, { \"Time\": \"2017-11-23T15:00:00Z\", \"State\": 0, \"Measurement\": 70 } ], [ null, { \"Time\": \"2017-11-23T17:00:00Z\", \"State\": 0, \"Measurement\": 80 } ] ] Note: Not all the values from streams were included since they are restricted by individual queries for each Stream."
                                     },
    "V1/SDS/Reading_Data.html":  {
                                     "href":  "V1/SDS/Reading_Data.html",
                                     "title":  "Reading data",
                                     "keywords":  "Reading data The REST APIs provide programmatic access to read and write data. This section identifies and describes the APIs used to read Streams data. Results are influenced by Types , Stream Views , Filter expressions , and Table format . Single stream reads The following methods for reading a single value are available: Get First Value returns the first value in the stream. Get Last Value returns the last value in the stream. Find Distinct Value returns a value based on a starting index and search criteria. In addition, the following methods support reading multiple values: Get Values retrieves a collection of stored values based on the request parameters. Get Interpolated Values retrieves a collection of stored or calculated values based on the request parameters. Get Summaries retrieves a collection of evenly spaced summary intervals based on a count and specified start and end indexes. Get Sampled Values retrieves a collection of sampled data based on the request parameters. All single stream reads are HTTP GET actions. Reading data involves getting events from streams. The base reading URI from a single stream is as follows: api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Parameters string namespaceId default or diagnostics string streamId The stream identifier Bulk reads SDS supports reading from multiple streams in one request. The following method for reading data from multiple streams is available: Join Values retrieves a collection of events across multiple streams and joins the results based on the request parameters. Multi-stream reads can be HTTP GET or POST actions. The base reading URI for reading from multiple streams is the following: api/v1/Tenants/default/Namespaces/{namespaceId}/Bulk/Streams/Data api v1 Tenants default Namespaces {namespaceId} Bulk Streams Data Parameters string namespaceId default or diagnostics Response format Supported response formats include JSON, verbose JSON, and SDS. JSON is the default response format for SDS, which is used in all examples in this documentation. Default JSON responses do not include any values that are equal to the default value for their type. Verbose JSON responses include all values, including defaults, in the returned JSON payload. To specify verbose JSON return, add the header Accept-Verbosity with a value of verbose to the request. SDS format is specified by setting the Accept header in the request to application/sds application sds . Indexes and reading data Most read operations take at least one index as a parameter. Indexes may be specified as strings. You can find additional details about working with indexes on the Indexes page. Read characteristics When you request data at an index for which no stored event exists, the read characterisitics determine whether the result is an error, no event, interpolated event, or extrapolated event. The combination of the type of the index and the interpolation and extrapolation modes of the SdsType and the SdsStream determine the read characteristics. For more information on read characteristics, see Types and Streams . Filter expressions You can apply filter expressions to any read that returns multiple values, including Get Values, Get Range Values, Get Window Values, and Get Intervals. The filter expression is applied to the collection events conditionally filtering events that do not meet the filter conditions. For details on filter expressions, see the Filter expressions section. Table format You can organize results of a query into tables by directing the form parameter to return a table. Two forms of table are available: table and header table. When you specify the form parameter as table, ?form=table , events are returned in row column form. Results include a collection named Columns that lists column name and type and a collection named Rows containing a collection of rows matching the order of the columns. When you specify a form of type table-headers , ?form=tableh , it results in a collection where the Rows collection contains a column header list. For details on table formats, see the Table format section. SdsBoundaryType The SdsBoundaryType enum defines how data on the boundary of queries is handled: around the start index for range value queries, and around the start and end index for window values. The following are valid SdsBoundaryType values: Boundary Enumeration value Operation Exact 0 Results include the event at the specified index boundary if a stored event exists at that index. Inside 1 Results include only events within the index boundaries Outside 2 Results include up to one event that falls immediately outside of the specified index boundary. ExactOrCalculated 3 Results include the event at the specified index boundary. If no stored event exists at that index, one is calculated based on the index type and interpolation and extrapolation settings. SdsSearchMode The SdsSearchMode enum defines search behavior when seeking a stored event near a specified index. The following are valid values for SdsSearchMode : Mode Enumeration value Operation Exact 0 If a stored event exists at the specified index, that event is returned. Otherwise, no event is returned. ExactOrNext 1 If a stored event exists at the specified index, that event is returned. Otherwise, the next event in the stream is returned. Next 2 Returns the stored event after the specified index. ExactOrPrevious 3 If a stored event exists at the specified index, that event is returned. Otherwise, the previous event in the stream is returned. Previous 4 Returns the stored event before the specified index. Transforming data SDS provides the ability to transform data upon reads. The supported data transformations are: Reading with SdsStreamViews : Changing the shape of the returned data Unit of Measure Conversions : Converting the unit of measure of the data Data transformations are supported for all single stream reads, but transformations have specific endpoints. The following are the base URIs for the tranformation endpoints: api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/First api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform First api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/Last api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Last api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/Interpolated api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Interpolated api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/Summaries api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Summaries api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/Sampled api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Sampled Reading with SdsStreamViews When you transform data with an SdsStreamView, the data read is converted to the target type specified in the SdsStreamView. For details on working with stream views, see the Stream Views section. All stream view transformations are GET HTTP requests. You specify the stream view by appending the stream view identifier to requests to the transformation endpoint. For example, the following request would return the first event in the stream as the target type in the stream view specified by the streamViewId : GET api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform/First?streamViewId={streamViewId} api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform First?streamViewId={streamViewId} All single stream data reads support stream view transformations. When you request data with an SdsStreamView, the read characteristics defined by the target type of the SdsStreamView determine what is returned. The read characteristics are discussed in the code samples. Unit conversion of data SDS supports assigning Units of Measure (UOM) to stream data. If stream data has UOM information associated, SDS supports reading data with unit conversions applied. On each read data request, unit conversions are specified by a user defined collection of SdsStreamPropertyOverride objects in read requests. The SdsStreamPropertyOverride object has the following structure: Property Type Optionality Description SdsTypePropertyId String Required Identifier for an SdsTypeProperty with a UOM assigned Uom String Required Target unit of measure InterpolationMode SdsInterpolationMode N/A N A Currently not supported in context of data reads This is supported in the REST API through HTTP POST calls with a request body containing a collection of SdsStreamPropertyOverride objects. All unit conversions are POST HTTP requests. The unit conversion transformation URI is as follows: POST api/v1/Tenants/default/Namespaces/{namespaceId}/Streams/{streamId}/Data/Transform api v1 Tenants default Namespaces {namespaceId} Streams {streamId} Data Transform Request body The Request Body contains a collection of SdsStreamPropertyOverride objects. The example request body below requests SDS to convert the Measurement property of the returned data from meter to centimeter. [ { \"SdsTypePropertyId\" : \"Measurement\", \"Uom\" : \"centimeter\" } ] All single stream data reads with streams that have specified UOMs support UOM conversions."
                                 },
    "V1/SDS/indexes.html":  {
                                "href":  "V1/SDS/indexes.html",
                                "title":  "Indexes",
                                "keywords":  "Indexes Indexes speed up and order the results of searches. A key uniquely identifies a record within a collection of records. Keys are unique within the collection. In Sds, the key of an SdsType is also an index. The key is often referred to as the primary index, while all other indexes are referred to as secondary indexes or secondaries . An SdsType that is used to define an SdsStream must specify a key. When inserting data into an SdsStream, every key value must be unique. Sds will not store more than a single event for a given key. An event with a particular key may be deleted or updated, but two events with the same key cannot exist. Secondary indexes are defined on SdsStreams and are applied to a single property. You can define many secondary indexes. Secondary index values do not need to be unique. The following table contains supported index types: Type SdsTypeCode Boolean 3 Byte 6 Char 4 DateTime 16 DateTimeOffset 20 Decimal 15 Double 14 Guid 19 Int16 7 Int32 9 Int64 11 SByte 5 Single 13 String 18 TimeSpan 21 UInt16 8 UInt32 10 UInt64 12 Working with Indexes The following discusses the types defined in the Python and Java Script samples. Samples in other languages can be found here . To build an SdsType representation of the following sample class, see Sample : Python class State(Enum): Ok = 0 Warning = 1 Alarm = 2 class Simple(object): Time = property(getTime, setTime) def getTime(self): return self.__time def setTime(self, time): self.__time = time State = property(getState, setState) def getState(self): return self.__state def setState(self, state): self.__state = state Measurement = property(getValue, setValue) def getValue(self): return self.__measurement def setValue(self, measurement): self.__measurement = measurement JavaScript var State = { Ok: 0, Warning: 1, Alarm: 2 } var Simple = function () { this.Time = null; this.State = null; this.Value = null; } Sample The following code is used to build an SdsType representation of the sample class above: Python # Create the properties # Time is the primary key time = SdsTypeProperty() time.Id = \"Time\" time.Name = \"Time\" time.IsKey = True time.SdsType = SdsType() time.SdsType.Id = \"DateTime\" time.SdsType.Name = \"DateTime\" time.SdsType.SdsTypeCode = SdsTypeCode.DateTime # State is not a pre-defined type. An SdsType must be defined to represent the enum stateTypePropertyOk = SdsTypeProperty() stateTypePropertyOk.Id = \"Ok\" stateTypePropertyOk.Measurement = State.Ok stateTypePropertyWarning = SdsTypeProperty() stateTypePropertyWarning.Id = \"Warning\" stateTypePropertyWarning.Measurement = State.Warning stateTypePropertyAlarm = SdsTypeProperty() stateTypePropertyAlarm.Id = \"Alarm\" stateTypePropertyAlarm.Measurement = State.Alarm stateType = SdsType() stateType.Id = \"State\" stateType.Name = \"State\" stateType.Properties = [ stateTypePropertyOk, stateTypePropertyWarning,\\ stateTypePropertyAlarm ] state = SdsTypeProperty() state.Id = \"State\" state.Name = \"State\" state.SdsType = stateType # Measurement property is a simple non-indexed, pre-defined type measurement = SdsTypeProperty() measurement.Id = \"Measurement\" measurement.Name = \"Measurement\" measurement.SdsType = SdsType() measurement.SdsType.Id = \"Double\" measurement.SdsType.Name = \"Double\" # Create the Simple SdsType simple = SdsType() simple.Id = str(uuid.uuid4()) simple.Name = \"Simple\" simple.Description = \"Basic sample type\" simple.SdsTypeCode = SdsTypeCode.Object simple.Properties = [ time, state, measurement ] JavaScript //    Time is the primary key var timeProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Time\", \"IsKey\": true, \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"dateType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.DateTime }) }); //    State is not a pre-defined type. A SdsType must be defined to represent the enum var stateTypePropertyOk = new SdsObjects.SdsTypeProperty({ \"Id\": \"Ok\", \"Value\": State.Ok }); var stateTypePropertyWarning = new SdsObjects.SdsTypeProperty({ \"Id\": \"Warning\", \"Value\": State.Warning }); var stateTypePropertyAlarm = new SdsObjects.SdsTypeProperty({ \"Id\": \"Alarm\", \"Value\": State.Alarm }); var stateType = new SdsObjects.SdsType({ \"Id\": \"State\", \"Name\": \"State\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Int32Enum, \"Properties\": [stateTypePropertyOk, stateTypePropertyWarning, stateTypePropertyAlarm, stateTypePropertyRed] }); //    Value property is a simple non-indexed, pre-defined type var valueProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Value\", \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"doubleType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Double }) }); //    Create the Simple SdsType var simpleType = new SdsObjects.SdsType({ \"Id\": \"Simple\", \"Name\": \"Simple\", \"Description\": \"This is a simple Sds type\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.Object, \"Properties\": [timeProperty, stateProperty, valueProperty] }); The Time property is identified as the Key by defining its SdsTypeProperty as follows: Python # Time is the primary key time = SdsTypeProperty() time.Id = \"Time\" time.Name = \"Time\" time.IsKey = True time.SdsType = SdsType() time.SdsType.Id = \"DateTime\" time.SdsType.Name = \"DateTime\" time.SdsType.SdsTypeCode = SdsTypeCode.DateTime JavaScript //    Time is the primary key var timeProperty = new SdsObjects.SdsTypeProperty({ \"Id\": \"Time\", \"IsKey\": true, \"SdsType\": new SdsObjects.SdsType({ \"Id\": \"dateType\", \"SdsTypeCode\": SdsObjects.SdsTypeCodeMap.DateTime }) }); Note: The time.IsKey field is set to true. To read data using the key, you define a start index and an end index. For DateTime, use ISO 8601 representation of dates and times. To query for a window of values between January 1, 2010 and February 1, 2010, you would define indexes as ???2010-01-01T08:00:00.000Z??? and ???2010-02-01T08:00:00.000Z???, respectively. For additional information, see Reading data ."
                            },
    "V1/SDS/Filter_Expressions.html":  {
                                           "href":  "V1/SDS/Filter_Expressions.html",
                                           "title":  "Filter Expressions: Values",
                                           "keywords":  "Filter Expressions: Values Filter expressions can be applied to certain read operations that return Sequential Data Store values, including: Get Values and Get Summaries . SdsTypeCodes The following types are supported for use within a filter expression: Boolean Byte Char DateTime DateTimeOffset Decimal Double Guid Int16 Int32 Int64 Sbyte Single String Timespan UInt16 UInt32 Uint64 The following types are not supported for use within a filter expression: Array IEnumerable IDictionary IList SdsType SdsTypeProperty Nullable Types Logical operators The following logical operators are supported for use within a filter expression: Operator Description eq Equal to ne Not equal ge Greater than or equal to le Less than or equal to lt Less than gt Greater than ( ) Parenthesis can be used to affect the order of the operation or Or logical operator and And logical operator not Not logical operator - Negation Logical operator examples For the following examples, you can assume that the SDS Type event includes a field named Value of type double : Value eq 1.0 Value ne 15.6 Value ge 5.0 Value le 8.0 Value gt 5.0 Value lt 4.0 Value gt 2.0 and Value lt 9.0 Value gt 6.0 or Value lt 2.0 not (Value eq 1.0) Math functions The following math functions are supported for use within a filter expression: Function Description add Addition sub Subtraction mul Multiplication div Division mod Modulo round Rounds to the nearest numeric component without a decimal, with the midpoint rounded away from 0. For example, 0.5 rounds to 1; -0.5 rounds to -1) floor Rounds down to the nearest numeric component without a decimal ceiling Rounds up to the nearest numeric component without a decimal Math function examples For the following examples, you can assume that the SDS Type event includes a field named Value of type double : Value eq (6.0 add 3.0) Value eq (6.0 sub 3.0) Value eq (6.0 mul 3.0) Value eq (6.0 div 3.0) Value eq (7.0 mod 3.0) round(Value) eq 16 floor(Value) eq 15 ceiling(Value) eq 16 String functions String operations are case sensitive. The character index in a string is 0-based. The following string functions are supported for use within a filter expression: Function Description endswith Compare the character at the end of the input string startswith Compare the character at the start of the input string length Examines the string length indexof Examines the character starting at a given index substring Examine characters within another string at a specific location contains Search for characters anywhere in another string tolower Convert characters to lowercase toupper Convert characters to uppercase trim Remove whitespace from front and end of a string concat Concatenate strings together replace Replace one set of characters with another String function examples For the following examples, you can assume that the SDS Type event includes a field named sValue of type string : Example Result endswith(sValue, \u0027XYZ\u0027) True if sValue ends with the characters ???XYZ??? startswith(sValue, \u0027Val\u0027 True if sValue starts with the characters ???Val??? length(sValue) eq 11 True if sValue is 11 characters indexof(sValue, \u0027ab\u0027) eq 4 True if the 5th and 6th characters are ???ab??? contains(sValue, \u0027ab\u0027) True if characters ???ab??? are found anywhere in sValue substring(sValue, 10) eq \u0027a b\u0027 True if ???a b??? is found in sValue at index 10 tolower(sValue) eq \u0027val5\u0027 Change sValue to lowercase and compare to ???val5??? toupper(sValue) eq \u0027ABC\u0027 Change sValue to uppercase and compare to ???ABC??? trim(sValue) eq \u0027vall22\u0027 Trim whitespace from front and end of sValue and compare to ???val22??? concat(sValue,\u0027xyz\u0027) eq \u0027dataValue_7xyz\u0027 Add characters to sValue and compare to ???dataValue_7xyz??? replace(sValue,\u0027L\u0027,\u0027D\u0027) eq \u0027Dog1\u0027 Replace any ???L??? in sValue with ???D??? and compare to ???Dog1??? DateTime functions The following DateTime functions are supported for use within a filter expression: Function Description year Get year value from DateTime month Get month value from DateTime day Get day value from DateTime hour Get hour value from DateTime minute Get minute value from DateTime second Get second value from DateTime DateTime function examples For the following examples, you can assume that the SDS Type event includes a field named TimeId of type DateTime : year(TimeId) eq 2015 month(TimeId) eq 11 day(TimeId) eq 3 hour(TimeId) eq 1 minute(TimeId) eq 5 second(TimeId) eq 3 TimeSpan functions The following TimeSpan functions are supported for use within a filter expression: Function Description years Get year value from TimeSpan days Get day value from TimeSpan hours Get hour value from TimeSpan minutes Get minute value from TimeSpan seconds Get second value from TimeSpan TimeSpan function examples For the following examples, you can assume that the SDS Type event includes a field named TimeSpanValue of type TimeSpan : years(TimeSpanValue) eq 1 days(TimeSpanValue) eq 22 hours(TimeSpanValue) eq 1 minutes(TimeSpanValue) eq 1 seconds(TimeSpanValue) eq 2"
                                       },
    "V1/SDS/Compression.html":  {
                                    "href":  "V1/SDS/Compression.html",
                                    "title":  "Compression",
                                    "keywords":  "Compression To more efficiently utilize network bandwidth, the EDS Sequential Data Store supports compression for reading data and writing data through the REST API. Supported compression schemes gzip deflate Request compression (writing data) You can compress the body content of an HTTP request by using the supported compression schemes allowing you to send stream values to the REST API more efficiently. You must use the Content-Encoding HTTP header to specify the compression scheme of compressed-content requests. This header provides context to the API to properly decode the request content. Response compression (reading data) You can request compressed responses from the REST API by specifying one of the supported compression schemes using the Accept-Encoding HTTP header. Compressed responses from the REST API will include a Content-Encoding HTTP header indicating the compression scheme used to compress the response content. Note: Specifying a compression scheme through the use of the* Accept-Encoding HTTP header does not guarantee a compressed response. Always refer to presence and value of the* Content-Encoding HTTP header of the response to properly decode the response content.*"
                                },
    "V1/ReleaseNotes/ReleaseNotes.html":  {
                                              "href":  "V1/ReleaseNotes/ReleaseNotes.html",
                                              "title":  "Edge Data Store Release Notes",
                                              "keywords":  "Edge Data Store Release Notes Overview Edge Data Store is supported on a variety of platforms and processors. OSIsoft provides ready to use install kits for the following platforms: Windows 10 x64 - EdgeDataStore.msi (Intel/AMD (Intel AMD 64 bit processors) Debian 9 or later x64/AMD64 x64 AMD64 - EdgeDataStore_linux-x64.deb (Intel/AMD (Intel AMD 64 bit processors) Debian 9 or later ARM32 - EdgeDataStore_linux-arm.deb (Raspberry PI 2,3,4, BeagleBone devices, other ARM v7 and ARM v8 32 bit processors) In addition to ready to use install kits, OSIsoft also provides examples of how to create Docker Containers in a separate file. tar.gz files are provided with binaries for customers who want to build their own custom installers or containers for Linux. Differences from Beta 1 Edge Data Store is built using Microsoft .NET Core version 2.2.6. The default port has been changed from 5000 to 5590. It can be changed during the install process, and also through configuration after installation. Changing the port requires a restart of Edge Data Store for it to take effect. When run in a Docker container, the exposed port is now 5590 and not port 80 as in Beta 1. Entire Edge Data Store (including Modbus TCP and OPC UA adapters) can now be configured using a single file in a single REST call. Secret storage on Linux has been moved from the /.OSIsoft  .OSIsoft to a directory under /usr/share/OSIsoft.  usr share OSIsoft. PeriodicEgressTargets has been renamed to PeriodicEgressEndpoints. StreamStorage configuration has been renamed Runtime configuration and includes a new setting for ingress debugging. Both ingress and egress debugging options have been changed from a boolean value to a DateTime. After the configured DateTime for debugging, it will automatically be disabled. OMF Health messages are now supported for all Edge Components (Storage, Modbus TCP, OPC UA) A new diagnostics namespace has been added where streams are populated by components in the system with information useful for monitoring performance and reliabiliy. It can be egressed to a remote PI Web API server or OSIsoft Cloud Services to assist with remote montitoring of an Edge Data Store. Support for PI Connector Relay has been removed - the only authentication models supported for egress are now Basic Authentication for PI Web Api, and ClientId and ClientSecret for OSIsoft Cloud Services. Schemas for a number of configuration files have changed to make them more consistent across different components. Please refer to the updated documentation for the new schemas. Issues related to errors caused by egressing data upon startup of the product have been resolved. The TypePrefix property is now properly applied to types when they are egressed to PI Web Api or OSIsoft Cloud Services. The Event Filtering capabilities of PeriodicEgressEndpoints has been removed from the product. Significant improvements have been made in the reliability of egressing data to PI Web Api or OSIsoft Cloud Services. Edge Data Store now supports a REST method for performing a full reset of the product, which will include removal of all existing configuration and stored event data. A new REST method has been added for purging all stored event data and configuration related to the Storage component. Individual EDS adapters may be started and stopped through newly added REST methods. Startup of Edge Data Store has been made more resilient so that the product will start and may be configured even in circumstances where it\u0027s improperly configured. Library libicu63 is now added as a dependency on Linux so Edge Data Store may properly install on Raspberry PI 4 devices. The optional Type and Stream prefix strings for PeriodicEgressTargets were relaxed. Previously they had to be alphanumeric with an optional underscore. They can now be any string, including special characters, but there are a list of restriced characters that are not allowed. See documentation for list of restricted characters. Install Edge Data Store on a Device using an install kit To use any of the installers, first copy the appropriate file to the file system of the device. Windows (Windows 10 x64) Double click the EdgeDataStore.msi file in Windows Explorer or execute the file from a command prompt. You will be prompted for install location and default port, and when the install finishes the EdgeDataStore will be installed and running on either the default port 5590 or the port you specified during the install. Debian 9 or later Linux (Ubuntu Raspberry PI, BeagleBone, other Debian based Linux distros) Open a terminal window and type: sudo apt install ./EdgeDataStore_linux_\u003ceither . EdgeDataStore_linux_\u003ceither x64 or arm depending upon processor\u003e.deb A check will be done for prerequisites. If the Linux OS is up to date, the install will succeed. If the install fails, run the following commands from the terminal window and try the install again: sudo apt update sudo apt uggrade After the check for prerequisites succeeds, a prompt will display asking if you want to change the default port (5590). If you want to change the port type in another port in the acceptable range for the OS you are using, or if 5590 is acceptable, press enter. The install will complete and EdgeDataStore will be running on your device. You can verify that EdgeDataStore is correctly installed by running the following script from the terminal window. Note: Depending on the processor, memory, and storage, it may take the system a few seconds to start up curl http://localhost:5590/api/v1/configuration http:  localhost:5590 api v1 configuration If the installation was successful, you will get back a JSON copy of the default system configuration: { \"Storage\": { \"Runtime\": { \"streamStorageLimitMb\": 2, \"streamStorageTargetMb\": 1, \"ingressDebugExpiration\": \"0001-01-01T00:00:00\" }, \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"OEM\": { \"checkpointRateInSec\": 30, \"transactionLogLimitMB\": 250, \"enableTransactionLog\": true }, \"PeriodicEgressEndpoints\": [] }, \"System\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"Components\": [{ \"componentId\": \"OpcUa1\", \"componentType\": \"OpcUa\" }, { \"componentId\": \"Modbus1\", \"componentType\": \"Modbus\" }, { \"componentId\": \"Storage\", \"componentType\": \"EDS.Component\" } ], \"HealthEndpoints\": [], \"Port\": { \"port\": 5590 } }, \"Modbus1\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"DataSource\": {}, \"DataSelection\": [] }, \"OpcUa1\": { \"Logging\": { \"logLevel\": \"Information\", \"logFileSizeLimitBytes\": 34636833, \"logFileCountLimit\": 31 }, \"DataSource\": {}, \"DataSelection\": [] } } If you get back an error, wait a few seconds and try it again. On a device with limited processor, memory, and slow storage, it may take some time before Edge Data Store is fully initialized and running for the first time. Known Issues When configuration is retrieved from a default installation of Edge Data Store http://localhost:5590/api/vi/configuration http:  localhost:5590 api vi configuration , the output JSON cannot be successfully written back to configure the system. The workaround is to remove the OEMConfiguration section of the JSON schema and any non-configured Modbus or Opc Ua components before updating the configuration. Otherwise, 400 errors will occur when the http://localhost:5590/api/vi/configuration http:  localhost:5590 api vi configuration URI is called with a PUT command. This will be fixed before the inital release of Edge Data Store. Final component health status updates may be lost when the product is shutdown. This will be fixed before the inital release of the Edge Data Store. The Edge Data Store reset and Storage component reset methods do not properly restart the server when invoked. You must manually restart the server in order to complete the reset of the System or Storage component. This will be fixed before the inital release of the Edge Data Store."
                                          },
    "V1/Overview/VisualizationQuickStart.html":  {
                                                     "href":  "V1/Overview/VisualizationQuickStart.html",
                                                     "title":  "Edge Data Store Visualization quick start",
                                                     "keywords":  "Edge Data Store Visualization quick start This document is a quick tour of getting data from the Edge Data Store Storage component and displaying it on the screen of the device where the Edge Data Store is installed. This example is intended for simplicity rather than thoroughness, and should run on any device that is supported by Edge Data Store. This example will iterate through all streams in the default namespace on the Edge Data Store and continously display the latest values to the screen. This example assumes the Edge Data Store was installed with the default port (5590). using System; using System.Collections.Generic; using System.Net.Http; using Newtonsoft.Json; namespace EdgeDataScroller { class EdgeStream { public string Id { get; set; } } class DataScroller { static HttpClient _client = new HttpClient(); private static Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e GetDataForNamespace(string ns) { Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e outputs = new Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e(); string uri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/{0}/streams\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces {0} streams\", ns); string json = _client.GetStringAsync(uri).Result; List\u003cEdgeStream\u003e streams = JsonConvert.DeserializeObject\u003cList\u003cEdgeStream\u003e\u003e(json); foreach (var stream in streams) { string lastValueUri = string.Format(\"http://localhost:5590/api/v1/tenants/default/namespaces/{0}/streams/{1}/Data/Last\", string.Format(\"http:  localhost:5590 api v1 tenants default namespaces {0} streams {1} Data Last\", ns, stream.Id.Trim()); string lastValueJson = _client.GetStringAsync(lastValueUri).Result; Dictionary\u003cstring, object\u003e values = JsonConvert.DeserializeObject\u003cDictionary\u003cstring, object\u003e\u003e(lastValueJson); outputs.Add(stream.Id.Trim(), values); } return outputs; } static void DisplayData(List\u003cstring\u003e namespaces, TimeSpan interval) { Dictionary\u003cstring, Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e\u003e outputs = new Dictionary\u003cstring, Dictionary\u003cstring, Dictionary\u003cstring, object\u003e\u003e\u003e(); Console.WriteLine(\"Data Displayed at \" + DateTime.UtcNow.ToString(\"o\")); foreach (string ns in namespaces) { outputs.Add(ns, GetDataForNamespace(ns)); } foreach (string ns in outputs.Keys) { foreach (string stream in outputs[ns].Keys) { if (null == outputs[ns][stream]) { Console.WriteLine(\"No values for \" + stream); continue; } foreach (string field in outputs[ns][stream].Keys) { object obj = outputs[ns][stream][field]; string value = obj.ToString(); if (obj is DateTime) { value = ((DateTime)obj).ToString(\"o\"); } Console.WriteLine($\"{ns}.{stream}.{field} = {value}\"); } } Console.WriteLine(\"****\"); } Console.WriteLine(string.Empty); System.Threading.Thread.Sleep(interval); } static void Main(string[] args) { List\u003cstring\u003e namespaces = new List\u003cstring\u003e(); namespaces.Add(\"default\"); TimeSpan interval = TimeSpan.FromSeconds(5.0); if (null != args \u0026\u0026 args.Length \u003e 0) { string choice = args[0].Trim().ToLowerInvariant(); if (choice == \"all\") { namespaces.Add(\"diagnostics\"); } if (choice == \"diagnostics\") { namespaces.Clear(); namespaces.Add(\"diagnostics\"); } if (args.Length \u003e 1) { string newInterval = args[1].Trim(); double newValue = -1.0; if (double.TryParse(newInterval, out newValue)) { interval = TimeSpan.FromSeconds(newValue); } } } while (true) DisplayData(namespaces, interval); } } }"
                                                 },
    "V1/Overview/SDSQuickStart.html":  {
                                           "href":  "V1/Overview/SDSQuickStart.html",
                                           "title":  "Edge Storage SDS quick start",
                                           "keywords":  "Edge Storage SDS quick start This quick start gives an overview on how to get data into the Edge Storage component using the Sequential Data Store (SDS) REST API. Prerequisites for this quick start are that Edge Data Store is installed, and that it is accessible through a REST API using the default installed port (5590). This quick start uses curl, a commonly available tool on both Windows and Linux, and command line commands. You can use the same operations with any programming language or tool that supports making REST calls. In addition, you can accomplish data retrieval steps (GET commands) using a browser if one is available on the device. Create an SDS type Create an SDS type that describes the format of the data to be stored in a container. In the following example, the data to be written is a timestamp and a numeric value, so the JSON describing the type is: { \"Id\": \"Simple\", \"Name\": \"Simple\", \"SdsTypeCode\": 1, \"Properties\": [ { \"Id\": \"Time\", \"Name\": \"Time\", \"IsKey\": true, \"SdsType\": { \"SdsTypeCode\": 16 } }, { \"Id\": \"Measurement\", \"Name\": \"Measurement\", \"SdsType\": { \"SdsTypeCode\": 14 } } ] } The value is indexed by a timestamp and the numeric value that will be stored is a 64 bit floating point value. In order to create the SDS type in the data store Save the JSON as a file with the name SDSCreateType.json. Run the following curl script: curl -i -d \"@SDSCreateType.json\" -H \"Content-Type: application/json\" application json\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/types/Simple http:  localhost:5590 api v1 tenants default namespaces default types Simple When this command completes successfully, an SDS type with the same name will have been created on the server. You can create any number of containers from the type, as long as they use a timestamp as an index and a 32 bit floating point value. You only need to do type creation the first time you send using a custom application. It does not cause an error if you resend the same definition at a later time. Create an SDS stream Create a stream. As with an SDS type, you only need to do this once before sending data events. Resending the same definition repeatedly does not cause an error. { \"Id\": \"Simple\", \"Name\": \"Simple\", \"TypeId\": \"Simple\" } This stream references the type that was created in the last step, and an error will occur if the type does not exist when the stream is created. In order to create the SDS stream in the data store Save the JSON as a file with the name SDSCreateStream.json. Run the following curl script: curl -i -d \"@SDSCreateStream.json\" -H \"Content-Type: application/json\" application json\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/Simple http:  localhost:5590 api v1 tenants default namespaces default streams Simple When this command completes successfully, an SDS stream will have been created to store data defined by the type. Write data events to the SDS stream After type and container creation, you can write data using SDS like in the following example: [{ \"Time\": \"2017-11-23T17:00:00Z\", \"Measurement\": 50.0 }, { \"Time\": \"2017-11-23T18:00:00Z\", \"Measurement\": 60.0 }] This example includes two data events that will be stored in the SDS Stream that was created in the previous steps. As a best practice, for the best performance, batch SDS values when writing them. In order to write the data Save the JSON as a file with the name SDSWriteData.json. Run the following curl script: curl -i -d \"@SDSWriteData.json\" -H \"Content-Type: application/json\" application json\" -X POST http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/Simple/Data http:  localhost:5590 api v1 tenants default namespaces default streams Simple Data When this command completes successfully, two values will have been written to the SDS stream. Read last data written using SDS In order to read the data back from the server that has been written, you can use the SDS REST API. The following is an example curl script that reads back the last value entered: curl http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data/Last http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data Last When run, this GET command returns the last value written: {\"Timestamp\":\"2019-07-16T15:18:25.9870136Z\",\"Value\":12346.6787} Read a range of data events written using SDS In order to read the data back from the server that has been written, you can use the SDS REST API. The following is an example curl script that reads back a time range of values that have been written: curl \"http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/MyCustomContainer/Data?startIndex=2019-07-08T13:00:00Z\u0026count=100\" \"http:  localhost:5590 api v1 tenants default namespaces default streams MyCustomContainer Data?startIndex=2019-07-08T13:00:00Z\u0026count=100\" [{\"Timestamp\":\"2019-07-16T15:18:24.9870136Z\",\"Value\":12345.6787},{\"Timestamp\":\"2019-07-16T15:18:25.9870136Z\",\"Value\":12346.6787}] Both values that were entered were returned - up to 100 values after the specified timestamp will be returned. For more information on SDS APIs, see Sequential Data Store ."
                                       },
    "V1/Overview/PIEgressQuickStart.html":  {
                                                "href":  "V1/Overview/PIEgressQuickStart.html",
                                                "title":  "PI System (PI Web API) egress quick start",
                                                "keywords":  "PI System (PI Web API) egress quick start This document is a quick tour of getting data stored in the Edge Data Store into a remote PI System. This is accomplished using PI Web API which is configured for Basic authentication. Create a periodic egress configuration Configure Edge Storage periodic egress for the PI Web API endpoint and credentials: [{ \"Id\": \"PWA\", \"ExecutionPeriod\": \"00:00:50\", \"Name\": null, \"NamespaceId\": \"default\", \"Description\": null, \"Enabled\": true, \"Backfill\": false, \"EgressFilter\": \"\", \"StreamPrefix\": \"\u003cunique stream prefix\u003e\", \"TypePrefix\": \"\u003cunique type prefix\u003e\", \"Endpoint\": \"https://\u003cyour \"https:  \u003cyour PI Web API Server\u003e/piwebapi/omf/\", Server\u003e piwebapi omf \", \"ClientId\": null, \"ClientSecret\": null, \"UserName\": \"\u003cusername\u003e\", \"Password\": \"\u003cpassword\u003e\", \"DebugExpiration\": null }] Edit the JSON above to add the server name of your PI Web API server, add a username and password properties to specify a valid account that can write data via PI Web API using Basic authentication. The StreamPrefix and TypePrefix can be used to ensure uniqueness on the destination system, if required. The StreamPrefix value will be used if provided in creating unique PI Points on the PI System. Run the following curl script to configure the Edge Storage to send data to the PI System. This configuration is set up to send all stream data to the PI System. If you wish to only send specific streams, edit the EgressFilter value. Examples of more advanced scenarios are in the Egress section of this documentation. Save the JSON with the file name PeriodicEgressEndpoints.json and run the following curl script in the same directory where the file exists on the device where the Edge Data Store is installed. The file and curl script can be run from any directory on the device as long as the file and the curl script are run from the same directory: curl -i -d \"@PeriodicEgressEndpoints.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/storage/PeriodicEgressEndpoints/ http:  localhost:5590 api v1 configuration storage PeriodicEgressEndpoints  When this command completes successfully, data will start being sent to the PI System."
                                            },
    "V1/OpcUa/OpcUaOverview.html":  {
                                        "href":  "V1/OpcUa/OpcUaOverview.html",
                                        "title":  "OPC UA EDS adapter",
                                        "keywords":  "OPC UA EDS adapter Overview The OPC UA EDS adapter transfers time-series data from OPC UA devices into Edge Data Store. It is possible to add a single EDS OPC UA adapter during installation. If multiple EDS OPC UA adapters are desired, please reference Edge Data Store Configuration on how to add a new component to Edge Data Store. The example below covers configuring the first adapter. If another adapter has been installed, please substitute the name of the installed adapter in the below example for OpcUa1. As with other Edge Data Store EDS adapters, the EDS OPC UA adapter is configured using data source and data selection JSON documents. The data source configuration are identical with other adapters, but OPC UA supports an option to generate a template data selection file that can be manually edited and used for subsequent configuration. This optional process for generating and editing the file is different for Windows and Linux . Once the template file is created it can be reused on both Linux and Windows without changes. OPC UA is a standard, which ensures open EDS adapter, interoperability, security, and reliability of industrial automation devices and systems. OPC UA is recognized as one of the key communication and data modeling technologies of Industry 4.0, due to the fact that it works with many software platforms and that it is completely scalable and flexible. Configuration of OPC UA data source To use the OPC UA EDS adapter of Edge Data Store, you must configure from which OPC UA data source it will be receiving data. Procedure for Configuring OPC UA data source Note: You cannot modify OPC UA data source configurations manually. You must use the REST endpoints to add or edit the configuration. The following procedure is for configuring OPC UA data source. Use any text editor and create a file that contains an OPC UA data source in JSON form For content structure, see the following OPC UA data source example section. For a table of all available parameters, see the following Parameters for OPC UA data source section. Save the file as DataSource.config.json. Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:5590/api/v1/configuration/\u003cEDS http:  localhost:5590 api v1 configuration \u003cEDS adapterId\u003e/DataSource/ adapterId\u003e DataSource  . During installation it is possible to add a single EDS OPC UA adapter and it is named OpcUa1. The example below uses this component name. Example using cURL: curl -v -d \"@DataSource.config.json\" -H \"Content-Type: application/json\" application json\" -X POST \"http://localhost:5590/api/v1/configuration/OpcUa1/DataSource\" \"http:  localhost:5590 api v1 configuration OpcUa1 DataSource\" Parameters for OPC UA data source The following parameters are available for configuring an OPC UA data source. Parameter Required Type Description EndpointURL Required string The endpoint URL of the OPC UA server. The following is an example of the URL format: opc.tcp://OPCServerHost:Port/OpcUa/SimulationServer opc.tcp:  OPCServerHost:Port OpcUa SimulationServer Note: If you change the EndpointURL on a configured OPC UA EDS adapter that has DataCollection.config.csv file exported, you will need to relocate the DataCollection.config.csv file from the configuration directory to trigger a new browse (export). UseSecureConnection Optional bool When set to true, the OPC UA EDS adapter connects to a secure endpoint using OPC UA certificate exchange operation. The default is true. When set to false, the OPC UA EDS adapter connects to an unsecured endpoint of the server and certificate exchange operation is not required. Note: OSIsoft recommends setting this option to false for testing purposes only. UserName Optional string User name for accessing the OPC UA server. Password Optional string Password for accessing the OPC UA server. Note: OSIsoft recommends using REST to configure the data source when the password must be specified. RootNodeIds Optional string List of comma-separated NodeIds of those objects from which the OPC UA EDS adapter browses the OPC UA server address space. This option allows selecting only subsets of the OPC UA address by explicitly listing one or more NodeIds which are used to start the initial browse. For example: ns=5;s=85/0:Simulation, ns=5;s=85 0:Simulation, ns=3;s=DataItems. If not specified, it means that the whole address space will be browsed. IncomingTimestamp Optional string Specifies whether the incoming timestamp is taken from the source, from the OPC UA server, or should be created by the OPC UA EDS adapter instance. Source - Default and recommended setting. The timestamp is taken from the source timestamp field. The source is what provides data for the item to the OPC UA server, such as a field device. Server - In case the OPC UA item has an invalid source timestamp field, the Server timestamp can be used. Connector - The OPC UA EDS adapter generates a timestamp for the item upon receiving it from the OPC UA server. StreamIdPrefix Optional string Specifies what prefix is used for Stream IDs. Naming convention is StreamIdPrefix.NodeId. Note: An empty string means no prefix will be added to the Stream IDs. OPC UA data source example The following is an example of valid OPC UA data source configuration: { \"EndpointUrl\": \"opc.tcp://IP-Address/TestOPCUAServer\", \"opc.tcp:  IP-Address TestOPCUAServer\", \"UseSecureConnection\": true, \"UserName\": null, \"Password\": null, \"RootNodeIds\": null, \"IncomingTimestamp\": \"Source\", \"StreamIdPrefix\": null } Configuration of OPC UA data selection In addition to the data source configuration, you need to provide a data selection configuration to specify the data you want the OPC UA EDS adapter to collect from the data sources. Procedure Note: You cannot modify OPC UA data selection configurations manually. You must use the REST endpoints to add or edit the configuration. The following procedure is for configuring OPC UA data selection: Use any text editor and create a file that contains an OPC UA data selection in JSON form For content structure, see the following OPC UA data selection example. For a table of all available parameters, see the following Parameters for OPC UA data selection section. Save the file as DataSelection.config.json. Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:5590/api/v1/configuration/\u003cEDS http:  localhost:5590 api v1 configuration \u003cEDS adapterId\u003e/DataSelection/ adapterId\u003e DataSelection  Example using cURL: curl -v -d \"@DataSelection.config.json\" -H \"Content-Type: application/json\" application json\" -X POST \"http://localhost:5590/api/v1/configuration/\u003cEDS \"http:  localhost:5590 api v1 configuration \u003cEDS adapterId\u003e/DataSelection\" adapterId\u003e DataSelection\" Parameters for OPC UA Data Selection Parameter Required Type Description Selected Optional bool This field is used to select or clear a measurement. To select an item, set to true. To remove an item, leave the field empty or set to false. If not configured, the default value is true. Name Optional string The optional friendly name of the data item collected from the data source. If not configured, the default value will be the stream id NodeId Required string The NodeId of the variable. StreamID Required string The custom stream ID that will be used to create the streams. If not specified, the Modbus TCP EDS adapter will generate a default stream ID based on the measurement configuration. A properly configured custom stream ID follows these rules: Is not case-sensitive. Can contain spaces. Cannot start with two underscores (\"__\"). Can contain a maximum of 260 characters. Cannot use the following characters: /   : ? # [ ] @ ! $ \u0026 \u0027 ( ) \\ * + , ; = % \u003c \u003e | Cannot start or end with a period. Cannot contain consecutive periods. Cannot consist of only periods. OPC UA data selection example The following is an example of valid OPC UA Data Selection configuration: [ { \"Selected\": true, \"Name\": \"Random1\", \"NodeId\": \"ns=5;s=Random1\", \"StreamId\": \"CustomStreamName\" }, { \"Selected\": false, \"Name\": \"Sawtooth1\", \"NodeId\": \"ns=5;s=Sawtooth1\", \"StreamId\": null }, { \"Selected\": true, \"Name\": \"Sinusoid1\", \"NodeId\": \"ns=5;s=Sinusoid1\", \"StreamId\": null } ]"
                                    },
    "V1/OpcUa/OpcUaDataSelectionWindows.html":  {
                                                    "href":  "V1/OpcUa/OpcUaDataSelectionWindows.html",
                                                    "title":  "Generating a template OPC UA data selection configuration file on Windows",
                                                    "keywords":  "Generating a template OPC UA data selection configuration file on Windows On startup, the OPC UA EDS adapter browses the entire OPC UA server address space and exports the available OPC UA variables into a .json file for data selection. Data is collected automatically based upon user demands. OPC UA data from OPC UA variables is read through subscriptions (unsolicited reads). A default OPC UA data source template file will be created if there is no OPC UA data selection configuration, but a valid OPC UA data source exists. There are two necessary prerequisites for this template data selection to be generated: Add an OPC UA EDS adapter with a unique ComponentId. This can also be done during installation of the Edge Data Store by choosing an OPC UA EDS adapter. Configure a valid OPC UA Data Source Once these steps are taken a template OPC UA data selection will be generated in the following directory. For the purpose of this example it is assumed the ComponentId of the OPC UA component is the default OpcUa1: c:\\ProgramData\\OSIsoft\\EdgeDataStore\\Configuration\\OpcUa1_DataSelection.json Copy the file to a different directory to edit it. The contents of the file will look something like: [ { \"Selected\": false, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Cold Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideOutletTemperature\", \"StreamId\": null } ] In a text editor edit the file and change any Selected : false, lines to Selected : true to transfer the OPC UA data to be stored in the Edge Data Store. After that is done, in the same directory where you edited the generated file, run the following curl command: curl -i -d \"@OpcUa1_DataSelection.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/OpcUa1/Dataselection http:  localhost:5590 api v1 configuration OpcUa1 Dataselection To see the streams that have been created in Edge Storage to store the data you are writing you can run the following curl script: curl http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/ http:  localhost:5590 api v1 tenants default namespaces default streams  To view the data in the streams being written you can refer to the SDS part of this documentation. To egress the data to OSIsoft Cloud Services or the PI System, see the egress documentation or quick starts."
                                                },
    "V1/OpcUa/OpcUaDataSelectionLinux.html":  {
                                                  "href":  "V1/OpcUa/OpcUaDataSelectionLinux.html",
                                                  "title":  "Generating a template OPC UA data selection configuration file on Windows",
                                                  "keywords":  "Generating a template OPC UA data selection configuration file on Windows On startup, the OPC UA EDS adapter browses the entire OPC UA server address space and exports the available OPC UA variables into a .json file for data selection. Data is collected automatically based upon user demands. OPC UA data from OPC UA variables is read through subscriptions (unsolicited reads). A default OPC UA data source template file will be created if there is no OPC UA data selection configuration, but a valid OPC UA data source exists. There are two necessary prerequisites for this template data selection to be generated: Add an OPC UA component with a unique ComponentId, unless one was added during Edge Data Store installation. Configure a valid OPC UA Data Source Once these steps are taken a template OPC UA data selection will be generated in the following directory. For the purpose of this example it is assumed the ComponentId of the OPC UA component is the default OpcUa1: /usr/share/OSIsoft/EdgeDataStore/Configuration/OpcUa1_DataSelection.json  usr share OSIsoft EdgeDataStore Configuration OpcUa1_DataSelection.json Copy the file to a different directory to edit it. The contents of the file will look something like: [ { \"Selected\": false, \"Name\": \"Cold Side Inlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideInletTemperature\", \"StreamId\": null }, { \"Selected\": false, \"Name\": \"Cold Side Outlet Temperature\", \"NodeId\": \"ns=2;s=Line1.HeatExchanger1001.ColdSideOutletTemperature\", \"StreamId\": null } ] In a text editor edit the file and change any Selected : false, lines to Selected : true to transfer the OPC UA data to be stored in the Edge Data Store. After that is done, in the same directory where you edited the generated file, run the following curl command: curl -i -d \"@OpcUa1_DataSelection.json\" -H \"Content-Type: application/json\" application json\" -X PUT http://localhost:5590/api/v1/configuration/OpcUa1/Dataselection http:  localhost:5590 api v1 configuration OpcUa1 Dataselection To see the streams that have been created in Edge Storage to store the data you are writing you can run the following curl script: curl http://localhost:5590/api/v1/tenants/default/namespaces/default/streams/ http:  localhost:5590 api v1 tenants default namespaces default streams  To view the data in the streams being written you can refer to the SDS part of this documentation. To egress the data to OSIsoft Cloud Services or the PI System, see the egress documentation or quick starts."
                                              },
    "V1/OMF/OMFOverview.html":  {
                                    "href":  "V1/OMF/OMFOverview.html",
                                    "title":  "OSIsoft Message Format (OMF) ingress with Edge Storage",
                                    "keywords":  "OSIsoft Message Format (OMF) ingress with Edge Storage The Edge Storage component supports both OMF version 1.0 and OMF version 1.1 for data ingress. The OMF ingress functionality is the same technology that is used in OSIsoft Cloud Services (OCS). Writing an OMF application to run on EDS is very similar to writing an OMF application to write data to OCS. No authentication is necessary for writing to Edge Data Store, as long as the application is running on the same computer or device as Edge Data Store. Remote access to OMF data ingress is currently not supported. OMF specification The OMF specification may be found here: http://omf-docs.osisoft.com http:  omf-docs.osisoft.com OMF endpoint The route to the OMF endpoint provided by the Edge Storage component is: Method: POST Endpoint: http://localhost:5590/api/v1/tenants/default/namespaces/default/omf http:  localhost:5590 api v1 tenants default namespaces default omf Supported functionality The OMF endpoint for the Edge Storage component supports both OMF version 1.0 and OMF version 1.1 for data ingress. The OMF endpoint for the Edge Storage component does not support the update action."
                                },
    "V1/Egress/Egress.html":  {
                                  "href":  "V1/Egress/Egress.html",
                                  "title":  "Egress from Edge Data Store",
                                  "keywords":  "Egress from Edge Data Store Edge Data Store provides an egress mechanism to copy and transfer data to another device or destination. Data is transferred through OMF. Supported destinations are OSIsoft Cloud Services or a PI server. Configuration of egress includes specifying zero or more endpoints. An egress endpoint represents a destination to which data will be sent. Each egress endpoint is comprised of the properties specified in the Parameters section, is executed independently of all other egress endpoints, and is expected to accept OMF messages. More than one endpoint for the same destination is allowed. Note: Some types, and consequently containers and data, cannot be egressed. See Egress Execution Details for more information. One tenant and two namespaces are supported in the Edge Data Store. The tenant is default, and the two namespaces are default (where adapter and OMF data is written) and diagnostics. Diagnostics is where the system and its components write information that can be used locally or egressed to a remote PI Server or OCS for monitoring. To egress both namespaces two egress definitions are required. Configuration Procedure Note: You cannot add egress configurations manually, because some parameters are stored to disk encrypted. You must use the REST endpoints to add/edit add edit egress configuration. See REST Urls for additional endpoints. Complete the following to create new egress endpoints: Using any text editor, create a file that contains one or more egress endpoints in JSON form See Examples section below for content structure See Parameters section below for a table of all available egress parameters Save the file. Use any tool capable of making HTTP requests to execute a POST command with the contents of that file to the following endpoint: http://localhost:5590/api/v1/configuration/storage/periodicegressendpoints/ http:  localhost:5590 api v1 configuration storage periodicegressendpoints  Example using cURL: curl -v -d \"@Storage_PeriodicEgressEndspoints.config.json\" -H \"Content-Type: application/json\" application json\" -X POST \"http://localhost:5590/api/v1/configuration/storage/periodicegressendpoints\" \"http:  localhost:5590 api v1 configuration storage periodicegressendpoints\" Parameters Parameter Required Type Description Id Required string Unique identifier ExecutionPeriod Required string Frequency of time between each egress action. Must be a string in the following format d.hh:mm:ss.## Endpoint Required string Destination that accepts OMF v1.1 messages. Supported destinations include OCS and PI. ClientId Required for OCS endpoint string Used for authentication with the OCS OMF endpoint. ClientSecret Required for OCS endpoint string Used for authentication with the OCS OMF endpoint. Username Required for PI endpoint string Used for Basic authentication to the PI Web API OMF endpoint. Password Required for PI endpoint string Used for Basic authentication to the PI Web API OMF endpoint. Name Optional string Friendly name Description Optional string Friendly description Enabled Optional bool An indicator of whether egress is enabled when the egress endpoint is loaded. Defaults to true. Backfill Optional bool An indicator of whether data should be backfilled. Backfilling will occur when the egress endpoint is run for the first time after application startup. Enabling backfilling will result in all data from the earliest index to the latest stored index being egressed, after applying the egress filter. Defaults to false. ValidateEndpointCertificate Optional bool Used to disable verification of destination certificate. Use for testing only with self-signed certificates. Defaults to true. EgressFilter Optional string A filter used to determine which streams and types are egressed. See Searching for more information on valid filters. StreamPrefix Optional string Prefix applied to any streams that are egressed. A null string or a string containing only empty spaces will be ignored. The following restricted characters will not be allowed: /   : ? # [ ] @ ! $ \u0026 \u0027 ( ) \\ * + , ; = % TypePrefix Optional string Prefix applied to any types that are egressed. A null string or a string containing only empty spaces will be ignored. The following restricted characters will not be allowed: /   : ? # [ ] @ ! $ \u0026 \u0027 ( ) \\ * + , ; = % DebugExpiration Optional string A property that enables persistence of detailed information, for each outbound HTTP request pertaining to this egress endpoint, to disk. The value of this property represents the date and time this detailed information should stop being persisted. See Troubleshooting for more information. NamespaceId Optional string Represents the namespace that will be egressed. There are two available namespaces: default; diagnostics. Default namespace is ???default???. TokenEndpoint Optional for OCS endpoint string Used to retrieve an OCS token from an alternative endpoint. This is not normally necessary with OCS. Only use if directed to do so by customer support . Examples Find various examples below of valid egress configurations. Egress data to OCS. All streams, every 15 seconds. [{ \"Id\": \"OCS\", \"ExecutionPeriod\" : \"00:00:15\", \"Endpoint\" : \" https://{OcsLocation}/api/Tenants/{tenantId}/Namespaces/{namespaceId}/omf\", https:  {OcsLocation} api Tenants {tenantId} Namespaces {namespaceId} omf\", \"ClientId\" : \"{clientId}\", \"ClientSecret\" : \"{clientSecret}\" }] Egress data to OCS - streams with a specific TypeId value, every 15 seconds. [{ \"Id\": \"OCS\", \"ExecutionPeriod\" : \"00:00:15\", \"EgressFilter\" : \"TypeId:myType\", \"Endpoint\" : \" https://{OcsLocation}/api/Tenants/{tenantId}/Namespaces/{namespaceId}/omf\", https:  {OcsLocation} api Tenants {tenantId} Namespaces {namespaceId} omf\", \"ClientId\" : \"{clientId}\", \"ClientSecret\" : \"{clientSecret}\" }] Egress data to OCS - all streams, every 15 seconds, including backfilling which occurs on first run or restart. [{ \"Id\": \"OCS\", \"ExecutionPeriod\" : \"00:00:15\", \"Backfill\" : true, \"Endpoint\" : \" https://{OcsLocation}/api/Tenants/{tenantId}/Namespaces/{namespaceId}/omf\", https:  {OcsLocation} api Tenants {tenantId} Namespaces {namespaceId} omf\", \"ClientId\" : \"{clientId}\", \"ClientSecret\" : \"{clientSecret}\" }] Egress diagnostic data to OCS - every 1 hour. [{ \"Id\": \"OCS\", \"ExecutionPeriod\" : \"01:00:00\", \"Endpoint\" : \" https://{OcsLocation}/api/Tenants/{tenantId}/Namespaces/{namespaceId}/omf\", https:  {OcsLocation} api Tenants {tenantId} Namespaces {namespaceId} omf\", \"ClientId\" : \"{clientId}\", \"ClientSecret\" : \"{clientSecret}\", \"NamespaceId\" : \"diagnostics\" }] Egress data to PI - all streams, every 15 seconds, including both type and stream prefix. All properties explicitly listed. [{ \"Id\": \"PI\", \"Name\" : null, \"Description\" : null, \"ExecutionPeriod\" : \"00:00:15\", \"Enabled\" : true, \"Backfill\" : false, \"EgressFilter\" : null, \"Endpoint\" : \"https://{webApiLocation}/piwebapi/omf/\", \"https:  {webApiLocation} piwebapi omf \", \"ClientId\" : null, \"ClientSecret\" : null, \"Username\" : \"{username}\", \"Password\" : \"{password}\", \"StreamPrefix\" : \"1ValidPrefix.\", \"TypePrefix\" : \"AlsoValid_\", \"DebugExpiration\" : null, \"NamespaceId\" : \"default\", \"TokenEndpoint\" : null, \"ValidateEndpointCertificate\" : true }] Egress data to PI - streams whose Id contains \"Modbus\" or \"Opc\", every 1 minute. [{ \"Id\": \"PI\", \"ExecutionPeriod\" : \"00:01:00\", \"EgressFilter\" : \"Id:*Modbus* OR Id:*Opc*\", \"Endpoint\" : \"https://{webApiLocation}/piwebapi/omf/\", \"https:  {webApiLocation} piwebapi omf \", \"Username\" : \"{username}\", \"Password\" : \"{password}\" }] Egress data to PI - streams containing a field that begins with \"Unique\", every 1 hour. [{ \"Id\": \"PI\", \"ExecutionPeriod\" : \"01:00:00\", \"EgressFilter\" : \"Unique*\", \"Endpoint\" : \"https://{webApiLocation}/piwebapi/omf/\", \"https:  {webApiLocation} piwebapi omf \", \"Username\" : \"{username}\", \"Password\" : \"{password}\" }] REST URLs Relative URL HTTP verb Action api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints GET Gets all configured egress endpoints api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints DELETE Deletes all configured egress endpoints api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints POST Add an array of egress endpoints, will fail if any endpoint already exists api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints POST Add a single egress endpoints, will fail if endpoint already exists api/v1/configuration/storage/periodicegressendpoints api v1 configuration storage periodicegressendpoints PUT Replace all egress endpoints api/v1/configuration/storage/periodicegressendpoints/{id} api v1 configuration storage periodicegressendpoints {id} GET Get configured endpoint with id api/v1/configuration/storage/periodicegressendpoints/{id} api v1 configuration storage periodicegressendpoints {id} DELETE Delete configured endpoint with id api/v1/configuration/storage/periodicegressendpoints/{id} api v1 configuration storage periodicegressendpoints {id} PUT Replace egress endpoint with id , will fail if endpoint doesn\u0027t exist api/v1/configuration/storage/periodicegressendpoints/{id} api v1 configuration storage periodicegressendpoints {id} PATCH Allows partial updating of configured endpoint with id Egress execution details After configuration for an egress endpoint is added, egress execution will periodically occur for that endpoint. Egress is handled individually per configured endpoint. On the first execution types and containers will be egressed; subsequently only new or changed types/containers types containers will be egressed. Only streams with a single, timeseries-based index can be egressed . Type creation must be successful in order to perform container creation; likewise container creation must be successful in order to perform data egress. Type, container and data items are batched into one or more OMF messages when egressing. Per the requirements defined in OMF, a single message will not exceed 192KB in size. Compression is automatically applied to outbound egress messages. On the destination, failure to add a single item will result in the message failing. In that case the Edge Data Store will fall back to egressing each item individually, per type or stream (i.e. each type, each stream, all data for a single stream). Types, containers, and data will continue to be egressed as long as the destination continues to respond to HTTP requests - retrying previous failures as needed. Certain HTTP failures during egress will result in a retry. The Edge Data Store will retry an HTTP request a maximum of 5 times with exponentially increasing delays between each request. The total time waiting and retrying is currently set at 1 minute. During that time egress of other messages will be delayed. List of retryable occurrences: TimeoutException HttpRequestException HttpStatusCode RequestTimeout (408) HttpStatusCode BadGateway (502) HttpStatusCode ServiceUnavailable (503) HttpStatusCode GatewayTimeout (504) For data collection and egress, in-memory and on-disk storage are used to track the last successfully-egressed data event, per stream. Data is egressed in order and includes events in the future. Note When an event with a future timestamp is successfully egressed, only values after the associated timestamp of that event will be egressed."
                              }
}
